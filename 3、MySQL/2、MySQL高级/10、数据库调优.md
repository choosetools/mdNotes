[TOC]



# 一、性能分析工具的使用

在数据库调优中，我们的目标是`响应时间更快`、`吞吐量更大`。利用宏观的监控工具和微观的日志分析可以帮我们快速找到调优的思路和方式。



## 数据库服务器的优化步骤

当我们遇到数据调优问题的时候，该如何思考呢？这里把思考的流程整理成下面这张图。

整个流程划分成了`观察（Show status）`和`行动（Action）`两个部分。字母S的部分代表观察（会使用响应的分析工具），字母A代表的部分的是行动（对应分析可以采取的行动）。

![image-20240409113015919](.\images\image-20240409113015919.png)![image-20240409113047191](.\images\image-20240409113047191.png)![image-20240409113125995](.\images\image-20240409113125995.png)

我们可以通过观察了解数据库整体的运行状态，通过性能分析工具可以让我们了解执行慢的SQL都有哪些，查看具体的SQL执行计划，甚至是SQL执行中的每一步的成本代价，这样才能定位问题所在，找到了问题，再采取相应的行动。

**`我们来详细解释一下数据库调优的具体步骤：`**

> 首先在S1部分，我们需要观察服务器的状态是否`存在周期性的波动`。如果存在周期性波动，有可能是周期性节点的原因，比如双十一、促销活动。这样的话，哦们可以通过A1这一步骤解决，也就是加缓存，或者更改缓存失效的策略。
>
> 如果缓存策略没有解决，或者不是周期性波动的原因，我们就需要进一步`分析查询延迟和卡顿的原因`。接下来进入到S2这一步，我们需要开启慢查询。慢查询可以帮我们定位执行慢的SQL语句。我们可以通过设置`long_query_time`参数定义“慢”的阈值，如果SQL执行的时间超过了`long_query_time`，则会认为是慢查询。当收集上来这些慢查询之后，我们就可以通过分析工具对慢查询日志进行分析。
>
> 在S3这一步骤中，我们就知道了执行慢的SQL，这样就可以针对性地用`EXPLAIN`查看对应SQL语句的执行计划，或者使用`show profile`查看SQL中每一个步骤的时间成本。这样我们就可以了解SQL查询慢是因为执行时间长，还是等待时间长。
>
> 如果是SQL等待时间长，我们进入A2步骤。在这一步骤中，我们可以`调优服务器参数`，比如适当增加数据库缓冲池等。如果是SQL执行时间长，就进入A3步骤，这一步中我们需要考虑是索引设计的问题，还是查询关联的数据表过多，还是因为数据表字段的设计问题导致了这一现象。然后在这些维度上进行对应的调整。
>
> 如果A2和A3都不能解决问题，我们需要考虑数据库自身的SQL查询性能是否已经达到了瓶颈，如果确认没有达到`性能瓶颈`，就需要重新检查，重复以上的步骤。如果已经达到了性能瓶颈，进入A4阶段，需要考虑`增加服务器`，采用读`写分离`的架构，或者考虑对数据库进行`分库分表`，比如垂直分库、垂直分表和水平分表等。
>
> 以上就是数据库调优的流程思路。如果我们发现执行SQL时存在不规则延迟或卡顿的时候，就可以采用分析工具帮我们定位有问题的SQL，这三种分析工具可以理解是SQL调优的三个步骤：**`慢查询`**、**`EXPLAIN`**和**`SHOW PROFILING`**。







## 查看系统性能参数

在MySQL中，可以使用`SHOW STATUS`语句查询一些MySQL数据库服务器的`性能参数`、`执行频率`。

SHOW STATUS语句语法如下：

```sql
SHOW [GLOBAL|SESSION] STATUS LIKE '参数';
```

一些常用的性能参数如下：

* Connections：连接MySQL服务器的次数。
* Uptime：MySQL服务器的上线时间。
* `Slow_queries`：慢查询次数
* Innodb_rows_read：当前mysql服务，所有执行SELECT查询返回的行数和。
* Innodb_rows_inserted：当前mysql服务，所有执行INSERT插入的行数和。
* Innodb_rows_updated：当前mysql服务，所有执行UPDATE更新的行数和。
* Innodb_rows_deleted：当前mysql服务，所有执行DELETE删除的行数和。
* Com_select：查询操作的次数。
* Com_insert：插入操作的次数。对于批量插入的INSERT操作，只累加一次。
* Com_update：更新操作的次数
* Com_delete：删除操作的次数

案例：

若查询MySQL服务器的连接次数，则可以执行如下语句：

```sql
SHOW STATUS LIKE 'Connections';
```

若查询服务器工作时间，则可以执行如下语句：

```sql
SHOW STATUS LIKE 'Uptime';
```

若查询MySQL服务器的慢查询次数，则可以执行如下语句：

```sql
SHOW STATUS LIKE 'Slow_queries';
```

**慢查询次数参数可以结合慢查询日志找出慢查询语句，然后针对慢查询语句进行`表结构优化`或`查询语句优化`。**

如下的执行可以查看相关SQL执行的行数情况：

```sql
SHOW STATUS LIKE 'Innodb_rows_%';
```





## 统计SQL的查询成本：last_query_cost

一条SQL查询语句在执行前需要确定查询执行计划，如果存在多种执行计划的话，MySQL会计算每个执行计划所需要的成本，从中选择`成本最小`的一个作为最终执行的执行计划。

如果我们想要查看某条SQL语句的查询成本，可以在执行完这条SQL语句之后，通过查看当前会话中的**`last_query_cost`**变量来得到当前查询的成本。它通常也是我们评价一个查询的执行效率的一个常用指标。

这个属性表示的含义是**最后一次查询语句所需要读取的页的数量**。

案例：

我们依然使用student_info表为例：

```sql
CREATE TABLE `student_info` (
 `id` INT(11) NOT NULL AUTO_INCREMENT,
 `student_id` INT NOT NULL ,
 `name` VARCHAR(20) DEFAULT NULL,
 `course_id` INT NOT NULL ,
 `class_id` INT(11) DEFAULT NULL,
 `create_time` DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
 PRIMARY KEY (`id`)
) ENGINE=INNODB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;
```

如果我们想要查询id=900001的记录，然后看下查询成本，我们可以直接在聚簇索引上进行查找：

```sql
SELECT student_id, class_id, name, create_time 
FROM student_info
WHERE id = 9000001;
```

运行速度为0.042s

然后再看下查询优化器的成本，实际上我们只需要检索一个页即可：

![image-20240409124048108](.\images\image-20240409124048108.png)

如果我们想要查询id为90000001到90001000之间的学生记录呢？

```sql
SELECT student_id, class_id, name, create_time 
from student_info
WHERE id BETWEEN 9000001 AND 900010000;
```

运行时间为0.046s。

然后再来看下查询优化器的成本，这时我们大概需要进行20个页的查询：

![image-20240409124633844](.\images\image-20240409124633844.png)

可以看到页的数量是刚才的20倍，但是查询的效率没有发生明显的变化，实际上这两个SQL查询时间基本上是一样的，就是因为采用了顺序读取的方式将区中的页面一次性加载到缓冲池中，然后再进行查找。虽然页数量(last_query_cost)增加了不少，但是通过缓冲池的机制，并没有增加多少查询时间。





## 定位慢的SQL：慢查询日志

MySQL的慢查询，用来记录在MySQL中`响应时间超过阈值`的语句，具体指运行时间超过`long_query_time`值的SQL，则会被记录到慢查询日志中。long_query_time的默认值为`10`，意思是运行10秒以上（不含10秒）的语句，认为是超出了我们的最大忍耐时间值。

它的主要作用是，帮助我们发现那些执行时间特别长的SQL查询，并且有针对化地进行优化，从而提高系统的整体效率。当我们的数据库服务器发生阻塞、运行变慢的时候，检查一下慢查询日志，找到那些慢查询，对解决问题很有帮助。比如一条sql执行超过5秒钟，我们就算慢SQL，希望能收集超过5秒的sql，结合explain进行全面分析。

**默认情况下，MySQL数据库没有开启慢查询日志**，需要我们手动来设置这个参数。**`如果不是调优需要的话，一般不建议启动该参数`**，因为开启慢查询日志或多或少会带来一定的性能影响。

慢查询日志支持将日志记录写入文件。



### 1、开启慢查询日志信息

1. **`开启慢查询日志参数slow_query_log`**

原本的慢查询日志参数是关闭的，使用

``` sql
SHOW VARIABLES LIKE 'slow_query_log%';
```

查看慢查询日志是否开启，以及慢查询日志文件的位置：

![image-20240409215423629](.\images\image-20240409215423629.png)

我们可以看到，在默认情况下，慢查询日志是关闭的，并且慢查询日志信息保存在`/var/lib/mysql/centOS7-slow.log`文件中。

使用下面的语句开启慢查询日志：

```sql
SET GLOBAL slow_query_log='ON';
```

这个slow_query_log是global类型的，所以我们在开启慢查询日志时，需要在SET关键字后面添加GLOBAL（如果不添加，表示修改的是会话变量）。



2. **`修改long_query_time阈值`**

我们来看下慢查询的时间阈值设置，使用如下命令：

```sql
SHOW VARIABLES LIKE '%long_query_time%';
```

![image-20240409215906633](.\images\image-20240409215906633.png)

long_query_time变量既是全局变量，又是会话变量。

当我们去修改global类型的long_query_time的值，修改后全局的属性都发生了变化，但是当前会话的响应时间依然是10s，因为修改全局的值只会对新建的会话有效。

所以，我们去修改long_query_time的值时，可以一并地对全局与会话属性都进行修改：

```sql
#修改全局阈值
set global long_query_time = 1;
show global variables like '%long_query_time%';

#修改当前会话阈值
set long_query_time = 1;
show variables like '%long_query_time%';
```

![image-20240409220221655](.\images\image-20240409220221655.png)

这些方式都是临时的方式进行修改（重启服务器后失效），如果要永久性地修改，可以使用下面的方式：



**`补充：配置文件中修改慢查询日志信息`**

如下方式，相较于前面的命令行方式，可以看作是永久设置的方式。

修改`/etc/my.cnf`文件，在文件中增加或修改参数`long_query_time`、`slow_query_log`和`slow_query_log_file`后，然后重启MySQL服务器。

```properties
slow_query_log=ON  #开启慢查询日志的开关
slow_query_log_file=/var/lib/mysql/test-slow.log  #设置慢查询日志的目录和文件信息
long_query_time=3  #设置慢查询的阈值为3秒，超出此设定值的SQL即被记录到慢查询日志
log_output=FILE
```

如果不指定存储路径，慢查询日志将默认存储到MySQL数据库的数据文件夹下。如果不指定文件名，默认文件名为hostname-slow.log。





### 2、查看慢查询数目

查看当前系统中有多少条慢查询记录

```sql
SHOW GLOBAL STATUS LIKE '%Slow_queries%';
```





### 3、数据准备

**步骤1：建表**

```sql
CREATE TABLE student(
	id INT NOT NULL AUTO_INCREMENT,
	stuno INT NOT NULL,
	name VARCHAR(20) DEFAULT NULL,
	age INT DEFAULT NULL,
    classId INT DEFAULT NULL,
    PRIMARY KEY(id)
)ENGINE = INNODB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;
```



**步骤2：设置log_bin_trust_function_creators**

我们在创建存储函数时，有可能会报错：

This function has none of DETERMINISTIC......

命令开启：允许创建存储函数

```sql
SET GLOBAL log_bin_trust_function_creators=1;
```



**步骤3：创建函数**

随机产生字符串函数

```sql
DELIMITER //
CREATE FUNCTION rand_string(n INT)
RETURNS VARCHAR(255) #该函数会返回一个字符串
BEGIN
DECLARE chars_str VARCHAR(100) DEFAULT
'abcdefghijklmnopqrstuvwxyzABCDEFJHIJKLMNOPQRSTUVWXYZ';
DECLARE return_str VARCHAR(255) DEFAULT '';
DECLARE i INT DEFAULT 0;
WHILE i < n DO
SET return_str =CONCAT(return_str,SUBSTRING(chars_str,FLOOR(1+RAND()*52),1));
SET i = i + 1;
END WHILE;
RETURN return_str;
END //
DELIMITER ;
```

创建产生随机数值函数：

```sql
DELIMITER //
CREATE FUNCTION rand_num (from_num INT ,to_num INT) RETURNS INT(11)
BEGIN
DECLARE i INT DEFAULT 0;
SET i = FLOOR(from_num +RAND()*(to_num - from_num+1)) ;
RETURN i;
END //
DELIMITER ;
```



**步骤4：创建存储过程**

```sql
DELIMITER //
CREATE PROCEDURE insert_stu1( START INT , max_num INT )
BEGIN
DECLARE i INT DEFAULT 0;
SET autocommit = 0; #设置手动提交事务
REPEAT #循环
SET i = i + 1; #赋值
INSERT INTO student (stuno, NAME ,age ,classId ) VALUES
((START+i),rand_string(6),rand_num(10,100),rand_num(10,1000));
UNTIL i = max_num
END REPEAT;
COMMIT; #提交事务
END //
DELIMITER ;
```



**步骤5：调用存储过程**

```sql
#调用刚刚写好的函数，4000000条记录，从100001号开始
CALL insert_stu1(100001,4000000);
```

此时就创建了4000000条记录。

### 4、测试及分析

使用查询语句，去student表中进行两次查询操作：

```sql
SELECT * FROM student WHERE stuno = 3626771;
```

![image-20240409224503949](.\images\image-20240409224503949.png)

这个查询所花费的时间超过了1s。

这个时候，我们去查看数据库所有的慢查询次数：

```sql
SHOW STATUS like 'slow_queries';
```

![image-20240409224706937](.\images\image-20240409224706937.png)

发现，出现了一次慢查询。

> **补充说明：**
>
> 我们需要知道的是，是否满足慢查询的条件，不仅仅是根据long_query_time参数来决定的，还有另一个参数：min_examined_row_limit一起共同决定。
>
> 只有当查询扫描数超过min_examined_row_limit，并且查询执行时间超过long_query_time的值，这个查询才会被记录到慢查询日志中。
>
> 在默认情况下，min_examined_row_limit的值是0。
>
> ![image-20240409223920313](.\images\image-20240409223920313.png)
>
> 与long_query_time=1结合起来，表示只要查询的执行时间超过10秒钟，哪怕一个记录也没有扫过，都要被记录到慢查询日志中。
>
> 我们只需要知道，慢查询日志的记录是根据两个系统参数来决定的，不需要对min_examined_row_limit参数进行修改。

### 5、慢查询日志分析工具：mysqldumpslow

在生产环境中，如果要手动分析日志，查找、分析SQL，显然是一个体力活，MySQL提供了日志分析工具`mysqldumpslow`。

查看mysqldumpslow的帮助信息，注意这个文件实际上不是在mysql中执行的，而是去Linux系统下进行执行，因为这个mysqldumpslow是一个脚本文件

```shell
mysqldumpslow --help
```

![image-20240410095035651](.\images\image-20240410095035651.png)

mysqldumpslow命令的具体参数如下：

* `-a`：表示不将结果中的数字使用N表示，字符串使用S表示。使用mysqldumpslow获取到的结果中，如果有数字，会使用N表示，如果有字符串，会使用S表示，-a参数的作用就是去显示完整的查询语句，而不将数字与字符串抽象表达。
* `-s：表示按照何种方式进行排序：`
  * c：访问次数
  * l：锁定时间
  * r：返回记录
  * **`t：查询时间`**
  * al：平均锁定时间
  * ar：平均返回记录数
  * at：平均查询时间（默认方式）
  * ac：平均查询次数
* `-t：返回前面多少条数据；`
* -g：后面搭配一个正则表达式，大小写不敏感

例如：我们想要查询按照时间排序，查看前5条SQL语句，可以这样写：

```shell
mysqldumpslow -s t -t 5 /var/lib/mysql/centOS7-slow.log
```

![image-20240410103304595](.\images\image-20240410103304595.png)

如上结果所示，查询出来的是前5条，按照时间的倒序（所花时间最长的放在最上面）排序的所有慢查询语句。

上述查询语句中，数字使用了N表示，字符串使用了S表示，如果我们想要查看原本的数字以及字符串信息，可以加上-a命令：

```shell
mysqldumpslow -a -s t -t 5 /var/lib/mysql/centOS7-slow.log
```

![image-20240410103719725](.\images\image-20240410103719725.png)

这个时候，我们就能够查看到完整的查询信息。



**`工作mysqldumpslow语句模板`**

```shell
#得到返回记录集最多的10个SQL
mysqldumpslow -s r -t 10 /var/lib/mysql/慢查询日志文件

#得到访问次数最多的10个SQL
mysqldumpslow -s c -t 10 /var/lib/mysql/慢查询日志文件

#得到按照时间排序的前10条里面含有左连接的查询语句
mysqldumpslow -s t -t 10 -g "left join" /var/lib/mysql/慢查询日志文件

#另外建议这些命令结合| more一起使用，否则可能出现爆屏情况
mysqldumpslow -s r -t 10 /var/lib/mysql/慢查询日志文件 | more
```





### 6、关闭慢查询日志

如果使用的是持久化方式打开的慢查询日志，也可以使用持久化的方式关闭慢查询日志。

**`方式1：永久性方式`**

```properties
[mysqld]
slow_query_log=OFF
```

上述就是在/etc/my.cnf文件中，将slow_query_log设置成OFF，或者也可以直接将该属性删除，然后重启MySQL服务。



如果使用临时方式打开的慢查询，也可以使用临时性方式关闭慢查询日志。

**`方式2：临时性方式`**

使用SET语句来进行设置

```sql
SET GLOBAL slow_query_log=OFF;
```

重启MySQL服务后，该属性以及long_query_time属性都会被重置：

![image-20240410105644368](.\images\image-20240410105644368.png)





### 7、删除慢查询日志

使用SHOW语句显示慢查询日志信息，具体SQL语句如下：

```sql
SHOW VARIBALES LIKE 'slow_query_log%';
```

![image-20240410110508675](.\images\image-20240410110508675.png)

从执行结果可以看出，慢查询日志默认为MySQL的数据目录。如果调优已经结束，并且慢查询日志信息过大时，我们可以进行删除操作，在`该目录下手动rm删除日志文件`即可，即：

```shell
cd /var/lib/mysql/

rm centOS7-slow.log  
```

删除完毕之后，我们还需要重新生成查询日志文件，具体命令如下，执行完毕后会在数据目录下重新生成慢查询日志文件。

```shell
mysqladmin -uroot -p flush-logs slow
```

注意：如果mysql中此时未开启慢查询日志，那么文件是不会立刻被重新生成的，将mysql中slow_query_log的值设为ON时，就会生成。

> 提示：
>
> 慢查询日志都是使用mysqladmin flush-logs命令来删除重建的。使用时一定要注意，一旦执行了这个命令，慢查询日志都只存在新的日志文件中，如果需要旧的查询日志，就必须事先备份。







### 慢查询语句的使用步骤总结：

1. **首先**，我们需要知道，慢查询日志是否开启，以及慢查询日志信息保存在哪一个文件中

   ```sql
   SHOW VARIABLES LIKE 'slow_query_log%';
   ```

   ![image-20240410101541589](.\images\image-20240410101541589.png)

   我们可以看到，慢查询日志已经开启，并且慢查询日志信息保存在/var/lib/mysql/centOS7-slow.log文件中。

   如果慢查询日志未开启，那么就需要使用：

   ```sql
   SET GLOBAL slow_query_log = ON;
   ```

   开启慢查询日志。默认情况下，慢查询日志是关闭状态。



2. **其次**，我们需要去考虑查询多少秒算慢查询，查看一下当前设置的慢查询时间：

   ```sql
   SHOW VARIBALES LIKE 'long_query_time';
   ```

   ![image-20240410102116477](.\images\image-20240410102116477.png)

   当前所设置的慢查询时间为1s。

   我们也可以通过

   ```sql
   SET GLOBAL long_query_time = 时间;
   
   SET long_query_time = 时间;
   ```

   的方式去修改慢查询的时间。（如果使用GLOBAL全局参数去修改    long_query_time的参数，只会对新会话生效，当前会话不会生效，必须还需要去修改当前会话的long_query_time的值）



3. **之后**，我们就可以使用`mysqldumpslow`，来查看慢查询的日志信息。注意mysqldumpslow命令是在Linux系统中执行的，它是一个脚本命令，不是SQL命令。比如：按照时间排序，查看前5条慢查询SQL语句

   ```shell
   mysqldumpslow -s t -t 5 /var/lib/mysql/centOS7-slow.log
   ```

   ![image-20240410103304595](.\images\image-20240410103304595.png)

   此时，我们就得到了前5条所花时间最长的慢查询语句。

   之后，我们就可以使用EXPLAIN去分析这些语句。

   

4. **最后**，我们使用完慢查询日志后，应当去关闭慢查询日志。

   ```sql
   SET GLOBAL slow_query_log = OFF;
   ```
   
   如果调优完毕，并且慢查询日志文件过大想要进行删除，我们也可以对慢查询日志文件进行删除操作，删除完毕之后再使用`mysqladmin flush-logs`命令对查询日志文件进行重新生成
   
   ```shell
   mysqladmin -uroot -p flush-logs slow
   ```

建议：如果没有在给数据库调优，建议关闭慢查询日志，因为慢查询日志会影响效率。





---



## 分析SQL执行成本：SHOW PROFILE

SHOW PROFILE是MySQL提供的可以用来分析当前会话中SQL做了什么、执行的资源消耗情况的工具，可用于SQL调优的测量。`默认情况下处于关闭状态`，并保存最近15次的运行结果。

### 开启SHOW PROFILE功能

首先，我们查看一下当前服务中是否开启了SHOW PROFILE功能

```sql
SHOW VARIABLES LIKE 'profiling';
```

<img src=".\images\image-20240410111724674.png" alt="image-20240410111724674" style="zoom:67%;" />

默认情况下是关闭状态。

通过设置**`profiling=ON`**来开启SHOW PROFILE功能：

```sql
SET PROFILING = ON;
```

<img src=".\images\image-20240410111912559.png" alt="image-20240410111912559" style="zoom:67%;" />





### 使用SHOW PROFILE功能

在开启SHOW PROFILE功能后，就可以去执行相关的查询语句，然后使用SHOW PROFILE去查看资源的使用情况。

**查看当前会话执行了哪些查询：**

```sql
SHOW profiles;
```

<img src=".\images\image-20240410112620418.png" alt="image-20240410112620418" style="zoom:67%;" />

可以看到当前会话一共有7个查询。

**使用下面命令查看最近一次查询的开销：**

```sql
SHOW profile;
```

<img src=".\images\image-20240410112713235.png" alt="image-20240410112713235" style="zoom:67%;" />

显示出来的结果是查询中，每一个步骤所花费的时间。

我们也可以使用`for query 数字`的方式，去查看指定查询的开销：

```sql
SHOW profile for query 5;
```

<img src=".\images\image-20240410112914904.png" alt="image-20240410112914904" style="zoom:67%;" />

同时，在SHOW profile中，我们还可以查看其他的开销，比如cpu、block io等，例如

```sql
SHOW profile cpu, block io for query 7;
```

![image-20240410113156181](.\images\image-20240410113156181.png)

对于上面查询得到的结果，我们可以得知，是executing所花费的时间最长，也就是执行过程花了很长时间，这个时候，我们就可以使用`EXPLAIN`去查看执行计划，分析花费时长的原因。

**`show profile的常用参数`**：

1. ALL：显示所有的开销信息。
2. BLOCK IO：显示块IO开销。
3. CONTEXT SWITCHES：上下文切换开销。
4. CPU：显示CPU开销信息。
5. IPC：显示发送和接收开销信息。
6. MEMORY：显示内存开销信息。
7. PAGE FAULTS：显示页面错误开销信息。
8. SOURCE：显示和source_function，source_file，source_line相关的开销信息。
9. SWAPS：显示交换次数开销信息。

**`日常开发需要注意的结论：`**

* `converting HEAP to MyISAM`：查询结果太大，内存不够，数据往磁盘上搬。
* `Creating tmp table`：创建临时表。先拷贝数据到临时表，用完再删除临时表。
* `Copying to tmp table on disk`：把内存中临时表复制到磁盘上，警惕！
* `locked`。

如果在show profile诊断结果中出现了以上四条结果中的任何一条，则sql语句需要优化。





---

## 分析查询语句：EXPLAIN

### 1、概述

**`定位了查询慢的SQL之后，我们就可以使用EXPLAIN或DESCRIBE工具做针对性的分析查询语句。`**DESCRIBE语句的使用方法和EXPLAIN语句是一样的，并且分析结果也是一样的。

MySQL中有专门负责优化SELECT语句的优化器模块，主要功能：通过计算分析系统中收集到的统计信息，为客户端的Query提供它自己认为的最优`执行计划`。

这个执行计划展示了接下来具体执行查询的方式，比如多表连接顺序是什么，对于每个表采用什么访问方法来具体执行查询等等。MySQL为我们提供了EXPLAIN语句来帮助我们查看某个查询语句的具体执行计划。了解EXPLAIN语句的各个输出项，可以有针对性的提升我们查询语句的性能。

EXPLAIN语句的**作用：`查看SQL的执行计划。`**

那么实际上，执行EXPALIN语句`并不会去真正地执行SQL`，而是去查看执行该SQL的计划。

**EXPLAIN能显示什么？**

* 表的读取顺序
* 数据读取操作的操作类型
* 哪些索引可以使用
* `哪些索引被实际使用`
* 表之间的引用
* `每张表有多少行被优化器查询`

**版本情况：**

* MySQL5.6.3以前只能`EXPLAIN SELECT`；MySQL5.6.3以后就可以`EXPLAIN SELECT,UPDATE,DELETE`。
* 在MySQL6.7以前的版本中，如果想要实现`partitions`，需要使用`explain partitions`命令；想要显示`filtered`，需要使用`explain extended`命令。在5.7版本后，默认explain直接显示partitions和filtered中的信息。

![image-20240410134624503](.\images\image-20240410134624503.png)



### 2、基本语法

**语法：**

```sql
EXPLAIN SELECT select_options;
或者
DESCRIBE SELECT select_options;
```

例如：

![image-20240410135141703](.\images\image-20240410135141703.png)

> **`说明：查询了几次表，就会生成几个数据。`**
>
> 上例就是只查询了一次student表。

输出的上述信息就是`执行计划`。在这个执行计划的辅助下，我们需要知道应该怎样改进自己的查询语句以及使查询执行起来更高效。其实除了以SELECT开头的查询语句，其余的DELETE、INSERT、REPLACE以及UPDATE语句等都可以加上EXPLAIN，用来查看这些语句的执行计划，只是平时我们对SELECT语句更感兴趣。

**注意：**执行EXPLAIN时并没有真正的执行该后面的语句，因此可以安全的查看执行计划。

EXPLAIN语句输出的各个列的作用简述如下：

| 列名            | 描述                                                     |
| --------------- | -------------------------------------------------------- |
| `id`            | 在一个大的查询语句中每一个SELECT关键字都对应一个唯一的id |
| `select_type`   | SELECT关键字对应的那个查询的类型                         |
| `table`         | 表名                                                     |
| `partitions`    | 匹配的分区信息                                           |
| **`type`**      | 针对单表的访问方法                                       |
| `possible_keys` | 可能用到的索引                                           |
| `key`           | 实际上用到的索引                                         |
| **`key_len`**   | 实际使用到的索引长度                                     |
| `ref`           | 当使用索引列等值查询时，与索引列进行等值匹配的对象信息   |
| **`rows`**      | 预估的需要读取的记录条数                                 |
| `filtered`      | 某个表经过所有条件过滤后剩余记录条数的百分比             |
| **`Extra`**     | 一些额外的信息                                           |



### 3、数据准备

1. **建表**

```sql
CREATE TABLE s1 (
 id INT AUTO_INCREMENT,
 key1 VARCHAR(100),
 key2 INT,
 key3 VARCHAR(100),
 key_part1 VARCHAR(100),
 key_part2 VARCHAR(100),
 key_part3 VARCHAR(100),
 common_field VARCHAR(100),
 PRIMARY KEY (id),
 INDEX idx_key1 (key1),
 UNIQUE INDEX idx_key2 (key2),
 INDEX idx_key3 (key3),
 INDEX idx_key_part(key_part1, key_part2, key_part3)
) ENGINE=INNODB CHARSET=utf8;
 
 
 
CREATE TABLE s2 (
 id INT AUTO_INCREMENT,
 key1 VARCHAR(100),
 key2 INT,
 key3 VARCHAR(100),
 key_part1 VARCHAR(100),
 key_part2 VARCHAR(100),
 key_part3 VARCHAR(100),
 common_field VARCHAR(100),
 PRIMARY KEY (id),
 INDEX idx_key1 (key1),
 UNIQUE INDEX idx_key2 (key2),
INDEX idx_key3 (key3),
 INDEX idx_key_part(key_part1, key_part2, key_part3)
) ENGINE=INNODB CHARSET=utf8;
```

创建的两张表字段其实完全一致，均有8个字段，5个索引，一个主键索引、两个普通单列索引，一个唯一索引以及一个联合索引。



2. **设置参数log_bin_trust_function_creators**

创建函数，假如报错，需开启如下命令：允许创建函数设置： 

```sql
set global log_bin_trust_function_creators=1;   # 不加global只是当前窗口有效。
```



3. **创建函数**

创建一个随机生成字符串的函数：

```sql
DELIMITER //
 CREATE FUNCTION rand_string1(n INT) 
RETURNS VARCHAR(255) #该函数会返回一个字符串
BEGIN 
DECLARE chars_str VARCHAR(100) DEFAULT 
'abcdefghijklmnopqrstuvwxyzABCDEFJHIJKLMNOPQRSTUVWXYZ';
 DECLARE return_str VARCHAR(255) DEFAULT '';
 DECLARE i INT DEFAULT 0;
 WHILE i < n DO
 SET return_str =CONCAT(return_str,SUBSTRING(chars_str,FLOOR(1+RAND()*52),1));
 SET i = i + 1;
 END WHILE;
 RETURN return_str;
 END //
 DELIMITER ;
```



4. **创建存储过程**

创建往s1表中插入数据的存储过程：

```sql
DELIMITER //
 CREATE PROCEDURE insert_s1 (IN min_num INT (10),IN max_num INT (10))
 BEGIN
 DECLARE i INT DEFAULT 0;
 SET autocommit = 0;
 REPEAT
 SET i = i + 1;
 INSERT INTO s1 VALUES(
 (min_num + i),
 rand_string1(6),
 (min_num + 30 * i + 5),
 rand_string1(6),
 rand_string1(10),
 rand_string1(5),
 rand_string1(10),
 rand_string1(10));
 UNTIL i = max_num
 END REPEAT;
 COMMIT;
 END //
 DELIMITER ;
```



创建往s2表中插入数据的存储过程：

```sql
DELIMITER //
 CREATE PROCEDURE insert_s2 (IN min_num INT (10),IN max_num INT (10))
 BEGIN
DECLARE i INT DEFAULT 0;
 SET autocommit = 0;
 REPEAT
 SET i = i + 1;
 INSERT INTO s2 VALUES(
 (min_num + i),
 rand_string1(6),
 (min_num + 30 * i + 5),
 rand_string1(6),
 rand_string1(10),
 rand_string1(5),
 rand_string1(10),
 rand_string1(10));
 UNTIL i = max_num
 END REPEAT;
 COMMIT;
 END //
 DELIMITER ;
```



5. **调用存储过程，往表中添加数据**

s1表数据的添加：加入1万条记录：

```sql
CALL insert_s1(10001, 10000);
```

s2表数据的添加：加入1万条记录：

```sql
CALL insert_s2(10001, 10000);
```



### 4、EXPLAIN各个列的作用

##### table

不论我们的查询语句有多复杂，里面包含了多少张表，到最后也是需要对每个表进行单表访问的，所以MySQL规定**`EXPLAIN语句输出的每一条记录都对应着某个单表的访问方法`**。

记录的table列代表着该表的表明（有时不是真实的表名字，可能是简称）。

例：

```sql
EXPLAIN SELECT * FROM s1;
```

![image-20240410142903084](.\images\image-20240410142903084.png)

```sql
EXPLAIN SELECT * FROM s1 INNER JOIN s2 ON s1.id = s2.id;
```

![image-20240410142930733](.\images\image-20240410142930733.png)

s1放在前面，称为驱动表；s2放在后面，称为被驱动表。



##### id

**`在一个大的查询语句中，实际执行几个SELECT，就有几个id`**

在一般情况下，我们可以理解为有几个SELECT语句，就有几个id。

但是，优化器可能会为我们修改SELECT的执行方式，比如对于子查询来说，因为子查询的效率不如多表连接查询的效率高，所以优化器有可能会将子查询转变为多表连接查询，此时就会将两个SELECT转变成1个SELECT，id值也会从两个变为1个。

即：**查询优化器可能对涉及子查询的查询语句进行重写，转变为多表查询的操作。**



**案例1：**

```sql
EXPLAIN SELECT * FROM s1 INNER JOIN s2;
```

![image-20240410144344508](.\images\image-20240410144344508.png)

这个很简单，有两个表所以有两条记录，一个SELECT，所以只有一个id值为1。s1为驱动表，s2为被驱动表。



```sql
EXPLAIN SELECT * FROM s1 WHERE key1 IN (SELECT key1 FROM s2) OR key3 = 'a';
```

![image-20240410144511892](.\images\image-20240410144511892.png)

两个表s1和s2，出现了一个子查询，有两个SELECT，所以有两条记录和两个id。



**案例2：**

```sql
EXPLAIN SELECT * FROM s1 WHERE key1 IN (SELECT key2 FROM s2 WHERE common_field = 'a');
```

对于这个查询语句来说，一般思考是有两个表，两个SELECT，是不是就有两条记录，两个id呢？我们来看看查询结果：

![image-20240410145039196](.\images\image-20240410145039196.png)

有两条记录不假，因为涉及到了两个表，s1为驱动表，s2为被驱动表。

但是id值只有1个。

为什么会出现这种情况？

原本的查询是外部一个查询，内部一个子查询，相当于外部执行了一次，内部就会执行n次，时间复杂度是O(n²)。

优化器对原本的查询进行了重写，改造成了多表连接的方式，相当于执行一次，左右两个表各执行一次，共两次，时间复杂度变为了O(2n)。

效率更高了，那么实际的SELECT也就变为了一个，所以id只有1个值。

优化器相当于改造成了：

```sql
SELECT s1* FROM s1 INNER JOIN s2 ON s1.key1 = s2.key2 WHERE s2.common_field = 'a';
```



**案例3：**

```sql
EXPLAIN SELECT * FROM s1 UNION SELECT * FROM s2;
```

![image-20240410150055004](.\images\image-20240410150055004.png)

首先，有两个SELECT，两个id，没有问题。

但是明明只有两张表，为什么结果有3个记录呢？

因为UNION操作是取并集，将前面的查询语句与后面的查询语句合起来，并去重。对于上例来说，实际上就是将SELECT * FROM s1和SELECT * FROM s2加起来，然后对其进行去重操作。此时，将这两个查询结果加起来，就会产生一个临时表，那么结果中的第三个结果，其实就是这个临时表，Extra列中的`Using temporary`也能够表示这个表是一个临时表，表名是<union1,2>。

即：**使用UNION联合查询，会产生一个临时表，这个临时表就是去重之前的，前后表加起来的临时表。**



**案例4：**

```sql
EXPLAIN SELECT * FROM s1  UNION ALL SELECT * FROM s2;
```

这里使用的是UNION ALL，UNION ALL并不会去重，此时也就没有临时表，那么查询结果中的也就没有第三个结果临时表出现。

![image-20240410153135818](.\images\image-20240410153135818.png)



> **说明：**
>
> * **`id如果相同，可以认为是一组，从上往下顺序执行。`**
> * **`在所有组中，id值越大，优先级越高，越先执行`**
> * **`关注点：id号每个号码，表示一趟独立的查询，sql的查询趟数越少越好`**



##### select_type

一条大的查询语句里面可以包含若干个SELECT关键字，`每个SELECT关键字代表着一个小的查询语句`，而每个SELECT关键字的FROM子句中都可以包含若干张表（这些表用来做连接查询），每一张表都对应着执行计划输出中的一条记录，对于在同一个SELECT关键字中的表来说，它们的id值是相同的。

MySQL为每一个SELECT关键字代表的小查询都定义了一个称之为`select_type`的属性，意思是只要我们知道了某个小查询的select_type属性，就可以知道这个`小查询在整个大查询中扮演了一个什么样的角色`。

**`select_type的值表示这个查询的角色。`**

**所有取值：**

* SIMPLE
* PRIMARY
* UNION
* UNION RESULT
* SUBQUERY
* DEPENDENT SUBQUERY
* DEPENDENT UNION
* DERIVED
* MATERIALIZED
* UNCACHEABLE SUBQUERY
* UNCACHEABLE UNION

DEPENDENT意思是有相关性的。



**具体分析如下:**

* **`SIMPLE`**

  查询语句中不包含UNION或子查询的查询，都算作是`SIMPLE`类型

例如：

```sql
EXPLAIN SELECT * FROM s1;
```

![image-20240410163340090](.\images\image-20240410163340090.png)

连接查询也算是SIMPLE类型

```sql
EXPLAIN SELECT * from s1 INNER JOIN s2;
```

![image-20240410163357609](.\images\image-20240410163357609.png)



* **`PRIMARY`**

  在进行`UNION操作`或者`包含子查询`（无法转换成多表连接）的查询语句中，主表的select_type就是`PRIMARY`。



* **`UNION`**与**`UNION RESULT`**

  对于包含UNION或UNION ALL的大查询来说，其中除了最左边的小查询以外，其余的小查询的select_type值就是`UNION`。

  当使用UNION查询来进行去重操作时，生成的临时表select_type就是`UNION RESULT`。

例如：

```sql
EXPLAIN SELECT * FROM s1 UNION SELECT * FROM s2;
```

![image-20240410164357056](.\images\image-20240410164357056.png)



```sql
EXPLAIN SELECT * FROM s1 UNION ALL SELECT * FROM s2;
```

![image-20240410164421753](.\images\image-20240410164421753.png)





* **`SUBQUERY`**与**`DEPENDENT SUBQUERY`**

  如果包含子查询的查询语句不能转变为对应的多表连接形式（优化器会转变为性能更佳的多表链接），并且该子查询是不相关子查询，该子查询的第一个SELECT关键字代表的那个查询的select_type就是`SUBQUERY`。

  如果包含子查询的查询语句不能转为对应的多表连接形式，并且该子查询是相关子查询，则该子查询的第一个SELECT关键字代表的那个查询的select_type就是`DEPENDENT SUBQUERY`。

例如：

```sql
EXPLAIN SELECT * FROM s1 WHERE key1 IN (SELECT key1 FROM s2) OR key3 = 'a';
```

![image-20240410164939018](.\images\image-20240410164939018.png)

此时的子查询是不相关子查询，即外部没有数据传入到子查询中。

此时，内部子查询的表的select_type值就是SUBQUERY。



```sql
EXPLAIN SELECT * FROM s1 WHERE key1 IN (SELECT key1 FROM s2 WHERE s1.key2 = s2.key2) OR key3 = 'a';
```

![image-20240410165228364](.\images\image-20240410165228364.png)

由于该查询的子查询属于相关子查询（外部字段传入到内部中），所以子查询的表s2的select_type类型是DEPENDENT SUBQUERY。

注意的是，select_type为`DEPENDENT SUBQUERY`的查询可能会被执行多次。因为关联子查询是，外部传入一个数据，内部执行一次返回；外部又传入一个数据，内部再执行一次返回......



* **`DEPENDENT UNION`**

  在包含UNION或UNION ALL的大查询中，如果各个小子查询都依赖于外层查询的话，那除了最左边那个小查询之外（最左边的小查询select_type是`DEPENDENT SUBQUERY`），其余的小查询的select_type值都是`DEPENDENT UNION`。

案例：

```sql
EXPLAIN SELECT * FROM s1 
WHERE key1 IN (
	SELECT key1 FROM s2 WHERE key1 = 'a' 
	UNION 
	SELECT key1 FROM s1 WHERE key1 = 'b'
);
```

![image-20240410170343781](.\images\image-20240410170343781.png)

这里有个疑问啊：第一个和第四个结果我们可以理解，第一个查询表的select_type为PRIMARY，是因为它是主表，存在UNION与子查询；第四个查询表的select_type为UNION RESULT，是因为它是UNION的临时表。

但是为什么第二个结果和第三个结果的select_type中包含DEPENDENT呢？这个大查询明明没有相关性啊（明明外部查询没有列传入）？

这实际上，还是因为优化器对SQL进行了改造。优化器经常将IN改造成EXISTS。EXISTS就需要将外部的列传入到子查询中。

即，将上述的SQL改成了：

```sql
EXPLAIN SELECT * FROM s1 a
WHERE EXISTS (
	SELECT b.* FROM s2 b 
    WHERE b.key1 = 'a' AND b.key1 = a.key1
    
	UNION 
    
	SELECT c.* FROM s1 c 
    WHERE c.key1 = 'b' AND c.key1 = a.key1
);
```

这样实际上就是将外层的列传入到内部中了。

此时，由于在内层中，第二个查询位于UNION最左边，所以它的select_type为DEPENDENT SUBQUERY。

第三个查询不是位于UNION的最左边，它的select_type为DEPENDENT UNION。



* **`DERIVED`**

  对于包含派生表的查询，派生表原本的查询select_type是`DERIVED`。

案例：

```sql
EXPLAIN SELECT * FROM (SELECT key1, COUNT(*) AS c FROM s1 GROUP BY key1) AS derived_s1 WHERE c > 1;
```

![image-20240410172251957](.\images\image-20240410172251957.png)

查询的结果，作为另一个查询的表来使用（FROM），那么这个查询的结果就叫做**派生表**。比如说上例中，我们会先去执行`SELECT key1, COUNT(*) AS c FROM s1 GROUP BY key1`，将这个结果作为外部查询的SELECT表来使用，这整个结果就是一个派生表。

所以，第二个结果的select_type为DERIVED，table为s1表示该查询使用的是s1表。

外部的查询，table是<derived2>，表示以id为2的查询表作为派生表进行查询。





* **`MATERIALIZED`**

  当查询优化器在执行包含子查询的语句时，选择将子查询物化之后与外层查询进行连接查询时，该子查询对应的select_type属性就是MATERIALIZED。

物化？什么是物化？

我们来看一个例子：

```sql
SELECT * FROM s1 WHERE key1 IN (SELECT key1 FROM s2); 
```

这个查询语句，简化之后，其实就是将s1中的key1与s2中的key1进行比对，那么实际上，我们都不需要去考虑s2中的其他字段，只需要考虑key1字段就行。

这实际上就是物化。

对于上例中，优化器会只将s2表中的key1列拿出来，单独看作一个表，让s1中的key1列与其作比较，这就是物化。

我们来看看EXPLAIN这段代码的结果：

```sql
EXPLAIN SELECT * FROM s1 WHERE key1 IN (SELECT key1 FROM s2); 
```

![image-20240410175226190](.\images\image-20240410175226190.png)

这里实际上，就是将s2表物化，抽取出其中的key1列作为一个新的表，也就是结果中的<subquery2>，表示抽取出id为2的表中的key1。

那么原SQL就会变成：

SELECT * FROM s1 key1 IN s2.key1。





##### partitions（略）

分区



##### type:star:

type表示的是**`访问方法`**。

执行计划的一条记录就代表着MySQL对某个表的执行查询时的访问方法，又称"访问类型"，其中的type列就表明了这个访问方法是啥，是较为重要的一个指标。比如，看到type列的值是ref，表明MySQL即将使用ref访问方法来执行对s1表的访问。

完整的访问方法如下：`system`，`const`，`eq_ref`，`ref`，`fulltext`，`ref_or_null`，`index_merge`，`unique_subquery`，`index_subquery`，`range`，`index`，`ALL`。

> **`访问方式越在前面，访问的方式越好，效率越高。`**

我们来详细解释一下：

* **`system`**

  当表中`只有一条记录`，并且该表使用的`存储引擎的统计数据是精准的`，比如MyISAM、Memory，那么对该表的访问方法是**`system`**。比方说我们新建一个MyISAM表，并为其插入一条记录：

  ```sql
  CREATE TABLE t(i int) Engine=MyISAM;
  
  INSERT INTO t VALUES(1);
  ```

  然后我们来看一下这个表的执行计划：

  ```sql
  EXPLAIN SELECT * FROM t;
  ```

  ![image-20240410182723567](.\images\image-20240410182723567.png)

  type类型为system的时候，效率是最高的。





* **`const`**

  当我们根据主键或唯一二级索引列与常数进行等值匹配时，对单表的访问方法就是const。

  比如：

  ```sql
  #使用主键与常数进行等值匹配
  EXPLAIN SELECT * FROM s1 WHERE id = 10005;
  ```

  ![image-20240410213632255](.\images\image-20240410213632255.png)

  ```sql
  #使用唯一二级索引列与常数值进行等值匹配，其中给key2建立了唯一索引
  EXPLAIN SELECT * FROM s1 WHERE key2 = 10066;
  ```

  ![image-20240410213818630](.\images\image-20240410213818630.png)



* **`eq_ref`**

  在链接查询时，如果被驱动表是通过主键或者唯一二级索引列等值匹配的方式进行访问的（如果该主键或者唯一二级索引是联合索引的话，所有的索引列都必须进行等值比较），则对该被驱动表的访问就是`eq_ref`。

  例如：

  ```sql
  EXPLAIN SELECT * FROM INNER JOIN s2 ON s1.id = s2.id;
  ```

  此时，s2的访问方式就是eq_ref：

  ![image-20240410215152983](.\images\image-20240410215152983.png)



* **`ref`**

  当通过普通的二级索引与常量进行等值匹配来查询某个表，那么对该表的访问方法就可能是`ref`。

  例如：

  ```sql
  EXPLAIN SELECT * FROM s1 WHERE key1 = 'a';
  ```

  ![image-20240410220736728](.\images\image-20240410220736728.png)



* **`fulltext`**

  全文索引



* **`ref_or_null`**

  当对普通二级索引进行等值匹配，该索引列的值也可以是NULL值时，那么对该表的访问方式就可能是`ref_or_null`。其实就相当于在ref的基础上加一个null值匹配。

  例如：

  ```sql
  EXPLAIN SELECT * FROM s1 WHERE key1 = 'a' OR key1 IS NULL;
  ```

  ![image-20240410221219585](.\images\image-20240410221219585.png)





* **`index_merge`**

  单表访问方法时，在某些场景下可以使用Intersection、Union、Sort-Union这三种索引合并的方式来执行查询。

  案例：

  ```sql
  EXPLAIN SELECT * FROM s1 WHERE key1 = 'a' OR key3 = 'a';
  ```

  执行结果：

  ![image-20240410221747188](.\images\image-20240410221747188.png)

  由于key1有索引，key3也有索引，并且它们之间使用了`OR`进行连接，表示将key1='a'与key3='a'的结果合并起来，相当于UNION，即将两者的结果都查出来然后合并。

  这个时候，优化器采用的是将二者的**索引合并**的方式对两个判断的结果都进行查询，所以type类型是`index_merge`。

  如果这里的两个判断条件使用的是AND进行连接，表示两个条件都需要满足，此时就只会使用一个index索引去查询，此时的type就会变成是ref。

  

  

* **`unique_subquery`**

  针对一些包含IN子查询的查询语句中，如果查询优化器决定将IN子查询转换为EXISTS子查询，而且子查询可以使用到主键进行等值匹配的话，那么该子查询执行计划的type列的值就是`unique_subquery`。

  例如：

  ```sql
  EXPLAIN SELECT * FROM s1
  WHERE key2 IN (
  	SELECT id
  	FROM s2
  	WHERE s1.key1 = s2.key1
  ) OR key3 = 'a';
  ```

  查询优化器，就将上述的IN转换成了EXISTS语句：

  ```sql
  SELECT * FROM s1
  WHERE EXISTS (
  	SELECT *
  	FROM s2
  	WHERE s1.key1 = s2.key1
  	AND s1.key2 = s2.id
  ) OR key3 = 'a';
  ```

  由于在子查询中，使用到了s2表中的id进行匹配，使用到了主键索引，那么此时的s2的访问方式就变成了`unique_subquery`。

  ![image-20240410222935247](.\images\image-20240410222935247.png)

  看上面的表，回顾一下：第二条记录中select_type为DEPENDENT SUBQUERY，原因在于使用了关联子查询。key可以看到是PRIMARY，即子查询使用了主键索引。type值是unique_subquery，就是因为上面的原因，转换成了EXISTS子句，并且在子查询中使用到了主键索引。





* **`rang`**

  如果使用索引获取某些范围区间的记录，那么就可能使用到`rang`访问方法。

  案例：

  ```sql
  EXPLAIN SELECT * FROM s1 WHERE key1 IN ('a','b','c');
  ```

  ![image-20240410223635771](.\images\image-20240410223635771.png)

  ```sql
  EXPLAIN SELECT * FROM s1 WHERE key1 > 'a' AND key1 < 'b';
  ```

  ![image-20240410223708156](.\images\image-20240410223708156.png)



* **`index`**

  当我们可以使用索引覆盖，但需要扫描全部的索引记录时，该表的访问记录就是index。

  例如：

  ```sql
  EXPLAIN SELECT key_part2 FROM s1 WHERE key_part3 = 'a';
  ```

  ![image-20240410224421808](.\images\image-20240410224421808.png)

  **对于type值为index值的解释：**

  数据表中有一个联合索引idx_key_part(key_part1, key_part2, key_part3)，如果单独去使用key_part3 = 'a'筛选的时候，实际上是用不了这个索引的，因为在一般情况下，只有查询条件中使用了这三个字段的第一个字段（也就是key_part1）时才会被使用。

  但是，由于需要查询的字段key_part2，也是联合索引的一部分，那么此时，就会去使用到联合索引了，我们也可以从上图的key列值为idx_key_part得出这个信息。

  使用联合索引去遍历一遍，根据key_part3的条件，获取key_part2的值。

  又因为，这个筛选条件key_part3实际上是在联合索引的第三个位置，索引是根据key_part1的值进行排列的，所以我们无法根据索引前面记录中key_part3的值来判断后面key_part3的值，即无法根据前面的key_part3是否是'a'来判断后面的key_part3中的值。

  所以当我们使用索引去遍历记录获取记录数据时，需要把索引中全部的记录都进行遍历，判断key_part3的值并获取key_part2的值。

  **什么是索引覆盖？**

  简单来说，就是使用到的联合索引，不需要进行回表操作，就能够查询到我们想要的数据。

  在上例中，我们使用到了idx_key_part联合索引，由于想要查询的数据key_part2在索引的记录中，此时就不需要回到聚簇索引中再进行查询，而可以直接得到我们想要的数据。这就是索引覆盖。

  



* **`ALL`**

  对表中所有数据都遍历了一遍，type值就是ALL。



> **要求：**
>
> **结果值从最好到最坏依次是**：`system > const > eq_ref > ref > fulltext > ref_or_null > index_merge > unique_subquery > index_subquery > range > index > ALL`
>
> **SQL性能优化的目标：**至少要达到**`range`**级别，要求是**`ref`**级别，最好是**`consts`**级别。





##### possible_key和key

在EXPLAIN语句输出的执行计划中，**`possible_keys`**列表示在某个查询语句中，某个表执行`单表查询时可能用到的索引有哪些`。一般查询涉及到的字段上若存在索引，则将该索引列出，但不一定被查询使用。

**`key`**列表示`实际用到的索引有哪些`，如果为NULL，表示没有用到索引，比如：

```sql
EXPLAIN SELECT * FROM s1 WHERE key1 > 'z' AND key3 = 'a';
```

![image-20240410233249821](.\images\image-20240410233249821.png)

上述执行计划的possible_keys列的值是idx_key1，idx_key3，表示查询可能使用到idx_key1，idx_key3两个索引，然后key列的值是idx_key3，表示经过查询优化器计算使用不同索引的成本后，最后决定使用idx_key3.

**优化器会去选择成本最低的索引执行，注意，这里的成本最低并不是指花费的时间最低。**

注意：有可能出现possible_keys中没有索引，但是key出现索引的情况，优化器去优化SQL，将SQL转变为可以使用索引的情况。





##### key_len:star:

**主要针对于`联合索引`有一定的参考意义。**

该参数，存储的是使用到的索引中的记录，可能所占的字节数。

这个参数，对单列索引的参考意义不大，我们实际上是想通过这个索引，让我们了解到实际使用到联合索引中的几个列，使用列的数目越多越好。





**例如：**

```sql
EXPLAIN SELECT * FROM s1 WHERE id = 10005;
```

![image-20240411093525931](.\images\image-20240411093525931.png)

这里的key_len为什么是4呢？

原因在于这个查询，使用到的是主键索引，主键是INT类型，INT类型占用4个字节。所以这里的一个`索引记录占用4个字节`。



**再比如：**

```sql
EXPLAIN SELECT * FROM s1 WHERE key2 = 10126;
```

![image-20240411093809768](.\images\image-20240411093809768.png)

这里有问题了，key2也是INT类型，但是为什么key_len是5呢？

原因在于key2使用的是UNIQUE索引，与id不同的是，key2有可能为空，所以记录中还需要存放NULL值列表，所以这里的5是key2`记录所占的字节数 + NULL值列表所占的字节数1`，一共是5个字节。



**再比如：**

```sql
EXPLAIN SELECT * FROM s1 WHERE key1 = 'a';
```

![image-20240411094441401](.\images\image-20240411094441401.png)

这里为什么是303，303怎么来的？

key1是varchar(100)类型，由于此时没有实际上去执行SELECT语句，所以虽然我们知道实际上并没有占用那么多空间，这个值实际上是一个最大值，就算我们知道要通过'a'字符去遍历key1的索引时，只需要考虑第一个字符，但是优化器并没有实际上去执行查询，而是假设varchar(100)中，真有100个字符。

所以，100 * 3 = 300，其中的300就是varchar字符所占用的地址。

另外的3呢？因为varchar是可变长度字符，所以有2个字符是`变长字段长度列表`所占用，1个字符是`NULL值列表`所占用。



但其实，上面三种情况的key_len没有参考意义，因为都是和自己比较。

**接下来，我们看看最后一种情况（重要）：**

```sql
EXPLAIN SELECT * FROM s1 WHERE key_part1 = 'a';
 
EXPLAIN SELECT * FROM s1 WHERE key_part1 = 'a' AND key_part2 = 'b';

EXPLAIN SELECT * FROM s1 WHERE key_part1 = 'a' AND key_part2 = 'b' AND key_part3 = 'c';
```

在表中，有一个联合索引：idx_key_part(key_part1, key_part2, key_part3)。

上述查询的结果分别为：

![image-20240411095608749](.\images\image-20240411095608749.png)

![image-20240411095526321](.\images\image-20240411095526321.png)

![image-20240411095547124](.\images\image-20240411095547124.png)

因为第一个查询中，使用到了key_part1与索引的第一个字段进行匹配

第二个查询中，使用到了key_part1和key_part2与索引的两个字段进行匹配

第三个查询中，使用到了key_part1、key_part2和key_part3与索引的三个字段进行匹配

此时，key_len值越大越好（即进行匹配的字段越多越好），因为在于进行匹配的字段越多，数据就越精准，获取的索引页也就越少，效率也就越高。





由上我们可知：

**`在联合索引中，key_len的值越高，就说明进行匹配的字段越多，数据就越精准，获取的索引页就越少，效率就越高。`**

同时我们也知道了key_len的值如何计算，比如：

1、使用可以为空的INT字段作为索引列，key_len = 4字节(INT占用长度) + 1字节(NULL值列表) = 5。

2、varchar(10)且允许NULL，key_len =10 * ( character set：utf8=3,gbk=2,latin1=1) + 1(NULL) + 2(变长字段)。



##### ref

当使用索引列等值查询时，与索引列进行等值匹配的对象信息。

比如只是一个常数或者是某个列。

案例：

```sql
EXPLAIN SELECT * FROM s1 WHERE key1 = 'a';
```

![image-20240411105211010](.\images\image-20240411105211010.png)

此时，与索引列key1进行等值匹配的值是'a'，是一个常量，ref的值就是const。



```sql
EXPLAIN SELECT * FROM s1 INNER JOIN s2 ON s1.id = s2.id;
```

![image-20240411105301189](.\images\image-20240411105301189.png)

上面SQL，是将s1表全表进行扫描，然后根据s1的id与s2的id进行匹配，使用了s1的id作为等值查询与s2的主键索引进行匹配的列，所以s2的ref为atguigudb1.s1.id。（s1的ref没有值，因为s1没有使用到索引，进行的是全表扫描）



```sql
EXPLAIN SELECT * FROM s1 INNER JOIN s2 ON s2.key1 = UPPER(s1.key1);
```

![image-20240411105536634](.\images\image-20240411105536634.png)

这里s2的索引key1，使用到的等值匹配是一个函数UPPER()，所以ref的值是func。





##### rows:star:

MySQL估算会扫描的行数。**`值越小越好`**

经常结合filtered一起使用。

如果查询使用到了索引，rows表示对索引扫描的行数；

如果查询是全表扫描，则rows表示该表的行数。

比如：

```sql
EXPLAIN SELECT * FROM s1 WHERE key1 > 'z';
```

![image-20240411110800125](.\images\image-20240411110800125.png)

这里使用了idx_key1索引。

这个404表示什么含义呢？

这个404，表示在索引中，要扫描404行，也就是说，索引是按照字段的大小进行排序的，其中key1索引列中，大于'z'的记录数一共有404条，即会扫描404行。



##### filtered

表示符合查询条件的数据百分比，最大100。

经常结合rows一起使用。

如果使用的是索引执行的单表扫描，那么计算时需要估计出满足除使用到对应索引的搜索条件外的其他搜索条件的记录有多少条。

例如：

```sql
EXPLAIN SELECT * FROM s1 WHERE key1 > 'z' AND common_field = 'a';
```

![image-20240411112055164](.\images\image-20240411112055164.png)

这里使用的索引是idx_key1索引，404表示的含义就是满足key1 > 'z'条件的idx_key1索引中的行数。

而这里的10表示什么含义？10表示在404的基础上，满足common_field='a'条件的行数，大约占404行的百分比，即大约有40行数据也是满足common_field='a'条件的。（这里是大约，有可能没有）



**对于单表查询，这个filtered列的值没有什么意义。**

我们更加关注在链接查询中，`驱动表`对应的执行计划记录的`filtered`的值，它决定了`被驱动表执行的次数`（即：**`rows * filtered`**）。

案例：

```sql
EXPLAIN 
SELECT * 
FROM s1 
INNER JOIN s2 ON s1.key1 = s2.key1
WHERE s1.common_field = 'a';
```

![image-20240411112552847](.\images\image-20240411112552847.png)

这个查询操作，首先会对s1表进行扫描，由于s1表没有使用到索引，所以预估对s1表实行全表扫描，此时rows表示s1的行数。

filtered是10，表示满足筛选条件的行数占总的要扫描数的百分比，这里预估是10%。

执行上面的SQL大致步骤：

对s1表进行扫描，然后对其中的数据进行筛选，筛选后，取出s1表中的一行数据，与s2表中的idx_key1索引进行比较筛选，筛选比较后再取出s1表中的一行数据与s2的索引比较......

其中，`rows * filtered`的值大致是被驱动表s2执行比较的次数。



##### Extra:star:

`Extra`列是用来说明一些额外信息的，包含不适合在其他列中显示但十分重要的额外信息。我们可以通过这些额外信息`更准确的理解MySQL到底如何执行给定的查询语句`。MySQL提供的额外信息有好几十个，这里只介绍比较重要的额外信息。

* **`Impossible where`**

  表示没有符合where条件的行。





* **`Using where`**

  有两种情况会出现Using where：

  1、当我们使用全表扫描来执行对某个表的查询时，有where筛选条件。

  2、当我们使用索引来对某个表进行查询时，where子句中包含除索引列的其他搜索条件。

  即：**当服务器对存储引擎检索行之后进行过滤时，就会有Using where。**

  例：

  ```sql
  EXPLAIN SELECT * FROM s1 WHERE common_field = 'a';
  
  EXPLAIN SELECT * FROM s1 WHERE key1 = 'a' AND common_field = 'a';
  ```

  以上两种情况都会出现Using where。



* **`Using temporary`**（重要指标）

  在许多查询的执行过程中，MySQL可能会借助临时表来完成一些功能，比如去重、排序之类的，比如我们在执行许多包含`DISTINCT`、`GROUP BY`、`UNION`等子句的查询过程中，如果不能有效利用索引来完成查询，MySQL很有可能寻求通过建立内部的**`临时表`**来执行查询，如果查询中使用到了内部的临时表，在执行计划的Extra列将会显示Using temporary提示。

  **效率较差。**

  例如：

  ```sql
  EXPLAIN SELECT DISTINCT common_field FROM s1;
  ```

  这个查询中，没有使用到索引，当我们要对其进行去重操作时，会先去将所有数据查询出来，组成一个临时表，然后再对临时表进行去重，此时Extra中就会出现Using temporary。

  ![image-20240411131441335](.\images\image-20240411131441335.png)

  再比如：

  ```sql
  EXPLAIN SELECT common_field, COUNT(*) AS amount FROM s1 GROUP BY common_field;
  ```

  由于common_field中没有索引，当使用common_field进行分组时，需要先创建一个临时表，对common_field合并。

  ![image-20240411132154025](.\images\image-20240411132154025.png)

  计划中出现Using temporary并不好，因为建立与维护临时表需要付出很大的成本，所以我们最好使用索引来替换掉使用临时表。比如：扫描指定的索引idx_key1即可。

  ```sql
  EXPLAIN SELECT key1, COUNT(*) AS amount FROM s1 GROUP BY key1;
  ```

  ![image-20240411132630494](.\images\image-20240411132630494.png)





* **`Using filesort`**（重要指标）

  在很多情况下，排序操作无法使用到索引进行排序，只能在内存中或者磁盘中进行排序，MySQL把这种在内存或者磁盘上进行排序的方式统称为**`文件排序`**（`filesort`）。**文件排序的性能较低。**

  如果某个查询需要使用到文件排序的方式执行查询，就会在执行计划的Extra列中显示`Using filesort`。

  例如：

  ```sql
  EXPLAIN SELECT * FROM s1 ORDER BY common_field LIMIT 10;
  ```

  由于common_field没有创建索引，此时该查询不会使用到索引，只能使用文件排序。

  ![image-20240411124416561](.\images\image-20240411124416561.png)

  再比如：

  ```sql
  EXPLAIN SELECT * FROM s1 ORDER BY key1 LIMIT 10;
  ```

  由于key1是创建了索引的，当我们需要排序时，直接使用key1索引的顺序即可，此时就不会使用文件索引。

  ![image-20240411124521014](.\images\image-20240411124521014.png)



* **`Using index`**（重要指标）

  当我们的查询列表以及搜索条件中只包含属于某个索引的列，也就是在可以使用**覆盖索引**的情况下，在Extra列会提示该额外信息。出现该指标表示**`效率不错`。**

  例如：

  ```sql
  EXPLAIN SELECT key1,id FROM s1 WHERE key1 = 'a';
  ```

  s1表中存在key1的索引。

  执行上面的查询语句，会使用到key1的索引去获取数据，由于我们只需要查询得到key1和id的值，这两个值在key1的索引中都会存储，我们可以直接从索引中获取值数据，而不需要再去聚簇索引中获取数据（回表），就称之为索引覆盖。

  ![image-20240411120433969](.\images\image-20240411120433969.png)



* **`Using index condition`**

  表示使用索引的条件。

  出现这个信息，表示优化器对执行的SQL处理进行了如下的优化操作：

  查询中有两个筛选条件，一个使用到了索引，一个未使用到索引。原先使用使用到的索引的筛选条件，在索引中对数据进行了扫描筛选，将筛选后的数据回表，在聚簇索引中再使用未使用到索引的筛选条件进行筛选。

  但是，优化器对其进行了优化，未使用到索引的筛选条件也在二级索引中进行了筛选操作，减少了回表操作的记录数，提高了效率。因为回表的效率较低。
  
  例如：

  ```sql
  EXPLAIN SELECT * FROM s1 WHERE key1 > 'z' AND key1 LIKE '%a';
  ```

  ![image-20240411193817922](.\images\image-20240411193817922.png)

  其中key1使用到了索引。
  
  在上例中，`key1 > 'z'`可以使用到索引，但是`key1 LIKE '%a'`却无法使用到索引，在以前版本的MySQL中，是按照下边步骤来执行这个查询的：
  
  * 先根据`key1 > 'z'`这个条件，从二级查询idx_key1中获取到对应的二级索引记录。
  * 根据上一步骤得到的二级索引记录中的主键值进行**`回表`**，找到完整的用户记录再检测该记录是否符合key1 LIKE '%a'这个条件，将符合条件的记录加入到最后的结果集。
  
  但是虽然key1 LIKE '%a'不能组成范围区间参加range访问方法的执行，但这个条件毕竟只涉及到了key1列，所以MySQL把上面的步骤修改了一下：

  * 先根据`key1 > z`这个条件，定位到二级索引`idx_key1`对应的二级索引记录。
  * 对于指定的二级索引记录，先不着急回表，而是先检测一下该记录是否满足`key1 LIKE '%a'`这个条件，如果这个条件不满足，则该二级索引记录压根儿没有必要回表。
  * 对于满足`key1 LIKE '%a'`这个条件的二级索引记录了执行回表操作。
  
  我们说**回表操作其实是一个`随机IO`**，比较耗时，所以上述修改只改进了一点点，但是，能够减少很多个记录回表操作，就减少了很多回表的成本。MySQL把这个改进称之为**`索引条件下推`**。在Extra列中显示Using index condition。



* **`Using join buffer`**

  在连接查询过程中，当被驱动表不能有效的利用索引加快访问速度，MySQL一般会为其分配一块名为`join buffer`的内存块来加快查询速度，也就是我们所讲的基于块的嵌套循环算法。

  例如：

  ```sql
  EXPLAIN SELECT * FROM s1 INNER JOIN s2 ON s1.common_field = s2.common_field;
  ```

  连接查询中的被驱动表是s2，由于s2中的common_field中是没有索引的，为了加快查询的速度，此时MySQL会为其分配一块独立的内存，帮助其加快查询，此时EXPALIN结果中Extra就会有信息Using join buffer。

  ![image-20240411122959817](.\images\image-20240411122959817.png)

  出现Using where是因为出现了除索引外的筛选条件，也就是common_field。



* **`Not exists`**

  当我们使用左（外）连接时，如果WHERE子句中包含被驱动表的某个列等于NULL值的搜索条件，而且那个列又是不允许存储NULL值的，那么该表的执行计划的Extra列就会提示Not exists额外信息。

  ```sql
  EXPLAIN SELECT * FROM s1 LEFT JOIN s2 ON s1.key1 = s2.key1 WHERE s2.id IS NULL;
  ```

  ![image-20240411123444045](.\images\image-20240411123444045.png)



其余Extra还有很多值，上面介绍了一些比较重要的，其余的值在开发中看到了有不懂的，再百度就是了。

##### 小结

* EXPLAIN不考虑各种Cache
* EXPLAIN不能显示MySQL在执行查询时所作的优化工作

* EXPLAIN不会告诉你关于触发器、存储过程的信息或用户自定义函数对查询的影响情况
* 部分统计信息是估算的，并非精确值



##### 对覆盖索引的解释

**理解：**

select数据列只用从索引中就能够取得，不必读取数据行，MySQL可以利用索引返回select列表中的字段，而不必根据索引再次读取数据文件，换句话说**`查询列要被所建的索引覆盖`**。

**案例：**

select id,name from student where age = 18;

有一个组合索引idx_id_name_age包含了id,name和age三个字段。查询是直接将建立索引的列读取了出来，而不需要去查找所在行的其他数据。

此时的EXPLAIN结果：

![image-20240411121356164](.\images\image-20240411121356164.png)

我们可以看到type的值是index，Extra中包含Using index。

* type为index的原因：

由于使用的是联合索引，筛选条件是联合索引的第三个字段，所以，我们无法根据索引列排列的顺序去判断age的值的大小，我们只能对所有的数据进行扫描（全表扫描），但是因为使用了索引覆盖（即只需要从索引中就可以获取到所有数据），那么此时的type就不是ALL，而是index，效率比ALL高一点，不需要再去回表操作。



* Extra为Using index的原因：

使用了索引覆盖，Extra的值就包含Using index。



**注意：**

* 如果要使用索引覆盖，一定要注意select列表只取出需要的列，不可使用select * 的查询方式。
* 因为如果将所有字段一起做索引会导致索引文件过大，查询性能下降。

我们可以根据Extra列中的值为Using index表示出现了索引覆盖。



### 5、EXPLAIN各种输出格式

这里谈谈EXPLAN的输出格式。EXPLAIN可以输出四种格式：`传统格式`、`JOSN格式`、`TREE格式`以及`可视化输出`。用于可以根据需要选择适合于自己的格式。

#### 1. 传统格式

传统格式简单明了，输出是一种表格形式，概要说明查询计划。

例：

```sql
EXPLAIN SELECT s1.key1, s2.key1 FROM s1 LEFT JOIN s2 ON s1.key1 = s2.key1 WHERE s2.common_field IS NOT NULL;
```

![image-20240411150659069](.\images\image-20240411150659069.png)



#### 2. JOSN格式

> **`当我们需要去查看预估的成本时，使用JSON格式。`**

第1种格式中介绍的EXPLAIN语句输出中缺少了一个衡量执行计划好坏的重要属性——`成本`。而JSON格式是四种格式里面输出**信息最详尽**的格式，里面包含了执行的成本信息。

* JOSN格式：在EXPLAIN单词和真正的查询语句中加上**`FORMAT=JSON`**。

  ```sql
  EXPLAIN FORMAT=JSON SELECT ...
  ```

* EXPLAIN的Column与JSON的对应关系：

| Column        | JSON Name     |
| ------------- | ------------- |
| `id`          | select_id     |
| select_type   | None          |
| table         | table_name    |
| partitions    | partitions    |
| `type`        | access_type   |
| possible_keys | possible_keys |
| key           | key           |
| `key_len`     | key_length    |
| `ref`         | ref           |
| rows          | rows          |
| filtered      | filtered      |
| `Extra`       | None          |

这样我们就可以得到一个json格式的执行计划，里面包含该计划花费的成本，比如这样：

```sql
EXPLAIN FORMAT=JSON SELECT * FROM s1 INNER JOIN s2 ON s1.key1 = s2.key2 WHERE s1.common_field = 'a'\G
```

使用传统模式查询得到的数据：

![image-20240411153312948](.\images\image-20240411153312948.png)

使用JSON模式查询得到的数据：

![image-20240411151905484](.\images\image-20240411151905484.png)

上图中：

**`query_cost`**，这表示的是查询所花费的**成本**。

`rows_examined_per_scan`表示的就是`rows`，即扫描的行数

`rows_produced_per_join`表示的是`rows * filered`的值。

`cost_info`表示的是具体花费的成本信息，其中的date_read_per_join表示读取的数据量。

`used_columns`表示查询的字段

`attached_condition`表示查询的条件

其他的信息在传统模式下都有对应的字段。



接下来，我们具体地介绍一下`cost_info`成本部分是如何计算的，先来看看s1表的cost_info部分：

```json
"cost_info": {
     "read_cost": "1840.84",
     "eval_cost": "193.76",
     "prefix_cost": "2034.60",
     "data_read_per_join": "1M"
}
```

* `read_cost`是由两部分组成的：

  * IO成本
  * 检测rows x (1 - filter)条记录的CPU成本

  > rows和filter都是我们前面介绍执行计划的输出列，在JSON格式的执行计划中，rows相当于rows_examined_per_scan，filter名称不变。

* `eval_cost`是这样计算的：

  检测rows x filter条记录的成本

* `prefix_cost`就是单独查询s1表的成本，也就是:

  `read_cost + eval_cost`

* `data_read_per_join`表示在此次查询中需要读取的数据量。

对于s2表的cost_info部分是这样的：

```sql
"cost_info": {
 "read_cost": "968.80",
 "eval_cost": "193.76",
 "prefix_cost": "3197.16",
 "data_read_per_join": "1M"
}
```

由于s2表是被驱动表，所以可能被读取多次，这里的`read_cost`和`eval_cost`是访问多次s2表后累加起来的值，大家主要关注里面的`prefix_cost`的值代表的是整个连接查询预计的成本（这个值也就是整个查询预计所花费的成本，即与`query_cost`的值相等）。

也就是单次查询s1表和多次查询s2表后的成本和，也就是：

```
968.80 + 193.76 + 2034.60 = 3197.16
```





#### 3、TREE格式（了解）

TREE格式是8.0.16版本之后引入的新格式，主要根据查询的`各个部分之间的关系`和`各部分的执行顺序`来描述如何查询。

使用**`FORMAT=TREE`**表示当前的EXPLAIN使用的格式是TREE格式。

例如：

```sql
EXPLAIN FORMAT=TREE SELECT * FROM s1 INNER JOIN s2 ON s1.key1 = s2.key2 WHERE s1.common_field = 'a'\G
```

![image-20240411155823574](.\images\image-20240411155823574.png)

我们可以看到这些信息：

使用了inner join进行连接，总体的cost是1360.8，rwos表示传统模式下rows * filtered的值

Filter是筛选条件。

第三行的cost=1013.75，rows是9895，表示的是在驱动表中，所花的成本是1013.75，rows*filtered是9895.

第四行包含的信息有idx_key2（索引），index condition（Extra），还有cost信息等。



#### 4、可视化输出格式（了解）

可视化输出，可以通过MySQL Workbench可视化查看MySQL的执行计划。通过点击Workbench的放大镜图标，即可生成可视化的查询计划。





### 6、SHOW WAININGS的使用

在我们使用`EXPLAIN`语句查看某个查询的执行计划后，紧接着还可以使用`SHOW WARNINGS`语句查看与这个查询的执行计划有关的一些扩展信息。

例如：

```sql
EXPLAIN SELECT s1.key1, s2.key1 FROM s1 LEFT JOIN s2 ON s1.key1 = s2.key1 WHERE s2.common_field IS NOT NULL;
```

![image-20240411161138673](.\images\image-20240411161138673.png)

此时使用`SHOW WARNINGS`查看扩展信息：

```sql
SHOW WARNINGS\G
```

![image-20240411161241555](.\images\image-20240411161241555.png)

这里有三个字段，分别是`Level`、`Code`、`Message`。

我们不需要知道Level和Code的其他值，只需要了解Message字段的信息：

**`Message`**字段展示的信息，就是执行器真正执行的SQL语句。优化器会给我们的查询语句进行优化重写。比如上边原本如果s2中有key1与s1中的key1没有等值关系时，是不保留的，但是会将s1中的所有数据全部保留，这是因为左外连接的关系。但是因为有了s2.common_field IS NOT NULL的条件，则会将s1中不匹配的关系也去除，这就相当于使用的是INNER JOIN，即保留的是两个表中都符合ON连接的数据。在上例中，优化器就是将左外连接优化成为内连接查询，从该字段中可以看出，原本的LEFT JOIN已经变成了JOIN。即：**`Message`是优化器对SQL进行重写以后的语句。**





## 分析优化器执行计划：trace（了解）

`OPTIMIZER_TRACE`是MySQL5.6引入的一项跟踪功能，它可以跟踪优化器做出的各种决策（比如访问表的方法、各种开销计算、各种转换等），并将跟踪结果记录到`information_schema.optimizer_trace`表中。

此功能默认关闭。开启trace，并设置格式为JSON，同时设置trace最大能够使用的内存大小，避免解析过程中因为默认内存过小而不能够完整展示。

```sql
SET optimizer_trace="enabled=on",end_markers_in_json=on;

SET optimizer_trace_max_mem_size=1000000;
```

开启后，可以分析如下语句：

* SELECT
* INSERT
* REPLACE
* UPDATE
* DELETE
* EXPLAIN
* SET
* DECLARE
* CASE
* IF
* RETURN
* CALL

测试：执行如下SQL语句：

```sql
select * from student where id < 10;
```

查询information_schema.optimizer_trance就可以知道MySQL是如何执行SQL的：

```sql
select * from information_schema.optimizer_trance\G
```

```json
************************1. row***********************
  //第1部分：查询语句
  QUERY: select * from student where id < 10
  //第2部分：QUERY字段对应语句的跟踪信息
  TRACE: {
  "steps": [
    {
      "join_preparation": {  //预备工作
        "select#": 1,
        "steps": [
          {
            "expanded_query": "/* select#1 */ select `student`.`id` AS 
`id`,`student`.`stuno` AS `stuno`,`student`.`name` AS `name`,`student`.`age` AS 
`age`,`student`.`classId` AS `classId` from `student` where (`student`.`id` < 10)"
          }
        ] /* steps */
      } /* join_preparation */
    },
    {
      "join_optimization": {  //进行优化
        "select#": 1,
        "steps": [
          {
            "condition_processing": {   //条件处理
              "condition": "WHERE",
              "original_condition": "(`student`.`id` < 10)",
              "steps": [
                {
                  "transformation": "equality_propagation",
                  "resulting_condition": "(`student`.`id` < 10)"
                },
                {
                  "transformation": "constant_propagation",
                  "resulting_condition": "(`student`.`id` < 10)"
                },
                {
                  "transformation": "trivial_condition_removal",
                  "resulting_condition": "(`student`.`id` < 10)"
                }
              ] /* steps */
            } /* condition_processing */
          },
          {
            "substitute_generated_columns": {  //替换生成的列
            } /* substitute_generated_columns */
          },
          {
            "table_dependencies": [    //表的依赖关系
              {
                "table": "`student`",
                "row_may_be_null": false,
                "map_bit": 0,
                "depends_on_map_bits": [
                ] /* depends_on_map_bits */
              }
            ] /* table_dependencies */
          },
          {
            "ref_optimizer_key_uses": [    //使用键
            ] /* ref_optimizer_key_uses */
          },
          {
            "rows_estimation": [    //行判断
              {
                "table": "`student`",
                "range_analysis": {
                  "table_scan": {
                    "rows": 3973767,
                    "cost": 408558
                  } /* table_scan */,    //扫描表
                  "potential_range_indexes": [  //潜在的范围索引
                    {
                      "index": "PRIMARY",
                      "usable": true,
                      "key_parts": [
                        "id"
                      ] /* key_parts */
                    }
                  ] /* potential_range_indexes */,
                  "setup_range_conditions": [  //设置范围条件
                  ] /* setup_range_conditions */,
                  "group_index_range": {
                    "chosen": false,
                    "cause": "not_group_by_or_distinct"
                  } /* group_index_range */,
                  "skip_scan_range": {
                    "potential_skip_scan_indexes": [
                      {
                        "index": "PRIMARY",
                        "usable": false,
                        "cause": "query_references_nonkey_column"
                      }
                    ] /* potential_skip_scan_indexes */
                  } /* skip_scan_range */,
                  "analyzing_range_alternatives": {//分析范围选项
                    "range_scan_alternatives": [
                      {
                        "index": "PRIMARY",
                        "ranges": [
                          "id < 10"
                        ] /* ranges */,
                        "index_dives_for_eq_ranges": true,
                        "rowid_ordered": true,
                        "using_mrr": false,
                        "index_only": false,
                        "rows": 9,
                        "cost": 1.91986,
                        "chosen": true
                      }
                    ] /* range_scan_alternatives */,
                    "analyzing_roworder_intersect": {
                      "usable": false,
                      "cause": "too_few_roworder_scans"
                    } /* analyzing_roworder_intersect */
                  } /* analyzing_range_alternatives */,
                  "chosen_range_access_summary": {//选择范围访问摘要
                    "range_access_plan": {
                      "type": "range_scan",
                      "index": "PRIMARY",
                      "rows": 9,
                      "ranges": [
                        "id < 10"
                      ] /* ranges */
                    } /* range_access_plan */,
                    "rows_for_plan": 9,
                    "cost_for_plan": 1.91986,
                    "chosen": true
                  } /* chosen_range_access_summary */
                } /* range_analysis */
              }
            ] /* rows_estimation */
          },
          {
            "considered_execution_plans": [//考虑执行计划
              {
                "plan_prefix": [
                ] /* plan_prefix */,
                "table": "`student`",
                "best_access_path": {   //最佳访问路径
                  "considered_access_paths": [
                    {
                      "rows_to_scan": 9,
                      "access_type": "range",
                      "range_details": {
                        "used_index": "PRIMARY"
                      } /* range_details */,
                      "resulting_rows": 9,
                      "cost": 2.81986,
                      "chosen": true
                    }
                  ] /* considered_access_paths */
                } /* best_access_path */,
                "condition_filtering_pct": 100, //行过滤百分比
                "rows_for_plan": 9,
                "cost_for_plan": 2.81986,
                "chosen": true
              }
            ] /* considered_execution_plans */
          },
          {
            "attaching_conditions_to_tables": {  //将条件附加到表上
              "original_condition": "(`student`.`id` < 10)",
              "attached_conditions_computation": [
              ] /* attached_conditions_computation */,
              "attached_conditions_summary": [  //附加条件概要
                {
                  "table": "`student`",
                  "attached": "(`student`.`id` < 10)"
                }
              ] /* attached_conditions_summary */
            } /* attaching_conditions_to_tables */
          },
          {
            "finalizing_table_conditions": [
              {
                "table": "`student`",
                "original_table_condition": "(`student`.`id` < 10)",
                "final_table_condition   ": "(`student`.`id` < 10)"
              }
            ] /* finalizing_table_conditions */
          },
          {
            "refine_plan": [   //精简计划
              {
                "table": "`student`"
              }
            ] /* refine_plan */
          }
        ] /* steps */
      } /* join_optimization */
    },
    {
      "join_execution": {    //执行
        "select#": 1,
        "steps": [
        ] /* steps */
      } /* join_execution */
    }
  ] /* steps */
 }
 //第3部分：跟踪信息过长时，被截断的跟踪信息的字节数。
MISSING_BYTES_BEYOND_MAX_MEM_SIZE: 0   //丢失的超出最大容量的字节
//第4部分：执行跟踪语句的用户是否有查看对象的权限。当不具有权限时，该列信息为1且TRACE字段为空，一般在调用带有SQL SECURITY DEFINER的视图或者是存储过程的情况下，会出现此问题。
INSUFFICIENT_PRIVILEGES: 0   //缺失权限
1 row in set (0.00 sec)
```



## MySQL监控分析视图：sys schema

关于MySQL的性能监控和问题诊断，我们一般都从performance_schema中去获取想要的数据，在MySQL5.7.7版本中新增sys schema，它将performance_schema和information_schema中的数据以更容易理解的方式总结归纳为“视图”，其目的就是为了`降低查询performance_schema的复杂度`，让DBA能够快速定位问题。

**Sys schema的使用：**

下面所有的SQL直接使用即可。

**`索引情况`**

```sql
#1. 查询冗余索引
select * from sys.schema_redundant_indexes;
#2. 查询未使用过的索引
select * from sys.schema_unused_indexes;
 #3. 查询索引的使用情况
select index_name,rows_selected,rows_inserted,rows_updated,rows_deleted from sys.schema_index_statistics where table_schema='dbname' ;
```



**`表相关`**

```sql
# 1. 查询表的访问量
select table_schema, table_name, sum(io_read_requests+io_write_requests) as io from 
sys.schema_table_statistics group by table_schema, table_name order by io desc;

 # 2. 查询占用buffer pool较多的表
select object_schema,object_name, allocated, data 
from sys.innodb_buffer_stats_by_table order by allocated limit 10;

 # 3. 查看表的全表扫描情况
select * from sys.statements_with_full_table_scans where db='dbname';
```



**`语句相关`**

```sql
#1. 监控SQL执行的频率
select db,exec_count,query from sys.statement_analysis 
order by exec_count desc;

#2. 监控使用了排序的SQL
select db,exec_count, first_seen, last_seen,query from sys.statements_with_sorting limit 1;

#3. 监控使用了临时表或者磁盘临时表的SQL
select db, exec_count, tmp_tables, tmp_disk_tables, query from sys.statement_analysis where tmp_tables>0 or tmp_disk_tables >0 order by (tmp_tables+tmp_disk_tables) desc;
```



**`IO相关`**

```sql
#查看消耗磁盘IO的文件
select file, avg_read, avg_write, avg_read+avg_write as avg_io from sys.io_global_by_file_by_bytes order by avg_read limit 10;
```



**`InnoDB相关`**

```sql
#行锁阻塞情况
select * from sys.innodb_lock_waits;
```



> 风险提示：
>
> 通过sys库去查询时，`MySQL会消耗大量资源去收集相关信息`，严重的可能会导致业务请求被阻塞，从而引起故障。建议生产上不要频繁的区查询sys或者performance_schema、information_schema来完成监控、巡查等工作。







---

# 二、索引优化与查询优化

虽然SQL查询优化的技术有很多，但是大方向上完全可以分成`物理查询优化`和`逻辑查询优化`两大块。

* 物理查询优化是通过`索引`和`表连接方式`等技术来进行优化，这里重点需要掌握索引的使用。
* 逻辑查询优化是通过SQL`等价变换`提升查询效率，即换一种查询写法执行效率可能更高。

## 1、数据准备

创建两个表：学员表和班级表，学员表插入50万条数据，班级表插入1万条数据。

**步骤1：建表**

```sql
CREATE TABLE `class` (
 	`id` INT(11) NOT NULL AUTO_INCREMENT,
     `className` VARCHAR(30) DEFAULT NULL,
	 `address` VARCHAR(40) DEFAULT NULL,
 	`monitor` INT NULL ,
	 PRIMARY KEY (`id`)
) ENGINE=INNODB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;
 
 
CREATE TABLE `student` (
 	`id` INT(11) NOT NULL AUTO_INCREMENT,
 	`stuno` INT NOT NULL ,
 	`name` VARCHAR(20) DEFAULT NULL,
 	`age` INT(3) DEFAULT NULL,
	 `classId` INT(11) DEFAULT NULL,
	 PRIMARY KEY (`id`)
 	#CONSTRAINT `fk_class_id` FOREIGN KEY (`classId`) REFERENCES `t_class` (`id`)
 ) ENGINE=INNODB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;
```



**步骤2：设置参数**

命令开启：允许创建函数设置

```sql
set global log_bin_trust_function_creators = 1;
```



**步骤3：创建函数**

保证每条数据都不同

```sql
#随机产生字符串
DELIMITER //
CREATE FUNCTION rand_string(n INT) RETURNS VARCHAR(255)
BEGIN    
DECLARE chars_str VARCHAR(100) DEFAULT 
'abcdefghijklmnopqrstuvwxyzABCDEFJHIJKLMNOPQRSTUVWXYZ';
DECLARE return_str VARCHAR(255) DEFAULT '';
DECLARE i INT DEFAULT 0;
WHILE i < n DO  
SET return_str =CONCAT(return_str,SUBSTRING(chars_str,FLOOR(1+RAND()*52),1));  
SET i = i + 1;
END WHILE;
RETURN return_str;
END //
DELIMITER ;
#假如要删除
#drop function rand_string;
```

随机产生班级编号

```sql
#用于随机产生多少到多少的编号
DELIMITER //
 CREATE FUNCTION  rand_num (from_num INT ,to_num INT) RETURNS INT(11)
 BEGIN   
DECLARE i INT DEFAULT 0;  
SET i = FLOOR(from_num +RAND()*(to_num - from_num+1))   ;
 RETURN i;  
END //
 DELIMITER ;
 #假如要删除
#drop function rand_num;
```



**步骤4：创建存储过程**

```sql
#创建往stu表中插入数据的存储过程
DELIMITER //
 CREATE PROCEDURE  insert_stu(  START INT ,  max_num INT )
BEGIN  
DECLARE i INT DEFAULT 0;   
SET autocommit = 0;    
#设置手动提交事务
REPEAT  #循环
SET i = i + 1;  #赋值
INSERT INTO student (stuno, name ,age ,classId ) VALUES 
((START+i),rand_string(6),rand_num(1,50),rand_num(1,1000));  
UNTIL i = max_num  
END REPEAT;  
COMMIT;  #提交事务
END //
DELIMITER ;
#假如要删除
#drop PROCEDURE insert_stu;
```

创建往class表中插入数据的存储过程

```sql
#执行存储过程，往class表添加随机数据
DELIMITER //
CREATE PROCEDURE `insert_class`(  max_num INT )
BEGIN  
DECLARE i INT DEFAULT 0;   
SET autocommit = 0;    
REPEAT  
SET i = i + 1;  
INSERT INTO class ( classname,address,monitor ) VALUES 
(rand_string(8),rand_string(10),rand_num(1,100000));  
UNTIL i = max_num  
END REPEAT;  
COMMIT; 
END //
DELIMITER ;
#假如要删除
#drop PROCEDURE insert_class;
```



**步骤5：调用存储过程**

class

```sql
#执行存储过程，往class表添加1万条数据  
CALL insert_class(10000);
```

stu

```sql
#执行存储过程，往stu表添加50万条数据  
CALL insert_stu(100000,500000);
```



**步骤6：删除某表上的索引**

创建存储过程

```sql
DELIMITER //
 CREATE  PROCEDURE `proc_drop_index`(dbname VARCHAR(200),tablename VARCHAR(200))
 BEGIN
 DECLARE done INT DEFAULT 0;
 DECLARE ct INT DEFAULT 0;
 DECLARE _index VARCHAR(200) DEFAULT '';
 DECLARE _cur CURSOR FOR  SELECT   index_name   FROM 
information_schema.STATISTICS   WHERE table_schema=dbname AND table_name=tablename AND 
seq_in_index=1 AND    
index_name <>'PRIMARY'  ;
 #每个游标必须使用不同的declare continue handler for not found set done=1来控制游标的结束
DECLARE  CONTINUE HANDLER FOR NOT FOUND set done=2 ;      
#若没有数据返回,程序继续,并将变量done设为2
 OPEN _cur;
 FETCH _cur INTO _index;
 WHILE  _index<>'' DO 
SET @str = CONCAT("drop index " , _index , " on " , tablename ); 
PREPARE sql_str FROM @str ;
 EXECUTE  sql_str;
 DEALLOCATE PREPARE sql_str;
 SET _index=''; 
FETCH _cur INTO _index; 
END WHILE;
CLOSE _cur;
END //
DELIMITER ;
```

该存储过程用于删除索引信息

在后续操作中，需要有的地方去删除索引信息

```sql
CALL proc_drop_index("dbname","tablename");
```



## 2、索引失效情况

> **`其实，看索引生不生效，实际上就是考虑底层索引的有序排列有没有起作用，会不会对整体效率有所提高。`**这实际上就是我们考虑索引是否有效的思路。

MySQL中`提高性能`的一个最有效的方式是对数据表`设计合理的索引`。索引提供了高效访问数据的方法，并且加快查询的速度，因此索引对查询的速度有着至关重要的影响。

* 使用索引可以`快速地定位`表中的某条记录，从而提高数据库查询的速度，提高数据库的性能。
* 如果查询时没有使用索引，查询语句就会`扫描表中的所有记录`。在数据量大的情况下，这样查询的速度会很慢。

大多数情况下都（默认）使用`B+树`来构建索引。只是空间列类型的索引使用`R-树`，并且MEMORY表还支持`hash索引`。

其实，用不用索引，最终都是优化器说了算。

**优化器是基于`cost开销`，不是基于`规则`，也不是基于`语义`**。哪种方式开销（const)越小，优化器就选择哪种方式。

另外，**`SQL语句是否使用索引，跟数据库版本、数据量、数据选择度都有关系`**。



#### 优先选择全值匹配索引

> **`顾名思义，优化器会优先选择更加匹配等值筛选列的索引`**

我们来看看一个查询语句：

```sql
SELECT SQL_NO_CACHE * FROM student WHERE age = 30 AND classId = 4 AND name = 'abcd';
```

此时，由于student表中没有任何的索引，所以此时去执行该查询语句不会使用到任何索引，此时的执行时间为0.392s。

我们此时去建立索引：

1、给age建立索引：

```sql
CREATE INDEX idx_age ON student(age);
```

创建好索引后，再去执行上述的查询语句，使用到的索引就是刚刚创建出来的age索引。此时所花费的时间是0.352s。

此时，使用EXPLAIN去解析上面的查询语句，得到的结果为：

![image-20240412004426631](.\images\image-20240412004426631.png)

2、建立age、classId联合索引

```sql
CREATE INDEX idx_age_classid ON student(age, classId);
```

创建完索引后，再去执行上面的SQL，所花费的时间是0.286s。

此时，使用EXPLAIN解析上面的查询语句，变成了：

![image-20240412004708000](.\images\image-20240412004708000.png)

此时，使用的是刚刚创建的两个列组成的联合索引。



3、建立age、classId和name联合索引

```sql
CREATE INDEX idx_age_classid_name ON student(age, classId, name);
```

此时再去执行查询语句，所花费的时间为：0.122s。

此时，使用的索引就变为了刚刚创建的三个列组成的联合索引：

![image-20240412005319278](.\images\image-20240412005319278.png)

那此时，之前创建的两个索引就失效了，实际使用的变成了第三个联合索引。

这是因为索引选择的是最优的全值匹配。

当WHERE筛选条件中，有多个列均符合索引列时，优化器会给我们优先选择满足匹配列多的索引。

因为能够减少页的IO次数。

比如相较于idx_age_classid索引来说，在idx_age_classid_name索引中，由于其索引组成有三个列，所以我们在索引页中的能够尽可能地与筛选条件进行匹配，筛选出所有符合条件的数据回表到聚簇索引中获取最终的数值。

由于idx_age_classid索引来说，其由两个列组成，所以其只能在索引中筛选出满足前两个条件的记录（age = 30 AND classId = 4），在这些筛选出的条件的记录中，还包含着不满足第三个条件的记录，其在二级索引中筛选出来的记录的数量是比idx_age_classid_name索引筛选出来的记录数量多的，那么其在聚簇索引中需要进行比较的记录也就多了，其在聚簇索引中比较的页数也会较多，此时效率就没有包含三个列的联合索引快。

所以，优化器会去尽量地选择与WHERE等值条件列更匹配的联合索引。那么，相比于等值匹配的索引，其他的索引就会失效。

**什么是SQL_NO_CACHE？**

`SQL_NO_CACHE`是MySQL的一个关键字，它可以让MySQL在查询时不使用查询缓存。（在MySQL8.0后不再支持查询缓存功能）

我们可以使用这个关键字，来测试查询的速度，例如：

```sql
SELECT SQL_NO_CACHE * FROM table_name WHERE condition;
```

在这里，我们将SQL_NO_CACHE关键字添加到查询语句中。这样，即使之前有相同的查询被执行过并且结果已经被缓存，这个查询也不会使用查询缓存。



#### 最佳左前缀原则

在MySQL建立联合索引使会遵守最佳左前缀匹配原则，即最左优先，在检索数据时从联合索引的最左边开始匹配。

在student中创建了一个联合索引idx_age_classid_name(age, classid, name)，现在来测试一下下面的案例：

**举例1：**

```sql
EXPLAIN SELECT SQL_NO_CACHE * FROM student WHERE student.age = 30 AND student.name = 'abcd';
```

此时，可以使用idx_age_classid_name吗？

是可以使用的，因为遵循了最左前缀匹配原则，在匹配条件中包含了联合索引的最左侧字段age，所以联合索引在筛选匹配时，可以根据第一个字段进行匹配；但是，当我们筛选出age=30的索引记录时，此时就需要去匹配第二个字段数据，由于在筛选条件中不存在classid字段，所以我们也就无法去对第二个字段进行筛选，无法对第二个字段进行筛选，那自然是无法使用索引对第三个字段进行匹配筛选（不是有序的），此时该查询就只能使用索引的一个字段数据。

我们根据执行计划中的key_len也能够得知这一信息：

![image-20240412152619435](.\images\image-20240412152619435.png)

key_len的值是5，其中INT类型字段占4个字节，NULL值列表占用1个字节。    



举例2：

```sql
EXPLAIN SELECT SQL_NO_CACHE * FROM student WHERE student.classid = 1 AND student.name = 'abcd';
```

此时，索引的使用情况是什么样的呢？

由于上述的查询中，筛选条件中完全没有出现联合索引的第一个字段age的信息，如果要使用联合索引，第一个字段age的值实际上就是去整个索引扫描了，即索引不起作用了，所以，上述的查询语句不会使用到联合索引。、

我们根据查询计划信息也能知道：

![image-20240412153207320](.\images\image-20240412153207320.png)

此时，没有使用到任何索引。

> 那么，我们也就可以知道，**`如果想要使用到联合索引，过滤条件要按照索引建立的顺序，依次满足，一旦跳过某个字段，索引后面的字段都无法使用了。`**如果查询条件中没有使用这些字段中的第一个字段，联合索引不会被使用。



举例3：索引idx_age_classid_name还能否正常使用？

```sql
EXPLAIN SELECT SQL_NO_CACHE * FROM student WHERE classid = 4 AND age = 30 AND name = 'abcd';
```

我们先说一个结论：这个查询可以使用联合索引，并且使用了联合索引的三个字段。

为什么？

因为优化器会将查询语句修改。由于上述的查询语句实际上在语义上来说与SELECT SQL_NO_CACHE * FROM student WHERE age = 30 AND classid = 4 AND name = 'abcd';这一段SQL没有任何区别，只不过是WHERE筛选条件的顺序发生了改变，所以优化器会给我们做一个小小的改动，将WHERE筛选条件的先后顺序改变一下，这样就能够符合联合索引的顺序。



#### 主键插入顺序

对于一个使用InnoDB存储引擎的表来说，在我们没有显式的创建索引时，表中的数据实际上都是存储在聚簇索引的叶子节点的。而记录又是存储在数据页中的，数据页和记录又是按照记录`主键值从小到大`的顺序进行排序的，所以如果我们插入记录的主键值是依次增大的话，那我们每插满一个数据页就换到下一个数据页继续插，而如果我们插入的主键值忽小忽大的话，就比较麻烦了，假设某个数据页存储的记录已经满了，它存储的主键值在1~100之间：

![image-20240412154403747](.\images\image-20240412154403747.png)

如果此时再插入一条主键值为9的记录，那它插入的位置就如下图：

![image-20240412154428386](.\images\image-20240412154428386.png)

可这个数据页已经满了，再插入咋办？我们需要把当前页面分裂成两个页面，把本页中的一些记录移动到新创建的这个页中。页面分裂和记录移位意味着什么？意味着：性能损耗。所以如果我们想尽量避免这样无谓的性能损耗，最好让插入的记录的主键值依次递增，这样就不会这样的性能损耗了。所以我们建议：让主键具有`AUTO_INCREMENT`，让存储引擎自己为表生成主键，而不是我们手动插入。



#### 计算、函数、类型转换（自动或手动）导致索引失效

顾名思义，在筛选条件中，涉及到了计算、函数、以及类型转换都会使索引失效。

我们来看几个例子：

例一：

```sql
EXPLAIN SELECT SQL_NO_CACHE * FROM student WHERE name LIKE 'abc%';

EXPLAIN SELECT SQL_NO_CACHE * FROM student WHERE LEFT(student.name, 3) = 'abc';
```

在student表中拥有一个name索引

上述两种方式拥有一样的效果，即去查询student表中name列是以abc开头的数据。

但是，这两种方式的效率是不同的。第一种方式可以使用索引，下面是它的查询计划：

![image-20240412161412543](.\images\image-20240412161412543.png)

第二种方式使用不了索引，下面是它的查询计划：

![image-20240412161521251](.\images\image-20240412161521251.png)

为什么使用不了索引呢？

因为它使用了函数。机器不像人，人知道数据经过函数计算后是否符合要求，计算不会，**机器只能去索引中一个一个地取出数据，将每个数据经过函数计算后与筛选条件进行比较，此时，索引是否有序就不起作用了（都是全表扫描），所以，此时就不会去使用索引了。**

同样地，对于计算来说，由于机器也是一个一个地去计算出结果，然后与索引中的数据一个一个地比较，无法根据索引的有序性快速地得出结果，所以此时的索引对计算筛选条件也就失去了效果。

例如：student表中包含stuno字段的单列索引

```sql
EXPLAIN SELECT SQL_NO_CACHE id, stuno, name FROM student WHERE stuno+1 = 900001;

EXPLAIN SELECT SQL_NO_CACHE id, stuno, name FROM student WHERE stuno = 9000000;
```

上面这两个SQL语句表示的含义都是相同的，但是在效率上，确实第二个查询更高一点。原因就在于对于计算来说，机器是不知道到底计算的结果是什么，有可能计算非常复杂，如果使用到索引，就需要对索引中的每一条数据进行计算，将计算的结果对条件进行比对，此时索引的有序性就失去了效果，索引也就失去了意义。

所以，**对于函数、计算来说，索引会失效。**

同样地还有类型转化，MySQL会对每一条记录都进行类型转换，与条件进行比较，所以，**有类型转换时，索引也会失效。**



#### 范围条件右边的列索引失效

这个实际的含义就是>、<筛选右边的索引失效。

具体的内容请查看《联合索引遇到范围查询的情况》

这里简单举一个例子：

```sql
SELECT * FROM test WHERE a > 1 and b = 2;
```

这里有一个(a, b)联合索引，由于满足a>1条件之后，b的数据是无序的，索引是失效的，所以这里只能使用到联合索引的一个字段，而无法使用第二个字段b来进行筛选。

对于>=、<=以及between and这样的条件，索引是可以生效的，因为它们相当于多了一个=的条件，在=条件下，索引是生效的，是有序的，所以这个整体的索引变成了有效的。

例如：

```sql
SELECT * FROM test WHERE a >= 1 and b = 2;
```

此时的索引，实际上是使用到了联合索引的两个字段的。



#### 不等于（!=或者<>）筛选，索引失效

案例：

```sql
EXPLAIN SELECT * FROM student where name <> 'nihao';
```

在student表中创建了一个name字段的索引。

但是，上面的查询语句使用不了这个name索引：

![image-20240412183904930](.\images\image-20240412183904930.png)

原因还在于索引是否可以起作用。

当条件是=时，我们只需要找到那一块区域都是=的列即可；

但是当条件是<>不等于时，这个时候就必须对索引中的记录一个一个地比较，索引的顺序就没有什么意义，还是得全表扫描，此是索引就没起作用，那自然是不用索引的。

所以<>不等于会造成索引失效的情况。



#### IS NULL可以使用索引，IS NOT NULL不能使用索引

在B+Tree索引中，可以存放NULL值的索引，一般在NULL值索引放在最左边。

其实，将`IS NULL可以使用索引，IS NOT NULL不能使用索引`和等于与不等于做比对就能够理解了。

等于类似于IS NULL

不等于类似于IS NOT NULL

在索引中，是将NULL值的字段存放在一起的，当我们使用的条件是IS NULL，实际上也是去取那一部分数据。

对于IS NOT NULL，就需要我们去索引中一个一个地去遍历扫描，对比是否为NULL，此时索引就是没有起作用的，依旧是全表扫描。（用不等于进行思考）

例如：

student表中拥有name列的索引

```sql
EXPLAIN SELECT * FROM student WHERE name IS NULL;
```

![image-20240412185538510](.\images\image-20240412185538510.png)



```sql
EXPLAIN SELECT * FROM student WHERE name IS NOT NULL;
```

![image-20240412185508458](.\images\image-20240412185508458.png)

> **启示：**
>
> 最好在设计数据表的时候就`将字段设置为NOT NULL约束`。如果表中字段有为空的需求时，可以考虑将数值类型的字段默认值设为0，字符串类型的字段默认值设为''空字符串。
>
> 同理：在查询中使用`not like`也无法使用索引，导致全表扫描。





#### like以通配符%开头索引失效

具体可以查看《联合索引遇到范围查询的情况》

案例：

```sql
SELECT * FROM student WHERE name like '%j';
```

表中包含name字段的索引。

其实很简单的道理，我要去查询%j的name属性，但是索引中，我要想去查询以j结尾的name值，就必须要一个一个地去遍历，去扫描，那实际上就是全表扫描，索引没有用，所以这个查询用不了索引。

![image-20240412191126229](.\images\image-20240412191126229.png)

> **`Alibaba《Java开发手册》`**
>
> **【强制】页面搜索严禁左模糊或者全模糊，如果需要请走搜索引擎解决。**





#### OR前后存在非索引的列会造成索引失效

案例：

在student表中，只有age列索引，没有classid列的索引，此时去执行下面的查询语句：

```sql
select * from student where age = 1 OR classid = 2;
```

上面的查询语句，实际上是将下面两个查询语句的内容合并起来：

select * from student where age = 1

select * from student where classid = 2

第一个查询语句可以使用age索引

由于第二个查询语句没有索引，所以需要去全文扫描

这两个查询语句合起来，如果要去使用索引，就必须去过一遍索引，还要去全文扫描一遍，这个时候所花的时间就比全文扫描所花的时间还要多了。

那这个时候，使用索引就有点得不偿失了，不如直接去全文扫描，将两个字段的数据都进行筛选匹配。

所以，**对于OR连接的筛选，如果一个字段有索引，一个字段没有索引，这个查询也不会去使用索引。**

查看其查询计划：

![image-20240412193040638](.\images\image-20240412193040638.png)



#### 不同的字符集造成索引失效

统一使用utf8mb4兼容性更好，统一字符集可以避免由于字符集转换产生的乱码。**不同的字符集进行比较前需要`转换`会造成索引失效。**



#### 一般性建议：

* 对于单列索引，尽量选择针对当前query过滤性更好的索引。
* 在选择组合索引的时候，当前query中过滤性最好的字段在索引字段熟悉怒中，位置越靠前越好。
* 在选择组合索引的时候，尽量选择能够包含当前query中where子句中更多的字段的索引。
* 在选择组合索引的时候，如果某个字段可能出现范围查询，尽量把这个字段放在索引次序的最后面。



## 3、关联查询优化

多表的连接分为内连接和外连接，外连接又分为左外连接、右外连接和全外连接。

MySQL不支持FULL OUTER JOIN全外连接，全外连接实际上使用的是UNION来实现的：

```sql
select 投影列 from 表名 left outer join 表名 on 连接条件
union
select 投影列 from 表名 right outer join 表名 on 连接条件
```

这里我们就不去考虑全外连接的优化了。



### 情况1：外连接

> **总结：**
>
> **`给被驱动表的连接字段添加索引能够有效地加快查询的效率。`**
>
> **`给驱动表连接字段添加索引没有意义（除非在WHERE子句中也使用了连接字段筛选）`**
>
> **`给两张表的连接字段都添加索引，和只给被驱动表添加索引的效率一样`**
>
> **在外连接中，主表就是驱动表，从表就是被驱动表。**
>
> **外连接有时候可以被MySQL优化器转换成内连接，此时主表不一定是驱动表。**

让我们来使用案例来解释一下这个结论

由于左外连接和右外连接只需要换一个表在SQL中的位置就可以相互转换，所以我们也只去考虑其中的一个即可。



**数据准备:**

创建两个表，一个是type表，一个是book表：

```sql
CREATE TABLE IF NOT EXISTS type(
	id INT UNSIGNED NOT NULL AUTO_INCREMENT,
	card INT UNSIGNED NOT NULL,
    PRIMARY KEY(id)
);

CREATE TABLE IF NOT EXISTS book(
	bookId INT UNSIGNED NOT NULL AUTO_INCREMENT,
	card INT NOT NULL,
    PRIMARY KEY(bookID)
);
```

往两个表中都插入数据：

```sql
#执行20次
INSERT INTO type(card) VALUES(FLOOR(1 + (RAND() * 20)));
#执行30次
INSERT INTO book(card) VALUES(FLOOR(1 + (RAND() * 20)));
```

执行完毕后，type有20条数据，book有30条数据



**案例：**

```sql
EXPLAIN SELECT SQL_NO_CACHE * FROM type LEFT JOIN book ON type.card = book.card;
```

![image-20240412225100947](.\images\image-20240412225100947.png)

type表是驱动表，book表是被驱动表

这段SQL执行的大致过程是：

取出type表中的一条数据，然后与book表中的每一条数据进行匹配；

然后再取出type表的一条数据，与book表中的每一条数据进行匹配

...

这样一来，type表中的每一条数据都会与book表中的30条数据都进行匹配，type表中一共有20条数据，这样一来，一共会匹配20 * 30 = 600次。

这就类似于Java中的嵌套循环，外层循环次数是20次，内层循环的次数是30次。

查询结果中的Type为ALL，表示进行了全表扫描。

上面的Extra的数据为`Using join buffer`表示MySQL为其分配一块名为`join buffer`的内存块来加快查询速度，这是MySQL的一个优化操作。



当我们给被驱动表的连接条件字段添加了一个索引后：

```sql
CREATE INDEX Y ON book(card);
```

此时，我们再去查看连接查询的执行计划：

```sql
EXPLAIN SELECT SQL_NO_CACHE * FROM type LEFT JOIN book ON type.card = book.card;
```

此时的查询结果为：

![image-20240412230337207](.\images\image-20240412230337207.png)

我们来看看上述的查询结果，被驱动表type变成了ref，key索引变成了Y，Extra中出现了Using index提示。

为什么会出现这些信息？

这个查询的过程是：取出type表中的一条数据，然后与book表中的所有数据进行匹配。当被驱动表book表中连接的字段有索引，就能够与type表中取出的数据快速地筛选匹配，这个时候索引是起作用的，能够有效地加快查询的效率。

对于驱动表type来说，由于是左外连接，所以驱动表中的数据全部都要保留的，所以原本就是要type表中的所有数据，就是要进行全表扫描的，所以驱动表的查询计划中的type为ALL。

最后，这里被驱动表中的Extra值为什么会有Using index呢？出现了索引覆盖的情况吗？是的。因为被驱动表book中只有id和card字段，在card索引中，是包含这两个字段信息的，当我们去select *时，实际上查询的就是这两个字段的数据，此时查询出来之后就不需要去回表操作了，自然也就是出现了索引覆盖现象，所以Extra中有Using index信息。

由上述可知：

> **`给被驱动表的连接字段添加索引，能够有效地加快查询的效率。`**



我们再来给驱动表添加一个索引：

```sql
CREATE INDEX X ON type(card);
```

此时，再去获取连接查询的执行计划：

```sql
EXPLAIN SELECT SQL_NO_CACHE * FROM type LEFT JOIN book ON type.card = book.card;
```

此时的执行结果为：

![image-20240412235456588](.\images\image-20240412235456588.png)

我们来解释一下，为什么驱动表的type为index，使用了X的索引，并且Extra的信息为Using index？

原因其实和索引覆盖有关。因为type表中只有两个字段id和card，而在X索引中，也包含这两个字段（二级索引目录项唯一的特性），如果MySQL执行的时候使用这个索引，是不需要再进行回表操作的，在二级索引中就能够得到这些数据，但是在二级索引中还是需要进行全表扫描，只不过不需要回表了，效率略微高了一点，所以，此时这个X索引是有意义的，所以type为index，key为X，Extra为Using index，使用到了这个索引。

但实际上，如果type表不是两个字段，而是多个字段时，此时再去查询，type表中就不会使用到card的索引了，我们来看个例子：

```sql
EXPLAIN SELECT * FROM test1 LEFT JOIN test on test1.d = test.a;
```

在test和test1表中分别有三个字段，分别是a、b、c和d、e、f，这两个字段都是INT类型，在test中有a字段索引，在test1中有d字段的索引，我们来看看这个查询的执行计划：

![image-20240412234023486](.\images\image-20240412234023486.png)

我们可以看到，此时的驱动表就不会去使用索引，如果使用索引，不会出现索引覆盖的现象，还要去聚簇索引中重新进行回表操作，效率反而还更差了，，此时使用索引没有任何意义。

所以我们由此得知：

> **`关联查询时，给驱动表的连接字段添加索引没有意义` （除非在WHERE子句中使用到了该字段）**

因为本身就需要将驱动表中的所有数据取出与被驱动表中的数据进行匹配（全表扫描），所以此时就不会使用到连接字段的索引。

当给驱动表中的关联字段添加索引，并且在WHERE子句中对该字段进行了筛选，那此时，则在查询时会使用到关联字段的索引，例如：

```sql
EXPLAIN SELECT * FROM test1 LEFT JOIN test on test1.d = test.a WHERE test1.d = 1;
```

查询结果：

![image-20240412234148564](.\images\image-20240412234148564.png)

该查询语句中，索引就变得有意义了。

索引能够帮助我们快速定位到满足条件test1.d = 1的数据上，此时就不是全表扫描了，那自然就会使用到索引了。





### 情况2：内连接

> **总结：**
>
> **`给被驱动表的连接字段添加索引能够有效地加快查询的效率。`**
>
> **`给驱动表连接字段添加索引没有意义（除非在WHERE子句中也使用了连接字段筛选）`**
>
> **在内连接中，由优化器给我们选择驱动表与被驱动表，哪种方式效率更高，优化器就会选择哪种，所以我们只需要给一张表的连接字段添加索引，这张表就会被选择称为被驱动表，另一张没有添加索引的表就会被选择称为驱动表**
>
> **`若两个表的连接字段都有索引，MySQL会自动将小结果集的表选为驱动表，大结果集的表选为被驱动表。`**（小表驱动大表）
>
> 其实，内连接的索引优化与外连接的索引优化一样，都是给被驱动表的连接字段添加索引更有效率，只不过在内连接中，两张表的关系对等，是由优化器根据效率的高低自动地选择驱动表与被驱动表。（那只要我们给一张表的连接字段添加索引，这张表就会自动变成被驱动表）





数据准备，创建两个表type和book，分别为其创建三个字段

```sql
CREATE TABLE IF NOT EXISTS type(
	id INT UNSIGNED NOT NULL AUTO_INCREMENT,
    name VARCHAR(25) NOT NULL,
	card INT UNSIGNED NOT NULL,
    PRIMARY KEY(id)
);

CREATE TABLE IF NOT EXISTS book(
	bookId INT UNSIGNED NOT NULL AUTO_INCREMENT,
    name VARCHAR(25) NOT NULL,
	card INT NOT NULL,
    PRIMARY KEY(bookID)
);
```

我们来做一个测试，看看下面的SQL：

```sql
EXPLAIN SELECT * FROM type INNER JOIN book ON type.card = book.card;
```

我们看看执行计划的执行结果：

![image-20240413102017333](.\images\image-20240413102017333.png)

由于此时两张表中都没有索引，所以实际上的执行结果是：

从type（驱动表）中取出一条数据，与book（被驱动表）中的所有数据进行筛选匹配；然后再从type表中取出一条数据......

这样反复地取出数据，实际上是对两张表进行了全表扫描。



此时，我们给book表的连接字段card添加一个索引：

```sql
CREATE INDEX Y ON book(card);
```

这个时候，我们再去查看上述查询的执行计划信息：

![image-20240413102508126](.\images\image-20240413102508126.png)

我们可以看到，此时的查询是使用了book中的card索引的，book作为被驱动表。

此时的执行过程是：

取出type（驱动表）中的一条数据，然后在book（被驱动表）的索引中，与有序的数据进行比较筛选，此时的效率就会很高，因为数据是有序的，查询到book表的主键信息后回表查询所有数据返回；

然后再取出type表中的一条数据......

我们知道，给被驱动表的连接字段添加索引的效率很高，推荐使用。



我们此时再来做一个测试，将book表中的索引删除，给type表的连接字段添加索引：

```sql
DROP INDEX Y ON book;

CREATE INDEX X ON type(card);
```

此时，我们再去查看查询的执行计划：

![image-20240413103001633](.\images\image-20240413103001633.png)

发现：

book变成了驱动表

type变成了被驱动表

可是明明在上面的案例中，book是被驱动表，type是驱动表，为什么这里变了？

原因在于效率。

对INNER JOIN来说，没有所谓的主表和从表，两个表之间的关系是对等的，取出的数据也都是两张表之间的交集部分。

在上例中，如果依旧是把type当成驱动表，book当成被驱动表的话，取出type中的一条数据，与book中的数据进行比较，先将type中的数据一个一个取出，索引不起作用，同时与book中的数据比较，book中没有索引，book也是全表扫描，此时两张表都是全表扫描操作，效率较差。

但如果是把book当成驱动表，type看作被驱动表，此时由于type中包含索引，取出book中的一条数据，与type中的数据进行比较，type表中由于有索引，可以根据索引的有序性进行比较，此时的效率较高。

**由于INNER JOIN连接左右两表的关系对等，所以优化器会根据成本大小，选择不同的驱动表与被驱动表。**





若我们给两张表的字段都添加了索引：

```sql
CREATE INDEX X ON type(card);

CREATE INDEX Y ON book(card);
```

此时，两张表的连接字段都拥有索引，所以此时按道理来说，MySQL优化器选择哪一个表作为被驱动表的效率都比较高。

我们来给表中的字段添加数据：

给type表中添加20条数据，给book表中添加10条数据。

此时，再去查看查询的执行计划信息：
![image-20240413110919761](.\images\image-20240413110919761.png)

此时，MySQL优化器选择的就是type作为被驱动表。

这个现象的原理是什么：**当内连接查询中，两个表的连接字段都有索引时，MySQL会自动将`小结果集的表`选为驱动表，`大结果集的表`选为被驱动表。**

为什么？

因为将小结果集的表作为驱动表，大结果集的表选为被驱动表，驱动表中的数据本身就要进行全表扫描，驱动表较小，这样全表扫描的数目就会少一点，被驱动表因为使用了索引，所以将大结果集作为被驱动表，这样使用索引处理大量的数据效率就会高很多。

**有句口诀：`小表驱动大表。`**





**最后来看一个案例：**

```sql
EXPLAIN select * from book LEFT JOIN type on type.card = book.card WHERE type.card IS NOT NULL;
```

在上面两张表中，只有book表的card字段有索引。

那么，按照之前的学习我们可以知道，在外查询中，book表是主表，那么book表是驱动表，type表是从表，那么type表是被驱动表。由于type表中没有索引，book表虽有索引，但是是驱动表，所以不会使用，两张表的执行计划中的type应该都是ALL，即都是全表扫描。那我们现在来看看这个查询计划的信息：

![image-20240413144511756](.\images\image-20240413144511756.png)

发现错了，一切都错了。怎么book表变成了被驱动表了，而且还使用了索引Y，type变成驱动表了。

原因在于MySQL优化器的优化操作，将上面的查询语句转变成了内连接的方式。

由于WHERE type.card IS NOT NULL的条件，实际上将主表中查询到的type表中没有的数据也筛选去除了，这个时候，上述的查询语句其实就是和内连接一样，只取相交部分。此时，MySQL就将上面的查询转换成了：

```sql
EXPLAIN select * from book INNER JOIN type on type.card = book.card
```

此时，驱动表和被驱动表的选择就根据是否有索引，以及表中的数据决定了（由MySQL优化器自己决定），所以，此时，驱动表就变成了type，被驱动表就变成了book。

所以：**外连接有时候可以被MySQL优化器转换成内连接，此时主表不一定是驱动表。**



### 总结

> * 被驱动表的连接字段使用索引能够`减少外层循环的次数`，提高效率。
> * 外连接时，**`主表是驱动表，从表是被驱动表`**。
> * 内连接时，由MySQL优化器选择被驱动表，自动`将小结果集的表选为驱动表`，`将大结果集的表选为被驱动表`。
> * 尽量使用连接查询代替子查询，可以减少查询的趟数。
> * 不建议使用子查询，建议将子查询SQL拆开结合程序多次查询，或使用JOIN来代替子查询。
>
> **总之，要给连接查询中的被驱动表连接字段添加索引。**





### join语句原理

#### Simple Nested-Loop Join（简单嵌套循环连接）

这种算法相当简单，从表A中取出一条数据1，遍历表B，将匹配到的数据放到result...以此类推，驱动表A中的每一条记录与被驱动表B的记录进行判断：

![image-20240413150855430](.\images\image-20240413150855430.png)

可以看到这种方式效率是非常低的，以上述表A数据a条，表B数据b条记录，一共要比较a * b次。开销如下：

| 开销计算         | SNLJ      |
| ---------------- | --------- |
| 外表扫描次数     | 1         |
| 内表扫描次数     | a         |
| 读取记录数       | a + a * b |
| JOIN比较次数     | a * b     |
| 回表读取记录次数 | 0         |

mysql不会这样地进行表的连接，就算两张表都没有索引，还是会为其分配一个`join buffer`的内存块来加快查询的速度（参考`Block Nested-Loop Join块嵌套循环连接`），当使用到索引时，会使用`Index Nested-Loop Join索引嵌套循环连接`。

我们考虑一下，是A表中记录数少一点对性能更好，还是B表中记录少一点对性能更好，我们可以看到，若A表是驱动表，A表中的记录数是a条，B表是被驱动表，B表中的记录数是b条，此时读取记录数是a + a * b，看这个式子，我们可以知道，当a的记录数较小时，整体的数据相比与b记录数较小时更少。

所以：

> 若驱动表的数目更少，则对性能更优，这也说明了：**`小表驱动大表`**
>
> 即我们**在设计连接查询时，尽量让小表作为驱动表，大表作为被驱动表，让大表的连接字段使用索引。**





#### Index Nested-Loop Join（索引嵌套循环连接）

Index Nested-Loop Join其优化的思路主要是为了`减少内层表数据的匹配次数`，所以要求**`被驱动表上有索引`**才行。通过外层表匹配条件直接与内层表索引进行匹配，避免和内层表的每条记录去进行比较，这样极大的减少了对内层表的匹配次数。

![image-20240413152740053](.\images\image-20240413152740053.png)

驱动表中的每条记录通过被驱动表的索引进行访问，因为索引查询的成本是比较固定的，故mysql优化器都倾向于使用记录数少的表作为驱动表（外表）。

| 开销统计         | SNLJ      | INLJ                  |
| ---------------- | --------- | --------------------- |
| 外表扫描次数     | 1         | 1                     |
| 内表扫描次数     | a         | 0                     |
| 读取记录数       | a + b * a | a + b(match)          |
| JOIN比较次数     | a * b     | a * Index(Height)     |
| 回表读取记录次数 | 0         | b(match)(if possible) |

如果被驱动表加索引，效率是非常高的，但如果索引不是主键索引，所以还得进行一次回表查询。相比，被驱动表的索引是主键索引，效率会更高。

我们来看看这个语句：

```sql
EXPLAIN SELECT * FROM t1 STRAIGHT_JOIN t2 ON t1.a = t2.a;
```

如果直接使用join语句，MySQL优化器可能会选择表t1或t2作为驱动表，这样会影响我们分析SQL语句的执行过程。所以，为了便于分析执行过程中的性能问题，我们改用`straight_join`让MySQL使用固定的连接方式执行查询，这样优化器只会按照我们指定的方式去join。在这个语句中，t1是驱动表，t2是被驱动表。

![image-20240413153826343](.\images\image-20240413153826343.png)

可以看到，在这条语句里，被驱动表t2的字段a上有索引，join过程用上了这个索引，因此这个语句的执行流程是这样的：

1. 从表t1中读入一行数据R；
2. 从数据行R中，取出a字段到表t2里去查找；
3. 取出表t2中满足条件的行，跟R组成一行，作为结果集的一部分；
4. 重复执行步骤1到3，直到表t1的末尾循环结束。

这个过程是先遍历表t1，然后根据从表t1中取出的每行数据中的a值，去表t2中查找满足条件的记录。在形式上，这个过程就跟我们写程序时的嵌套循环类似，并且使用上了被驱动表的索引。

它的对应流程如下图所示：

![image-20240413154442015](.\images\image-20240413154442015.png)





#### Block Nested-Loop Join（块嵌套循环）

如果存在索引，那么会使用index的方式进行join，如果join的列没有索引，被驱动表要扫描的次数太多了，每次访问被驱动表，其表中的记录都会被加载到内存中，然后再从驱动表中取一条与匹配，匹配结束后清除内存，然后再从驱动表中加载一条记录，然后把被驱动表的记录加载到内存匹配，这样周而复始，大大增加了IO的次数。为了减少被驱动表的IO次数，就出现了Block Nested-Loop Join的方式。

不再是逐条获取驱动表的数据，而是一块一块的获取，引入了`join buffer缓冲区`，将驱动表join相关的部分数据列（大小受join buffer的限制）缓存到join buffer中，然后全表扫描被驱动表，被驱动表的每一条记录一次性和join buffer中的所有驱动表记录进行匹配（内存中操作），将简单嵌套循环中的多次比较合并成一次，降低了被驱动表的访问频率。

**如果能够将驱动表中的数据，一次性全部加载到join buffer中，那被驱动表只需要加载一次到内存中，与驱动表的数据进行匹配；但如果join buffer大小不够，不足以让驱动表中的数据一次性全部加载，只能分多次加载，假设加载了k次，被驱动表也需要加载k次到内存中。**

> **注意：**
>
> * **`join buffer`中不仅存放的是关联表字段，还会将select要查询的字段也放入到其中。**（所以，不推荐使用select *去查询数据，要查询什么字段就写什么字段，因为join buffer的大小有限，为了尽可能多地存放驱动表的数据，从而减少IO的次数，提高效率，所以要避免查询一些不必要的字段）
>
> * 在一个有N个join关联的sql中会分配N-1个join buffer。所以查询的时候尽量避免不必要的字段，可以让join buffer中可以存放更多的列。

![image-20240413164903838](.\images\image-20240413164903838.png)

**参数设置：**

* **`block_nested_loop`**

通过`show variables like '%optimizer_switch%'`查看`block_nested_loop`状态。默认是开启的。

* **`join_buffer_size`**

驱动表能不能一次加载完，要看join buffer能不能存储所有的数据，默认情况下`join_buffer_size=256k.`

![image-20240413165417757](.\images\image-20240413165417757.png)



**`在整体效率上：INLJ > BNLJ > SNLJ`**



#### Hash join（了解）

我们来看看一个查询：

```sql
EXPLAIN select * from book LEFT JOIN type on type.card = book.card;
```

book表和type表中均没有索引，我们看看查询的结果：

![image-20240413170329001](.\images\image-20240413170329001.png)

可以看到，Using join buffer后面跟着一个hash join，如果你的MySQL版本是5.7版本，后面跟着的内容是Block Nested Loop，这里使用的底层逻辑就不是块嵌套循环了，而是Hash join。

**`从MySQL8.0.2版本开始将废弃BNLJ，因为从MySQL8.0.18版本开始就加入了hash join，默认都会使用hash join代替块嵌套循环。`**

* Nested Loop:

  对于被连接的数据子集较小的情况，Nested Loop是一个较好的选择。

* Hash Join是做`大数据集连接`时的常用方式，优化器使用两个表中较小（相对较小）的表利用Join Key在内存中建立`散列表`，然后扫描较大的表并探测散列表，找出与Hash表匹配的行。

  * 这种方式适用于较小的表完全可以放入内存中的情况，这样总成本就是访问两个表的成本之和。
  * 在表很大的情况下并不能完全放入内存，这时优化器会将它分割成`若干不同的分区`，不能放入内存的部分就把该分区写入磁盘的临时段，此时要求较大的临时段从而尽量提高I/O的性能。
  * 它能够很好的工作于没有索引的大表和并行查询的环境中，并提供最好的性能。Hash JOIN只能应用于等值连接，这是由Hash的特点决定的。







## 4、子查询优化

**不建议使用子查询，建议将子查询SQL拆开结合程序多次查询，或使用JOIN来代替子查询。**

MySQL从4.1版本开始支持子查询，使用子查询可以进行SELECT语句的嵌套查询，即一个SELECT查询的结果作为另一个SELECT语句的条件。子查询可以一次性完成很多逻辑上需要多个步骤才能完成的SQL操作。

**`子查询是MySQL的一项重要的功能，可以帮助我们通过一个SQL语句实现比较复杂的查询。但是，子查询的执行效率不高。`**原因：

1. 执行子查询时，MySQL需要为内层查询语句的查询结果建立一个`临时表`，然后外层查询语句从临时表中查询记录。查询完毕后，再撤销这些临时表。这样会消耗过多的CPU和IO资源，产生大量的慢查询。
2. 子查询的结果集存储的临时表，不论是内存临时表还是磁盘临时表都不会存在索引，所以查询性能会受到一定的影响。

> **在MySQL中，可以`使用连接（JOIN）查询来代替子查询`。连接查询不需要建立临时表，其速度比子查询要快**，如果查询中使用索引的话，性能会更好。



举例1：查询学生表student中班长的学生信息

使用子查询：

```sql
#创建班级表中班长的索引
CREATE INDEX idx_monitor ON class(monitor);

#查询学生表中班长的信息
EXPLAIN SELECT * FROM student stu1
WHERE stu1.stuno IN (
	SELECT monitor
	FROM class c
    WHERE monitor IS NOT NULL
);
```

![image-20240413205941419](.\images\image-20240413205941419.png)

我们来看看这个查询计划的信息：

第三条记录中的select_type值为：MATERIALIZED，表示子查询使用了物化操作，将monitor单独看作了一个表。key是idx_monitor，表示子查询使用了monitor的索引。

第二条记录表示是子查询后的临时表。

包含子查询的查询过程，会先去执行子查询操作，然后将结果作为一个临时表进行维护，这个临时表就是第二条查询结果记录。

最后，类似于连接查询，将主表与临时表连接起来，匹配符合条件的数据记录。

相较于连接查询来说，子查询多了一个维护临时表的步骤，相较于连接查询效率较低，那如果可以将子查询改成使用连接查询，效率会得到提升。

对上述的查询使用连接查询修改：

```sql
EXPLAIN SELECT * 
FROM student stu1 
INNER JOIN class c 
ON stu1.stuno = c.monitor 
WHERE c.monitor IS NOT NULL;
```

![image-20240413211435472](.\images\image-20240413211435472.png)

此时的驱动表是stu1，被驱动表是c，被驱动表使用了连接字段的索引，效率较高，并且此时不会去维护一个临时表，效率得到了提升。



举例2：取所有不为班长的同学的信息

使用子查询：

```sql
EXPLAIN SELECT SQL_NO_CACHE a.*
FROM student a
WHERE a.stuno NOT IN (
	SELECT monitor 
	FROM class b
    WHERE monitor IS NOT NULL
);
```

修改成使用连接查询：

```sql
SELECT SQL_NO_CACHE a.*
FROM student a LEFT JOIN class b
ON a.stuno = b.monitor
WHERE b.monitor IS NULL;
```

> 结论：尽量不要使用`NOT IN`或者`NOT EXISTS`，用LEFT JOIN xxx ON xx WHERE xx IS NULL替代。

使用IS NULL可以使用索引，使用NOT IN、NOT EXISTS以及IS NOT NULL使用不了索引。



## 5、排序优化

### 5.1、为什么要进行排序优化

**`问题：`**在WHERE条件字段上加索引，但是为什么还要在ORDER BY字段上加索引呢？

**`回答：`**

在MySQL中，支持两种排序方式，分别是`FileSort文件排序`和`Index索引排序`。

* Index索引排序中，索引可以保证数据的有序性，不需要再进行排序，效率更高。
* FileSort排序则一般在内存中进行排序，占用CPU较多。如果待排序结果较大，会产生临时文件I/O到磁盘进行排序的情况，效率较低。

**`优化建议：`**

1. SQL中，可以在WHERE子句和ORDER BY子句中使用索引，目的是在WHERE子句中`避免全表扫描`，在ORDER BY子句`避免使用FileSort排序`。当然，某些情况下全表扫描，或者FileSort排序不一定比索引慢。但总的来说，我们还是要避免，以提高查询效率。
2. 尽量使用Index排序完成Order By操作。如果WHERE和ORDER BY后面是相同的列就使用单索引列；如果不同就使用联合索引。
3. 无法使用Index排序时，需要对FileSort方式进行调优。



### 5.2、测试及说明

**案例1：`只使用ORDER BY，不使用WHERE与LIMIT，索引失效`**

在student表中创建了一个联合索引：

```sql
CREATE INDEX idx_age_classid_name ON student(age, classid, name);
```

这个时候，去查看一下使用age、classid作为排序方式的查询的执行计划：

```sql
EXPLAIN SELECT SQL_NO_CACHE * FROM student ORDER BY age, classId;
```

![image-20240413230835874](.\images\image-20240413230835874.png)

发现此时并没有使用到索引，排序方式使用的是文件排序filesort。

为什么？

假如我们使用的是索引排序，我们需要现在二级索引中根据排列的顺序，取出所有的索引记录，然后还要到聚簇索引中回表。由于这里并没有使用到WHERE筛选，当数据表中的数据非常多的时候，不仅需要取出二级索引中的所有记录，还需要在聚簇索引中去获取所有的记录，扫描的记录数非常大。这个时候实际上还不如直接不使用索引，直接进行全表扫描，然后使用文件进行排序，反而效率还更高一点。

所以，**`当我们单独使用ORDER BY进行排序，而不使用WHERE或LIMIT的时候，不会使用到ORDER BY的字段索引。`**

假如，此时将SELECT * 修改成SELECT age,classid，这个时候会不会使用索引？

会，因为在联合索引中，包含了这两个字段，这个时候就会出现索引覆盖现象，不需要进行回表操作，那效率会提高很多，就可以直接使用索引排序了。



**案例2：`使用ORDER BY，并使用了LIMIT获取前面的数据，索引有效`**

我们在查询排序的基础上，增加一个LIMIT，获取前10条数据：

```sql
EXPLAIN SELECT SQL_NO_CACHE * FROM student ORDER BY age, classId LIMIT 10;
```

![image-20240413232024467](.\images\image-20240413232024467.png)

我们可以发现这个时候，使用到了联合索引。

为什么？

还是和数据量有关。当我们获取的是前面10条记录时，在二级索引中，就只会将10条记录进行回表，在聚簇索引中就不需要去获取的是所有记录了。而对于没有LIMIT的查询来说，其有可能需要对上百万条记录进行回表，需要进行两次的索引遍历（二级索引），此时不如使用全表扫描。但是如果使用了LIMIT，此时就是取出有限的记录进行回表，比对全表的记录进行扫描的效率高。所以，查询语句增加了LIMIT，排序时就会使用索引。

并且注意查看，此时没有使用WHERE子句筛选，仅包含ORDER BY和LIMIT时，key_len的长度包括了联合索引的所有字段长度（就算这些字段没有在ORDER BY排序中）。



所以，**`在增加了LIMIT子句的排序查询中，会使用到排序字段的索引。`**





**案例三：ORDER BY排序顺序与联合索引的顺序不同时，索引失效；方向相反，索引失效**

```sql
EXPLAIN SELECT * FROM student ORDER BY age DESC, classid ASC LIMIT 10;

EXPLAIN SELECT * FROM student ORDER BY classid DESC,name DESC LIMIT 10;

EXPLAIN SELECT * FROM student ORDER BY age ASC, classId desc LIMIT 10;

EXPLAIN SELECT * FROM student ORDER BY age DESC, classId DESC LIMIT 10;
```

上面四种查询，我们来说一个结论，除了最后一个查询，其余的查询皆无法使用索引。

为什么会出现这种情况呢？

对于第一个至第三个查询来说，由于其查询的排序顺序或者方向与联合索引不一致，这个时候就不会使用到索引。

对于第四个查询来说，其查询的排序顺序与联合索引一致，但是方向全部都相反，此时会使用到索引，此时去索引中反向扫描。

**结论：`在查询的排序中使用联合索引，排序列的顺序要与索引的顺序一致，并且方向与联合索引中设置的排序方向，要么全部保持一致，要么全部相反（反向检索）`。**





**案例四：使用ORDER BY，并且包含WHERE筛选，索引生效**

```sql
EXPLAIN SELECT * FROM student WHERE age = 1 ORDER BY classId, name;
```

在student表中包含(age, classId, name)的索引。此时，我们去执行时就会使用到这个索引。

![image-20240414103945165](.\images\image-20240414103945165.png)

可以看到，这里使用到了索引，虽然key_len的长度是5，但是实际上，在索引中经过age=1筛选之后的索引，就是按照classId、name进行排序的，所以实际上还是使用到了classId与name的索引字段。

即，WHERE子句和ORDER BY一起存在于查询中时，查询时会考虑使用联合索引。



**我们再来看两个例子：**

```sql
EXPLAIN SELECT * FROM student WHERE classid = 1 ORDER BY age;


EXPLAIN SELECT * FROM student WHERE classid = 1 ORDER BY age LIMIT 10;
```

第二个查询是在第一个查询的基础上增加了一个LIMIT

但是，第一个查询使用不了联合索引，但是第二个查询可以使用联合索引

第一个查询的执行计划：此时使用的是filesort文件排序

![image-20240414111345217](.\images\image-20240414111345217.png)

第二个查询的执行计划：

![image-20240414111420687](.\images\image-20240414111420687.png)

为什么会这样？实际是因为LIMIT 10。

第一个查询中，由于没有LIMIT字段，当我们要去使用索引的时候，由于索引中的age本身就是已经排好序了，第一个字段可以直接使用，然后我们进入到第二字段classId中进行比较，由于classId是无序的，我们需要去一个记录一个记录的遍历（全表扫描），筛选出classId=1的字段，最后，还需要回表操作，这样还不如直接不使用索引，直接进行全表扫描，这样反而更快。

第二个查询，由于有LIMIT字段，只获取前10条数据，那会在第一个查询的基础上，只取出10条数据进行回表，这样效率相对于全表扫描而已会更高，所以会使用到索引。

由此，我们可以知道，WHERE和ORDER BY一起使用时，有时候不遵循最左原则也能够使用联合索引，能不能使用还是需要经过查询优化器的分析。

这里实际上和之前学习的最左原则发生了一些冲突，我们的理解是：

**查询优化器会具体问题具体分析，有一套固定的模型针对不同的查询进行计算开销，而不是按照特定的规则选择是否使用索引。**





#### 对ORDER BY能否使用索引的小结

```sql
INDEX a_b_c(a, b, c)

# order by能使用索引最左前缀
ORDER BY a
ORDER BY a, b
ORDER BY a, b, c
ORDER BY a DESC, b DESC, c DESC

#如果WHERE使用索引的最左前缀定义为常量，则ORDER BY能使用索引
WHERE a = const ORDER BY b,c
WHERE a = const AND b = const ORDER BY c
WHERE a = const ORDER BY b,c
WHERE a = const AND b > const ORDER BY b,c

#不能使用索引进行排序
ORDER BY a ASC, b DESC, c DESC -- 排序不一致
WHERE g = const ORDER BY b,c -- 丢失a索引
WHERE a = const ORDER BY c -- 丢失b索引
WHERE a = const ORDER BY a,d -- d不是索引的一部分
WHERE a IN (...) ORDER BY b, c -- 对于排序来说，多个相等条件也是范围查询
```

当然，上述只是一些案例，没有任何的规律，对于查询来说还是需要具体问题具体分析，MySQL优化器会根据花费的成本来决定是否使用索引





### 5.3、对filesort与indexsort的测试与说明

ORDER BY子句，尽量使用INDEX方式排序，避免使用FileSort方式排序。

在测试之前，先将student表中的所有索引删除，只留下主键。

**案例：**查询年龄为30岁的，且学生编号小于101000的学生，按照名字进行排序

```sql
EXPLAIN SELECT SQL_NO_CACHE * FROM student WHERE age = 30 AND stuno < 101000 ORDER BY name;
```

查询结果如下：

![image-20240414115156833](.\images\image-20240414115156833.png)

此时使用的排序方式是`filesort`。所花费的时间是`0.178s`。



**改进方案1：**

为了能够使用到`Index索引`，我们为其创建联合索引，我们来看看这个查询的条件：WHERE age = 30 AND stuno < 101000 ORDER BY name。

age是等值筛选，stuno是一个范围筛选，最后根据name排序。

我们之前学习过，大于>、小于<这两个范围筛选之后的字段，是使用不了索引的，因为范围筛选后的下一个字段是无序的。当我们设置了联合索引的第二个字段为stuno，进行了stuno < 101000筛选后，第三个字段的name实际上是无序排序的，此时就无法进行index排序了。

所以，为了能够使用到index排序，我们就不能将stuno字段加入到联合索引中，而是直接在age=1筛选完成之后，直接使用name字段作为索引进行排序，排完序之后，再进行回表操作，在聚簇索引中完成对stuno<101000的筛选。

于是创建出来的联合索引是(age, name)：

```sql
CREATE INDEX idx_age_name ON student(age, name);
```

创建完毕之后，我们再去查看前面查询的执行计划信息：

![image-20240414115927489](.\images\image-20240414115927489.png)

此时就使用到了联合索引进行排序，key_len为5的原因在于，对索引中的age=30过滤完成之后，剩下的记录本身就是按照name进行排序的，就可以直接进行回表操作了，无需再进行操作，所以使用到了key_len是5。

此时，使用的是`Index排序`，所花费的时间是`0.128s`。





**改进方案二：**

使用index排序一定速度最快吗？

我们来看看这个案例，创建联合索引(age, stuno, name)：

```sql
CREATE INDEX idx_age_stuno_name ON student(age, stuno, name);
```

由于在查询SELECT SQL_NO_CACHE * FROM student WHERE age = 30 AND stuno < 101000 ORDER BY name;中，FROM后面的子句是：

WHERE age = 30 AND stuno < 101000 ORDER BY name

stuno是一个<小于号的范围查询，所以当查询使用到联合索引(age, stuno, name)时，经过stuno范围筛选后，name字段是无序的，所以该字段是使用不了的，所以，此时回表获取数据后，需要经过`FileSort`文件排序的方式，对查询的结果进行排序操作。

我们看看这个查询的执行计划：

```sql
EXPLAIN SELECT SQL_NO_CACHE * FROM student WHERE age = 30 AND stuno < 101000 ORDER BY name;
```

查询计划信息：

![image-20240414121158968](.\images\image-20240414121158968.png)

查询所花费的时间是`0.099s`。

我们由查询计划的结果可以看到，数据表中存在idx_age_name和idx_age_stuno_name，优化器选择的是idx_age_stuno_name索引执行。使用这种方式执行所使用的排序方式是filesort文件排序，但是所花费的时间却更少。

为什么？

使用idx_age_stuno_name索引，可以在二级索引中，根据age和stuno字段筛选，筛选出相较于idx_age_name索引更少的数据进行回表操作，而使用idx_age_name只经过age的筛选就将筛选后的数据进行回表，此时回表的数据较多。

所以，就算idx_age_stuno_age索引无法使用到index排序，但是由于其较少的数据回表排序，此时就算使用`filesort`效率也很高。



> **说明总结：**
>
> 1. 使用`文件排序filesort`不一定比使用`索引排序index sort`效率低，随着数据量的增加，选择的排序方式也会发生变化。
>
>    例如，在上例中，如果使用age = 30 and stuno < 101000筛选之后数据量依旧非常庞大，此时优化器可能会选择索引排序。
>
> 2. **`当【范围条件】和【group by或者order by】字段出现二选一时，优先观察条件字段的过滤数量，如果过滤的数据足够多，而需要排序的数量并不多时，优先把索引放在范围字段上。反之，亦然。`**





### 5.4、filesort算法：双路排序和单路排序

排序的字段若不在索引列上，则filesort会有两种算法：**`双路排序`**和**`单路排序`**。

**`双路排序（慢）`**

* `MySQL 4.1之前是使用双路排序`，字面意思就是两次扫描磁盘，最终得到数据，读取行指针和order by列，对他们进行排序，然后扫描已经排好序的列表，按照列表中的值重新从列表中读取对应的数据输出。
* 从磁盘取排序字段，在buffer进行排序，再从磁盘取其他字段。

例如order by age，是先将age字段扫描到内存中，先对age进行排序；然后根据age字段上的信息，去表中找到完整的信息输出。

取一批数据，要对磁盘进行两次扫描，IO是很耗时的，在mysql4.1之后，出现了第二种改进的算法，就是单路排序。

**`单路排序（快）`**

从磁盘读取读取需要的所有列，按照order by列在buffer对它们进行排序，然后扫描排序后的列表进行输出，它的效率更快一些，避免了第二次读取数据。并且把随机IO变成了顺序IO，但是它会使用更多的空间，因为它把每一行都保存在内存中了。

**`引申出来的问题`**

单路存在问题

* 在sort_buffer中，单路要比多路占用更多空间，因为单路是把所有字段都取出，所以有可能取出的数据的总体大小超出了`sort_buffer`容量，导致每次只能读取sort_buffer容量的数据，进行排序（创建temp文件，多路合并），排序完再取sort_buffer容量大小，再进行排序...从而多次I/O。
* 单路本来想节省一次I/O，反而导致了大量的I/O操作，反而得不偿失，所以，我们需要对排序进行优化。

**`优化策略`**

1. **`尝试提高sort_buffer_size`**

   sort_buffer_size即排序内存的大小

   不管使用单路排序还是多路排序，提高这个参数都会提高效率，要根据系统的能力去提高，因为这个参数是针对每个进程的调整。InnoDB存储引擎默认是1MB。

   ```sql
   SHOW VARIABLES LIKE '%sort_buffer_size%';
   ```

   ![image-20240414125401994](.\images\image-20240414125401994.png)

2. **`尝试提高max_length_for_sort_data`**

   提高这个参数，会增加使用改进算法单路排序的概率。

   ```sql
   #默认为1024个字节
   SHOW VARIABLES LIKE '%max_length_for_sort_data%';
   ```

   但是如果设置的太高，数据总容量超出sort_buffer_size的概率就增大，明显症状是高的磁盘I/O活动和低的处理器使用率。如果需要返回的列的总长度大于max_length_for_sort_data，使用双路算法，否则使用单路算法。在1024~8192字节之间调整。

3. **`Order BY时SELECT *是一个大忌，最好只查询需要的字段。`**

   原因：

   * 当QUERY的**字段大小总和小于`max_length_for_sort_data`**，而且排序字段不是TEXT|BLOB类型时，会使用**单路算法**，否则使用多路算法。
   * 两种算法的数据有可能超出sort_buffer_size的容量，超出之后，会创建temp文件进行合并排序，导致多次IO，但是使用单路排序的风险更大，所以要**尽可能低减少字段的长度，让`sort_buffer_size`能够尽可能多地存储数据**。





## 6、GROUP BY优化

* group by使用索引的原则几乎跟order by一致，group by即使没有过滤条件用到索引，也可以直接使用索引。
* group by先排序再分组，遵照索引建的最左前缀准则
* 当无法使用索引列，增大`max_length_for_sort_data`和`sort_buffer_size`参数的设置
* where效率高于having，能写在where限定的条件就乣写在having中
* 减少使用order by，和业务沟通能不排序就不排序，或将排序放在程序端去做。order by、group by、distinct这些语句较为耗费CPU，数据库的CPU资源是很宝贵的。
* 包含了order by、group by、distinct这些查询语句，where条件过滤出来的结果集请保持在1000行以内，否则SQL会很慢。



## 7、分页查询优化

一般分页查询时，通过创建覆盖索引能够比较好地提高性能。一个常见又非常头痛的问题是limit 200000000,10，此时需要MySQL排序前200000010记录，仅仅返回2000000~20000010的记录，其他记录丢弃，查询排序的代价非常大。

```sql
EXPLAIN SELECT * FROM student LIMIT 2000000,10;
```

![image-20240414134349130](.\images\image-20240414134349130.png)

**`优化思路一`**

在索引上完成排序分页操作，最后根据逐渐关联回原表查询所需要的其他列内容

```
EXPLAIN SELECT * FROM student t, (SELECT id FROM student ORDER BY id LIMIT 2000000,10) a
WHERE t.id = a.id;
```

![image-20240414134544693](.\images\image-20240414134544693.png)



**`优化思路二`**

该方案适用于主键自增的表，可以把LIMIT查询转换成某个位置的查询

```sql
EXPLAIN SELECT * FROM student WHERE id > 20000000 LIMIT 10;
```

![image-20240414134647473](.\images\image-20240414134647473.png)





## 8、优先考虑覆盖索引

### 8.1、什么是覆盖索引？

**`理解方式一`**：索引是高效找到行的一个方法，但是一般数据库也能使用索引找到一个列的数据，因此它不必读取整个行。毕竟索引叶子节点存储了它们的索引的数据；当能通过索引就可以得到想要的数据，那就不需要读取行了。**`一个索引包含了满足查询结果的数据就叫做覆盖索引。`**

**`理解方式二`**：非聚簇复合索引的一种形式，它包括在查询里的SELECT、JOIN和WHERE子句用到的所有列（即建索引的字段正好是覆盖查询条件中所涉及的字段）。

简单来说就是：`索引列+主键` 包含 `SELECT列到FROM列之间查询的列`。



**当某个索引中的字段包含着所有要查询的字段信息时，此时就会出现索引覆盖的现象。**原本可能不使用索引的查询，此时都会因为索引覆盖的缘故而使用了索引。

**案例1：**

```sql
EXPLAIN SELECT age, classid, name, id FROM student;
```

student中有一个联合索引(age, classid, name)，如果查询的是SELECT *，此时是不会去使用索引的。但是因为查询的是age,classid,name,id，由于此时的联合索引的字段中都包含这些数据，使用联合索引直接就可以查询出来所有的数据，不需要再进行回表操作，此时就会去使用索引：

![image-20240414141435863](.\images\image-20240414141435863.png)



**案例2：**

```sql
EXPLAIN SELECT * FROM student WHERE age <> 20;
```

此时，由于age的筛选条件是不等于，不等于不使用索引，所以查询计划是：

![image-20240414144928602](.\images\image-20240414144928602.png)

如果将查询改成查询索引中的字段：

```sql
EXPLAIN SELECT id, age, name, classid FROM student WHERE age <> 20;
```

此时就会因为索引覆盖的作用，而去使用索引。由于索引覆盖，此时使用索引的效率会比较高。

![image-20240414145108356](.\images\image-20240414145108356.png)

没有绝对的使用索引与不使用索引，实际上都是优化器对成本的权衡，如果使用索引效率更高，成本更低，那就使用索引；如果使用索引对效率没有太大提升，或者反而成本更高，那就不使用。



### 8.2、覆盖索引使用的利弊

**`好处：`**

1. **`避免InnoDB表进行索引的二次查询（回表）`**

InnoDB是以聚簇索引的顺序来存储的，对于InnoDB来说，二级索引在叶子节点中所保存的是行的主键信息，如果是用二级索引查询数据，在查找到相应的键值后，还需通过主键进行二次索引才能获取我们真实所需要的数据。

在覆盖索引中，二级索引的键值中可以获取所要的数据，`避免了对主键的二次查询，减少了IO操作`，提升了查询效率。



2. **`可以把随机IO变成顺序IO加快查询效率`**

回表操作实际上是随机IO。当我们在二级索引中查询出了一部分数据，将这些数据回表操作，由于在聚簇索引中，这些数据有可能存放在不同的页中（聚簇索引中的数据根据ID主键排列），此时我们可能就需要将这些不同的页读取到内存中，就需要进行多次IO操作（随机IO）。

而如果不进行回表操作，只在二级索引中就将数据全部查出，在一个索引中，数据之间是有序的，数据存放在一起，页与页之间是尽量存放在一起的，此时我们读取的时候就直接读取一个区的数据，只需要读取一次就可以将多个页读取到内存中，IO次数减少很多（顺序IO）。

**`由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。`**

**弊端：**

索引字段的维护总是有代价的。因此，在建立冗余索引来支持覆盖索引时就需要权衡考虑了。



## 9、如何给字符串添加索引

**`使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本`**。



> **注意：**
>
> **使用字符串的前缀索引就用不了覆盖索引了（因为使用覆盖索引时，需要根据索引字段查出所有的要查询的字段信息），这也是在使用前缀索引需要考虑的因素。**



## 10、索引条件下推（ICP）

### 10.1、根据案例解释

我们在学习EXPLAIN的Extra字段中，学习过`Using index condition`这个信息，这个信息表示的含义就是索引条件下推。

让我们回顾一下：

```sql
EXPALIN SELECT * FROM s1 WHERE key1 > 'z' AND key1 LIKE '%a';
```

![image-20240411193817922](.\images\image-20240411193817922.png)

我们可以看到Extra字段是Using index condition。

s1表拥有key1字段的索引，此时筛选条件key1 > 'z'是可以用到索引的，但是key1 LIKE '%a'无法使用到索引。

一般的步骤是，先在二级索引中对key1 > 'z'的数据进行筛选后，然后到聚簇索引中回表，对key1 LIKE '%a'的数据再进行筛选。

但是由于第二个筛选条件中的key1字段，索引中是包含这个字段的，所以MySQL对这个操作进行了优化：

先在二级索引中对key1 > 'z'的数据进行筛选，筛选完成之后，再看数据是否满足key1 LIKE '%a'条件，将满足条件的数据才进行回表操作，这样就减少了回表的记录数，减少了**随机IO的次数**（回表的数据读取时是随机IO），提高了效率。

这就是**`索引条件下推（ICP）`**。



**案例2：**

给student表根据age、name和stuno创建一个联合索引：

```sql
create index idx_age_name_stuno ON student(age, name, stuno);
```

此时我们去student查询数据：

```sql
EXPLAIN SELECT * FROM student WHERE age = 1 AND name LIKE '%a%' AND stuno = 5;
```

由于我们之前学习过，使用LIKE '%'开头的筛选条件实际上是不使用索引的，所以这里使用索引的字段只有age一个。

但是，因为name字段和stuno字段都存在于联合索引中，虽然无法使用到索引，但是MySQL会给我做一个优化操作，让满足age = 1条件的数据，先不回表，而是在回表操作之前，先对数据进行name LIKE  '%a%'以及stuno = 5的筛选操作，从而**减少了回表操作的记录数，降低了随机IO的次数**，从而提高了效率。

![image-20240414155641770](.\images\image-20240414155641770.png)



由上述的过程我们可知：

索引条件下推，实际上就是**当查询中有条件没有使用到索引，但是索引中包含这个条件字段时，会在回表操作之前，先对满足之前条件的记录数进行条件筛选，将满足条件的记录再进行回表**，就减少了回表的记录数，从而减少随机IO次数。



### 10.2、使用前后对比

`Index Condition Pushdown(ICP)`是MySQL5.6中新特性，是一种在存储引擎层使用索引过滤数据的优化方式。

* 如果没有ICP，存储引擎会遍历索引以定位基表中的行，并将它们返回给MySQL服务器，由MySQL服务器评估`WHERE`后面的条件是否保留行。

* 启用ICP后，如果部分`WHERE`条件可以仅使用索引中的列进行筛选，则MySQL服务器会把这部分WHERE条件放到存储引擎筛选。然后，存储引擎通过使用索引条目来筛选数据，并且只有在满足这一条件时才从表中读取行。
  * 好处：ICP可以减少存储引擎必须访问基表的次数和MySQL服务器必须访问存储引擎的次数。
  * 但是，ICP的`加速效果`取决于在存储引擎内通过`ICP筛选掉`的数据的比例。



### 10.3、ICP的开启/关闭

* 默认情况下启用索引条件下推，可以通过设置系统变量`optimizer_switch`控制：`index_condition_pushdown`。

  ```sql
  #打开索引条件下推
  SET optimizer_switch = 'index_condition_pushdown=ON';
  
  #关闭索引条件下推
  SET optimizer_switch = 'index_condition_pushdown = OFF';
  ```

* 当使用索引条件下推时，`EXPLAIN`语句输出结果中`Extra`列内容显示为`Using index condition`。



### 10.4、ICP的使用条件与注意点

* 如果表访问的类型是range、ref、eq_ref和ref_or_null可以使用ICP。
* ICP可以用于`InnoDB`和`MyISAM`表，包括分区表`InnoDB`和`MyISAM`表。
* 当SQL使用覆盖索引时，不支持索引条件下推，因为索引覆盖不会进行回表操作。
* 对于InnoDB表，ICP仅用于`二级索引`。ICP的目标是减少全行读取次数，从而减少I/O操作。





## 11、普通索引 vs 唯一索引

从性能的角度考虑，你选择唯一索引还是普通索引呢？选择的依据是什么呢？

假设，我们有一个主键列为ID的表，表中有字段k，并且在k上有索引，假设字段k上的值都不重复。

这个表的建表语句是：

```sql
create table test(
	id INT PRIMARY KEY,
	k INT NOT NULL,
	name VARCHAR(16),
	index(k)
)engine = InnoDB;
```





### 查询过程

假设，执行查询的语句是select id from test where k = 5;

* 对于普通索引来说没查找到满足条件的第一个记录后，需要查找下一个记录，直到碰到第一个不满足k=5条件的记录。
* 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。

那么，这个不同的查询的性能差距有多少呢？答案是微乎其微。



### 更新过程

为了说明普通索引和唯一索引对更新语句性能的影响这个问题，介绍一下`change buffer`。

当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，`InnoDB会将这些更新操作缓存在change buffer中`，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行change buffer中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。

将change buffer中的操作应用到原数据页，得到最新结果的过程称为`merge`。`除了访问这个数据页`会触发merge外，系统有`后台线程会定期merge`。在数据库正常关闭（shutdown）的过程中，也会执行merge操作。

如果能够将更新操作先记录在chaneg buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用buffer pool的，所以这种方式还能够`避免占用内存`，提高内存利用率。

**`唯一索引的更新不能使用change buffer，只有普通索引才可以使用。`**



### change buffer的使用场景

**`普通索引与唯一索引在查询上没有差别，主要考虑的是更新性能的影响，所以尽量选择普通索引。`**

普通索引和change buffer的配合使用，对于数据量大的表的更新优化明显。

首先，`业务正确性优先`。如果业务要求数据库做唯一性约束，就必须创建唯一索引。**在业务可以接受的情况下，从性能角度出发建议优先考虑`非唯一索引`。**





## 12、其他查询优化策略

### EXISTS和IN的区分

**问题：**

不太理解哪些情况下应该使用EXISTS，哪些情况应该用IN。选择的标准是看能够使用表的索引吗？

回答：

索引是个前提，其实选择与否还是要看表的大小。我们来看看个案例：

```sql
SELECT * FROM A WHERE cc IN (SELECT cc FROM B);

SELECT * FROM A WHERE EXISTS (SELECT cc FROM B WHERE B.cc = A.cc);
```

这两个查询所代表的含义都是一样的。

第一个查询使用的是IN筛选，非关联子查询，执行的过程是先去执行子查询，将子查询的结果作为一个临时表，然后主表与临时表进行连接；

第二个查询使用的是EXISTS筛选，关联子查询，执行的过程是取出A表中的一个字段传入到子查询中进行筛选，存在则将字段所在的行存入到结果集中；循环反复，直到外表字段中所有的数据都已经执行完毕。

由上述的执行过程我们可以知道：

对于IN筛选的非关联子查询，当内表B中的数据较少时，效率提升的更高；

对于EXISTS筛选的关联子查询，当外表A中的数据较少时，效率提升的更高。

总结：

**`哪个表小就用哪个表来驱动，外表小就用EXISTS，内表小就用IN`。**



### COUNT(*)与COUNT(具体字段)效率

问题：在MySQL中统计数据表的行数，可以使用三种方式：`SELECT COUNT(*)`、`SELECT COUNT(1)`和`SELECT COUNT(具体字段)`，使用这三者之间的查询效率是怎样的？

答：

前提：如果你要统计的是某个字段的非空数据行数，则另当别论，毕竟比较执行效率的前提是结果一样才可以。

1. `COUNT(*)`和`COUNT(1)`都是对所有结果进行COUNT，**COUNT(*)和COUNT(1)本质上并没有区别**。如果有WHERE子句，则是对所有符合筛选条件的数据行进行统计，如果没有WHERE子句，则是对数据表的数据行数进行统计。

2. 如果是MyISAM存储引擎，统计数据表的行数只需要`O(1)`的复杂度，这是因为每张MyISAM的数据表都有一个meta信息存储了`row_count`值，则一致性由由表级锁来保证。

   如果是InnoDB存储引擎，因为InnoDB支持事务，采用行级锁和MVCC机制，所以无法像MyISAM一样，维护一个row_count变量，因此需要采用`扫描全表`，是`O(n)`的复杂度，进行循环+计数的方式来完成统计。

3. 在InnoDB引擎中，如果采用`COUNT(具体字段)`来统计数据行数，要尽量采用二级索引。因为主键采用的索引是聚簇索引，聚簇索引包含的信息多，明显会大于二级索引（非聚簇索引）。**对于`COUNT(*)`和`COUNT(1)`来说，它们不需要查找具体的行，只是统计行数，系统会自动采用占用空间更小的二级索引来进行统计**。

   如果有多个二级索引，会使用key_len小的二级索引进行扫描。当没有二级索引的时候，才会采用主键索引来进行统计。



### 关于SELECT *

在表查询中，建议明确字段，不要使用*作为查询的字段列表。原因：

1. MySQL在解析过程中，会通过`查询数据字典`将*按序转换成所有列名，这会大大的耗费资源和时间。

2. 无法使用`覆盖索引`。

3. 使用SELECT *将一些无关的字段都包含了进去，此时一个页中能够存放的记录数变少了，一次IO操作，区中包含的页中的数据，可能不足以存放下所有的记录，此时就需要进行多次IO操作。即让`IO的次数增加了`。



### LIMIT 1对优化的影响

针对的是会扫描全表的SQL语句，如果确定结果集只有一条，那么加上`LIMIT 1`的时候，当找到一条结果的时候就不会继续扫描，这样会加快查询速度。

如果数据表已经对字段建立了唯一索引，那么可以直接通过唯一索引进行扫描，查询到一个结果就会停止，不需要加上`LIMIT 1`了。

### 多使用COMMIT

只要有可能，在程序中尽量多使用COMMIT，这样程序的性能得到提高，需求也会因为COMMIT所释放的资源而减少。

COMMIT所释放的资源：

* 回滚段上用于恢复数据的信息
* 被程序语句获得的锁
* redo / undo log buffer中的空间
* 管理上述三种资源中的内部花费



## 13、主键如何设计？

聊一个实际问题：淘宝的数据库，主键是如何设计的？

有些人认为是使用BIGINT做主键，而不使用INT。错！

这样的回答，只站在了数据库这一层，而没有从`业务的角度`思考主键。主键就是一个自增ID吗？用自增做逐渐，架构设计上可能连及格都拿不到。

### 自增ID的问题

自增ID做逐渐，简单易懂，几乎所有数据库都支持自增模型，只是实现上各自有所不同而已。自增ID除了简单，其他都是缺点，存在以下几个方面的问题：

1. **`可靠性不高`**

存在自增ID回溯的问题，这个问题直到最新版本的MySQL8.0才修复。

**自增ID回溯：**

删除最后的ID，自增值向前回溯。比如：表中的最大ID是3，此时AUTO_INCREMNET的值是4，后续插入的数据的ID从4开始自增；删除ID为3的列，重启MySQL，AUTO_INCREMENT的值回到3，开始从3自增。

2. **`安全性不高`**

对外暴露的接口可以非常容易猜测对应的信息。比如：/User/1这的接口，很容易猜测用户ID的值是多少，总用户量有多少，容易通过接口进行数据的爬取。

3. **`性能差`**

自增ID的性能较差，需要在数据库服务器端生成。

4. **`交互多`**

也许还需要额外执行一次类似`last_insert_id()`的函数才能知道刚才插入的自增值，这需要多一次的网络交互。在海量并发的系统中，多一条SQL，就多一次性能上的开销。

5. **`局部唯一性`**

最重要的一点，自增ID是局部唯一，只在当前数据库实例中唯一，而不是全局唯一，在任意服务器间都是唯一的。对于目前的分布式系统来说，这简直是噩梦。

### 使用业务字段做主键

为了能够唯一地标识一个会员的信息，需要为`会员信息表`设置一个主键。那么，怎么为这个表设置主键，才能达到我们理想的目标呢？这里我们考虑业务字段做主键。

表数据如下：

![image-20240414233651169](.\images\image-20240414233651169.png)

在这个表里，哪个字段比较合适呢？

* **若选择卡号**

会员卡号看起来比较合适，因为会员卡号不能为空，而且有唯一性，可以用来标识一条会员记录。

不同的卡号对应不同的会员，字段"cardno"唯一地标识某一个会员。如果是这样，会员卡号与会员一一对应，系统是可以正常运行的。

但实际情况是，`会员卡号可能存在重复使用的情况`。比如，张三因为工作变动搬离了原本的地址，不再到商家的门店消费了。于是张三就不再是这个商家门店的会员了。但是，商家不想让这个会员卡空着，就把卡号是1000000001的会员卡发给了王五。

从系统设计的角度看，这个变化只是修改了会员信息表中的卡号是10000001这个会员信息，并不会影响到数据的一致性。也就是说，修改会员卡号是10000001的会员信息。系统的各个模块，都会获取到修改后的会员信息，不会出现有的模块获取到修改之前的会员信息，有的模块获取到修改后的会员信息，而导致系统内部数据不一致的情况。因此，从`信息系统层面`上看是没有问题的。

但是从使用`系统的业务层面`来看，就有很大的问题了，会对商家造成影响。

比如，我们有一个销售流水表，记录了所有的销售流水明细。2020年12月01日，张三在门店购买了一本书，消费了89元。那么，系统中就有了张三买书的流水记录，如下所示：

![image-20240414234403158](.\images\image-20240414234403158.png)

接着，我们查询一下2020年12月01日的会员销售记录：

![image-20240414234432015](.\images\image-20240414234432015.png)

如果会员卡10000001又发给了王五，我们会更改会员信息表。导致查询时：
![image-20240414234511710](.\images\image-20240414234511710.png)

这次得到的结果是：王五在2020年12月01日，买了一本书，消费了89元，显然是错误的。结论：不要把会员卡号当做主键。

* **选择会员电话或身份证号**

会员电话可以做主键吗？不行的，在实际操作中，手机号也存在`被运营商收回`，重新发给别人用的情况。

那身份证呢？身份证属于个人隐私，不一定能够获取到用户的身份证信息。

所以，建议**`不要用跟业务有关的字段做主键`**。毕竟，作为项目设计的技术人员，我们谁也无法预测在项目的整个生命周期中，哪个业务字段会因为项目的业务需求而有重复，或者重用之类的情况出现。



### 淘宝的主键设计

在淘宝的电商业务中，订单服务是一个核心业务。请问：订单号的主键淘宝是如何设计的呢？是自增ID吗？

我们详细看下4个订单号：

```
1550672064762308113
1481195847180308113
1431156171142308113
1431146631521308113
```

订单号是19位的长度，且订单的最后6位都是一样的，都是308113，且订单号的前面14位部分是单调递增的。

淘宝的订单ID设计应该是：

```
订单ID = 时间 + 去重字段 + 用户ID后6位尾号
```

这样的设计能做到全局唯一，且对分布式系统查询及其友好。



### 推荐的主键设计（重要）

**非核心业务**：可以使用自增主键ID，如日志、监控等信息。

**核心业务**：**`主键设计至少应该是全局唯一且单调递增`**。单调递增是为了在B+树中，插入数据时，不会在中间插入，不影响数据库性能。

这里推荐最简单的一种主键设计：`UUID`.

**`1、UUID的特点：`**

全局唯一，占用36个字节，数据无序，插入性能查。

**`2、认识UUID：`**

* 为什么UUID是全局唯一的？
* 为什么UUID占用36个字节？
* 为什么UUID是无序的？

MySQL数据库的UUID组成如下所示：

```
UUID = 时间 + UUID版本（16字节） - 时钟序列（4字节） - MAC地址（12字节）
```

例如：我们以UUID值e0ea12d4-6473-11eb-943c-00155dbaa39d举例：

![image-20240414235451648](.\images\image-20240414235451648.png)

`为什么UUID是全局唯一的？`

在UUID中时间部分占用60位，存储的类似TIMESTAMP的时间戳，但表示的是从1582-10-15 00:00:00到现在的100ns的计数。可以看到UUID存储的时间精度比TIMESTAMP更高，时间维度发生重复的概率降低到1/100ns。

时钟序列是为了避免时钟被回拨导致产生时间重复的可能性。MAC地址用于全局唯一。

`为什么UUID占用36个字节？`

UUID根据字符串进行存储，设计时还带有无用的"-"字符串，因此总共需要36个字节。

`为什么UUID是随机无序的？`

因为UUID的设计中，将时间低位放在最前面，而这部分数据是一直在变化的，而且是无序的。

由于上述的UUID是无序的，若将其设置成主键，往其中插入数据的时候，在B+树中就有可能在中间插入数据，这样的效率很低，因为往中间插入数据，后续的数据需要往后移动，出现页分裂的现象。所以，我们需要对UUID进行改造。



**`3、改造UUID`**

看前面的UUID信息，我们可以知道，在原本的UUID组成中，将时间低位放在了前面，时间高位放在了后面，若**将时间高低位互换**，由于时间是单调递增的，那整体也就变得单调递增了。MySQL8.0可以更换时间低位和高位的存储方式，这样UUID就是有序的UUID了。

MySQL还解决了UUID存在的空间占用问题，除去了UUID字符串中无意义的"-"字符串，并且将字符串用二进制类型保存，这样存储空间降低为**16字节**。

MySQL提供了`bin_to_uuid`函数进行转化：

```sql
SET @uuid = UUID();

SELECT @uuid, uuid_to_bin(@uuid), uuid_to_bin(@uuid, TRUE);
```

![image-20240415001258872](.\images\image-20240415001258872.png)

@uuid，实际上是用原本的方式进行存储，占用36个字节。

uuid_to_bin(@uuid)，就是将uuid中的-去除，并使用二进制类型保存字符串，此时的存储空间已经是16字节了。

然后**`函数uuid_to_bin(@uuid true)表示将UUID转化成有序的UUID`**了。



**`4、有序UUID性能测试`**

16字节的有序UUID，相比之前8字节的自增ID，性能和存储空间对比究竟如何呢？

我们来做一个测试，插入一亿条数据，每条数据占用500字节，含有3个索引，最终的结果如下所示：
![image-20240415001523107](.\images\image-20240415001523107.png)

从上图可以看到插入1亿条数据有序UUID是最快的，而且在实际业务使用中有序UUID在业务端就可以生成。还可以进一步减少SQL的交互次数。

另外，虽然有序UUID相比自增ID多了8个字节，但实际只增大了3G的存储空间，还可以接受。

> 在当今的互联网环境中，非常不推荐自增ID作为主键的数据库设计。更推荐类似有序UUID的全局唯一的实现。 
>
> 另外在真实的业务系统中，主键还可以加入业务和系统属性，如用户的尾号，机房的信息等。这样的主键设计就更为考验架构师的水平了。





**`5、如果不是MySQL8.0该怎么办？`**

手动赋值字段做主键！ 

比如，设计各个分店的会员表的主键，因为如果每台机器各自产生的数据需要合并，就可能会出现主键重复的问题。 

可以在总部MySQL数据库中，有一个管理信息表，在这个表中添加一个字段，专门用来记录当前会员编号的最大值。 

门店在添加会员的时候，先到总部MySQL数据库中获取这个最大值，在这个基础上加1，然后用这个值作为新会员的“id”，同时，更新总部 MySQL 数据库管理信息表中的当前会员编号的最大值。 

这样一来，各个门店添加会员的时候，都对同一个总部 MySQL 数据库中的数据表字段进行操作，就解决了各门店添加会员时会员编号冲突的问题。





# 三、数据库的其他调优策略

## 1、数据库调优的措施

### 1.1、调优的目标

* 尽可能`节省系统资源`，以便系统可以提供更大负荷的服务。（吞吐量更大）
* 合理的结构设计和参数调整，以提高用户操作`响应的速度`。（响应速度更快）
* 减少系统的瓶颈，提高MySQL数据库整体的性能。

### 1.2、如何定位调优问题

不过随着用户量的不断增加，以及应用程序复杂度的提升，我们很难用“`更快`”去定义数据库调优的目标，因为用户在不同时间段访问服务器遇到的瓶颈不同，比如双十一促销的时候会带来大规模的`并发访问`；还有用户在进行不同业务操作的时候，数据库的`事务处理`和`SQL查询`都会有所不同。因此我们还需要更加精细的定位，去确定调优的目标。

如何确定呢？一般情况下，有如下几种方式：

* **`用户的反馈（主要）`**
* **`日志分析（主要）`**
* **`服务器资源使用监控`**
* **`数据库内部状况监控`**
* **`其他`**

### 1.3、调优的维度和步骤

我们需要调优的对象是整个数据库管理系统，它不仅包括SQL查询，还包括数据库的部署配置、架构等。从这个角度来说，我们思考的维度就不仅仅局限在SQL优化上了。通过如下的步骤我们进行梳理：

#### 第一步：选择适合的DBMS

如果对`事务性处理以及安全性要求高`的话，可以选择商业的数据库产品。这些数据库在事务处理和查询性能上都比较强，比如采用SQL Server、Oracle，那么单表存储上亿条数据是没有问题的。如果数据表设计得好，即使不采用分库分表的方式，查询效率也不差。

除此之外，选择存储引擎也比较重要，如果进行事务处理的话可以选择InnoDB，非事务处理可以选择MyISAM。

**`DBMS的选择关系到了后面的整个设计过程，所以第一步就是要选择合适的DBMS。`**

#### 第二步：优化表设计（范式与反范式、字段数据类型的选择）

选择DBMS之后，我们就需要进行表设计了。数据表的设计方式也直接影响了后续的SQL查询语句。优化原则参考：

1. 表结构要尽量`遵循三范式的原则`。这样可以让数据结构更加清晰规范，减少冗余字段，同时也减少了在更新、插入和删除数据时等异常情况的发生。
2. 如果查询应用比较多，尤其是需要进行`多表联查`的时候，可以采用`反范式`进行优化。反范式采用空间换时间的方式，通过增加冗余字段提高查询的效率。
3. `表字段的数据类型`选择，关系到了查询效率的高低以及存储空间的大小。一般来说，如果字段可以采用数值类型就不要采用字符类型；字符长度要尽可能设计得短一点。针对字符类型来说，当确定字符长度固定时，就可以采用CHAR类型；当长度不固定时，通常采用VARCHAR类型。

**`好的表结构可以在业务发展和用户量增加的情况喜爱依然发挥作用，不好的表结构设计会让数据表变得非常臃肿，查询效率也会降低。`**

#### 第三步：优化逻辑查询（对于SQL语句逻辑的重要性）

当我们建立好数据表之后，就可以对数据表进行增删改查的操作了。这时我们首先要考虑的是逻辑查询优化。

SQL查询优化，可以分为`逻辑查询优化`和`物理查询优化`。逻辑查询优化就是通过改变SQL语句的内容让SQL执行效率更高，采用的方式是对SQL语句进行等价变换，对查询进行重写。

**`SQL查询重写包括了子查询优化、等价谓词重写、视图重写、条件简化、连接消除和嵌套连接消除等。`**

比如我们在讲解EXISTS子查询和IN子查询的时候，会根据`小表驱动大表`的原则选择适合的子查询。在WHERE子句中会尽量避免对字段进行函数运算，会导致字段的索引失效。

#### 第四步：优化物理查询（索引）

物理查询优化是在确定了逻辑查询优化之后，采用的物理优化技术（比如索引等），通过计算代价模型对各种可能的访问路径进行估算，从而找到执行方式中代价最小的作为执行计划。**`在这个部分中，我们需要掌握的重点是对索引的创建和使用。`**

SQL查询时需要对不同的数据表进行查询，因此在物理查询优化阶段也需要确定这些查询所采用的路径，具体的情况包括：

1. `单表扫描`：对于单表扫描来说，我们可以全表扫描所有的数据，也可以全部扫描。

2. `两张表的连接`：常用的连接方式包括了嵌套循环连接，HASH连接和合并连接。
3. `多张表的连接`：多张数据表进行连接的时候，`顺序`很重要，因为不同的连接路径查询的效率也不同，搜索空间也会不同。我们在进行多表连接的时候，搜索空间可能会达到`很高的数量级`，巨大的搜搜空间显然会占用更多的资源，因此我们需要通过调整连接顺序，将搜索空间调整在一个可接受的范围内。

#### 第五步：使用Redis或Memcached作为缓存

除了可以对SQL本身进行优化以外，我们还可以请外援提升查询的效率。

因为数据都是存放到数据库中，我们需要从数据库层中取出数据放到内存中进行业务逻辑的操作，当用户量增大的时候，如果频繁地进行数据查询，会消耗数据库的很多资源。如果我们将常用的数据直接放到内存中，就会大幅提升查询的效率。

键值存储数据库可以帮我们解决这个问题。

常用的键值存储数据库有Redis和Memcached，它们都可以将数据存放到内存中。

从可靠性来说，`Redis支持持久化`，可以让我们的数据保存在硬盘上，不过这样一来，性能消耗也会比较大，而`Memcached仅仅是内存存储，不支持持久化`。

从支持的数据类型来说，Redis比Memacached要多，它不仅支持key-value类型的数据，还支持List、Set、Hash等数据结构。当我们有持久化需求或者是更高级的数据处理需求的时候，就可以使用Redis。如果是简单的key-value存储，则可以使用Memcached。

**`通常我们对于查询响应要求高的场景（响应时间短，吞吐量大），可以考虑内存数据库，毕竟术业有专攻。`**传统的DBMS都是将数据存储在硬盘上，而内存数据库则存放在内存中，查询起来要快得多。

#### 第六步：库级优化

库级优化是站在数据库的维度上进行的优化策略，比如控制一个库中的数据表数量。另外，单一的数据库总会遇到各种限制，不如取长补短，利用外援的方式。通过`主从架构`优化我们的读写策略，通过对数据库进行垂直或水平切分，突破单一数据库或数据表的访问限制，提升查询的性能。

**`1.主从复制`**

![image-20240416212656692](.\images\image-20240416212656692.png)

![image-20240416212714371](.\images\image-20240416212714371.png)

**`2.数据切片`**

对`数据库分库分表`。当数据量级达到千万级以上时，有时候我们需要把一个数据库切分成多份，放到不同的数据库服务器上，减少对单一数据库服务器的访问压力。如果你使用的是MySQL，就可以使用MySQL自带的分区表功能，当然你也可以考虑自己做`垂直拆分（分库）`、`水平拆分（分表）`、`垂直+水平拆分（分库分表）`。

![image-20240416213100615](.\images\image-20240416213100615.png)

![image-20240416213154416](.\images\image-20240416213154416.png)







## 2、优化MySQL服务器

优化MySQL服务器主要从两个方面来优化，一方面是对`硬件`进行优化；另一方面是对MySQL`服务的参数`进行优化。这部分的内容需要较全面的只是，一般只有`专业的数据库管理员`才能进行这一类的优化。对于可以定制参数的操作系统，也可以针对MySQL进行操作系统优化。

### 2.1、优化服务器硬件

**`服务器的硬件性能直接决定着MySQL数据库的性能。`**硬件的性能瓶颈直接决定MySQL数据库的运行速度和效率。针对性能瓶颈提高硬件配置，可以提高MySQL数据库查询、更新的速度。

（1）`配置较大的内存`。足够大的内存是提高MySQL数据库性能的方法之一。内存的速度比磁盘I/O快得多，可以通过增加系统的缓冲区容量使数据在内存中停留的时间更长，以减少磁盘I/O。

（2）`配置高速磁盘系统`，以减少读盘的等待时间，提高响应速度。磁盘的I/O能力，也就是它的寻道能力，目前的SCSI高速旋转的是7200转/分钟，这样的速度，一旦访问的用户量上去，磁盘的压力就会过大。在SSD上，随机访问和顺序访问性能几乎差不多，使用SSD可以减少随机IO带来的性能损耗。

（3）`合理分布磁盘I/O`，把磁盘I/O分散在多个设备上，以减少资源竞争，提高并行操作能力。

（4）`配置多处理器`，MySQL是多线程的数据库，多处理器可以同时执行多个线程。





### 2.2、优化MySQL参数

通过优化MySQL的参数可以提高资源利用率，从而达到提高MySQL服务器性能的目的。

MySQL服务的配置参数都在`my.cnf`或`my.ini`文件的[mysqld]组中。配置完参数之后，需要重启MySQL服务才会生效。

下面对几个性能影响比较大的参数进行详细介绍：

* **`innodb_buffer_pool_size`**：这个参数是MySQL数据库最重要的参数之一，表示`InnoDB类型的表和索引的缓存区大小`。它不仅仅缓存索引数据，还会缓存表的数据。这个值越大，查询的速度就会越快。但是这个值太大会影响操作系统的性能。



* **`key_buffer_size`**：表示`索引缓冲区的大小`。索引缓冲区是所有的线程共享。增加索引缓冲区可以得到更好处理的索引（对所有读和多重写）。当然，这个值不是越大于越好，它的大小取决于内存的大小。如果这个值太大，就会导致操作系统频繁换页，也会降低系统性能。对于内存在4GB左右的服务器该参数可以设置为256M或384M。



* **`table_cache`**：表示`同时打开表的个数`。这个值越大，能够同时打开的表的个数越多。物理内存越大，设置就越大。默认为2402，调到512-1024最佳。这个值不是越大越好，因为同时打开的表太多会影响操作系统的性能。



* **`query_cache_size`**：表示`查询缓冲区的大小`。在MySQL5.7及以前，可以使用查询缓存的情况下，该参数是有意义的。可以通过在MySQL控制台观察，如果Qcache_lowmem_prunes的值非常大，则表明经常出现缓冲不够的情况，就要增加Query_cache_size的值；如果Qcache_hits的值非常大，则表明查询缓冲使用非常频繁，如果该值较小反而会影响效率，那么可以考虑不用查询缓存；Qcache_free_blocks，如果该值非常大，表明缓冲区中碎片很多。MySQL8.0之后失效。该参数需要和query_cache_type配合使用。
* **`query_cache_type`**的值是0时，所有的查询都不使用查询缓存区。但是query_cache_type=0并不会导致MySQL释放query_cache_size所配置的缓存区内存。
  * 当`query_cache_type=1`时，所有的查询都将使用查询缓存区，除非在查询语句中制定SQL_NO_CACHE，如SELECT SQL_NO_CACHE * FROM tbl_name。
  * 当`query_cache_type=2`时，只有在查询语句中使用SQL_CACHE关键字，查询才会使用查询缓存区。使用查询缓存区可以提高查询的速度，这种方式只适用于修改操作少且经常执行相同的查询操作的情况。



* **`sort_buffer_size`**：表示`每个需要进行排序的线程分配的缓冲区的大小`。增加这个参数的值可以提高ORDER BY或GROUP BY操作的速度。默认数值是2097144字节（约2MB）。对于内存在4GB左右的服务器推荐设置为6-8M，如果有100个链接，那么实际分配的总共排序缓冲区大小为100 × 6 = 600MB。



* **`join_buffer_size=8M`**：表示`联合查询操作所能使用的缓冲区大小`，和sort_buffer_size一样，该参数对应的分配内存也是每个连接独享。



* **`read_buffer_size`**：表示`每个线程连续扫描时为每个表分配的缓冲区大小`。当线程从表中连续读取记录时需要用到这个缓冲区。SET SESSION read_buffer_size=n可以临时设置改参数的值。默认为64K，可以设置为4M.



* **`innodb_flush_log_at_trx_commit`**：表示`何时将缓冲区的数据写入日志文件，并且将日志文件写入磁盘`。该参数对于InnoDB引擎非常重要。该参数有3个值，分别为0、1和2。默认值是1。
  * 值为`0`时，表示每秒1次的频率将数据写入日志文件并将日志文件写入磁盘。（1s内可能会有非常多的事务提交）每个事务的commit并不会触发前面的任何操作。该模式速度最快，但不太安全，mysqld进程的崩溃会导致上一秒所有事物数据的丢失。
  * 值为`1`时，表示每次提交事务时将数据写入日志文件并将日志文件写入磁盘进行同步。该模式是最安全的，但也是最慢的一种方式。因为每次事务提交或事务外的指令都需要把日志写入（flush）硬盘。
  * 值为`2`时，表示每次提交事务将数据写入日志文件，每隔1秒将日志文件写入磁盘。该模式较快，也比0安全，只有在操作系统崩溃或者系统断电的情况下，上一秒所有事务数据才可能丢失。

* **`innodb_log_buffer_size`**：`InnoDB存储引擎的事务日志所使用的缓冲区大小`。为了提高性能，先是将信息写入Innodb Log Buffer中，当满足innodb_flush_log_trx_commit参数所设置的相应条件（或者日志缓冲区写满）之后，才会将日志写入到文件（或者同步到磁盘）中。



* **`max_connections`**：表示允`许连接到MySQL数据库的最大数量`，默认值是151.如果状态变量connection_errors_max_connections不为0，且一直增长，则说明不断有连接请求因数据库连接数已达到允许最大值而失败，这时可以考虑增大max_connections的值。在Linux平台下，性能好的服务器，支持500-1000个连接很正常，需要根据服务器性能进行评估设定。这个连接数不是越大越好，因为这些连接会浪费内存的资源。过多的连接可能导致服务器僵死。
* **`back_log`**：用于`控制MySQL监听TCP端口时设置的积压请求栈大小`。如果MySQL的连接数达到了max_connections时，新来的请求将会被存在堆栈中，以等待某一连接释放资源，该堆栈的数量即back_log，如果等待连接的数量超过back_log，将不被授予连接资源，并报错。5.6.6版本之前默认值为50，之后的版本默认为50+（max_connections / 5）。对于Linux系统推荐设置为小于512的整数，最大不超过900.



* **`thread_cache_size`**：`线程池缓存线程数量的大小`，当客户端断开连接后将当前线程缓存起来，当在接到新的连接请求时快速响应无需创建新的线程。这尤其对那些使用`短连接`的应用程序来说可以极大的提高创建连接的效率。那么为了提高性能可以增大该参数的值。默认为60，可以设置为120。

  可以通过如下几个MySQL状态值来适当调整线程池的大小：

  ![image-20240417120428956](.\images\image-20240417120428956.png)

  当Threads_cached越来越少，但Threads_connected始终不降，且Threads_created持续升高，可以适当增加thread_cache_size的大小。



* **`wait_timeout`**：指定`一个请求的最大连接时间`，对于4GB左右内存的服务器可以设置为5-10.



* **`interactive_timeout`**：表示服务器在关闭连接前等待行动的秒数。



这里给出一份my.cnf的参考配置：

```INI
[mysqld]
port = 3306 serverid = 1 socket = /tmp/mysql.sock 
skip-locking #避免MySQL的外部锁定，减少出错几率增强稳定性。
skip-name-resolve #禁止MySQL对外部连接进行DNS解析，使用这一选项可以消除MySQL进行DNS解析的时间。但需要注意，如果开启该选项，则所有远程主机连接授权都要使用IP地址方式，否则MySQL将无法正常处理连接请求！ 
key_buffer_size = 256M 
back_log = 384
max_allowed_packet = 4M 
table_cache = 128K 
sort_buffer_size = 6M 
read_rnd_buffer_size=16M 
join_buffer_size = 8M 
64M 
table_cache = 512 
tmp_table_size = 256M 
wait_timeout = 10 
thread_stack = 256K
read_buffer_size = 4M
myisam_sort_buffer_size =
thread_cache_size = 64 
query_cache_size = 64M
max_connections = 768 
max_connect_errors = 10000000
thread_concurrency = 8 #该参数取值为服务器逻辑CPU数量x2，在本例中，服务器有2颗物理CPU，而每颗物理CPU又支持H.T超线程，所以实际取值为4x2=8
skip-networking #开启该选项可以彻底关闭MySQL的TCP/IP连接方式,如果WEB服务器是以远程连接的方式访问MySQL数据库服务器则不要开启该选项！否则将无法正常连接！ 
table_cache=1024
innodb_additional_mem_pool_size=4M #默认为2M 
innodb_flush_log_at_trx_commit=1
innodb_log_buffer_size=2M #默认为1M 
innodb_thread_concurrency=8 #你的服务器CPU有几个就设置为几。建议用默认一般为8 
tmp_table_size=64M #默认为16M，调到64-256最挂
thread_cache_size=120 
query_cache_size=32M
```





#### 具体案例：

下面是一个电商平台，类似于京东或天猫这样的平台。商家购买服务，入住平台，开通之后，商家可以在系统中上架各种商品，客户通过手机app、微信小程序等渠道购买商品，商家接到订单以后安排快递送货。

刚刚上线的时候，系统运行状态良好。但是，随着入驻的商家不断增多，使用系统的用户量越来越多，每天的订单数据达到了5万条以上。这个时候，系统开始出现问题，CPU使用率不断飙升。终于，双十一或618活动高峰的时候，CPU使用率达到了99%，这实际上就意味着，系统的计算资源已经耗尽，再也无法处理任何新的订单了。换句话说，系统已经崩溃。

这个时候，我们想到了对系统参数进行调整，因为参数的值决定了资源配置的方式和投放的程度。

为了解决这个问题，一共调整3个系统参数，分别是

* InnoDB_flush_log_at_trx_commit
* InnoDB_buffer_pool_size
* InnoDB_buffer_pool_instances

下面我们就说一说调整这三个参数的原因是什么。

**`（1）调整系统参数InnoDB_flush_log_at_trx_commit`**

这个参数适用于InnoDB存储引擎，电商平台系统中的表用的存储引擎都是InnoDB。默认的值是1，意思是`每次提交事务，都把数据写入日志，并把日志写入磁盘`。这样做的好处是`安全性最佳`，不足之处在于每次提交事务，都要进行磁盘写入的操作。在大并发的场景下，过于频繁的磁盘读写会导致CPU资源浪费，系统效率变低。

这个参数大致还有2个可能的选项，分别是0和2。我们把这个参数的值改成了2，这样就不用每次提交事务的时候都启动磁盘读写了，在大并发的场景下，可以改善系统效率，降低CPU使用率。即便出现故障，损失的数据也比较小。

**`（2）调整系统参数InnoDB_buffer_pool_size`**

这个参数的意思是，InnoDB存储引擎`使用缓存来存储索引和数据`。这个值越大，可以加载到缓存区的索引和数据量就越多，需要的磁盘读写就越少。

因为我们的MySQL服务器是数据库专属服务器，只用来运行MySQL数据库服务，没有其他应用了，而我们的计算机是64位机器，内存是128G，于是我们把这个参数的值调整为64G，这样一来，磁盘读写次数可以大幅降低，我们就可以充分利用内存，释放一些CPU资源。

**`（3）调整系统参数InnoDB_buffer_pool_instances`**

这个参数可以将InnoDB的缓存区分成几个部分，这样就可以提高系统的`并行处理能力`，因为可以允许将多个进程同时处理不同的缓存区。

我们把InnoDB_buffer_pool_instances的值修改为64，意思是把InnoDB的缓存区分成64个分区，这样就可以同时有多个进程进行数据操作，CPU的效率就高多了。

修改好系统参数的值，要重启MySQL数据库服务器。



> 总结一下就是遇到CPU资源不足的情况，可以从下面2个思路去解决：
>
> * 疏通拥堵路段，消除瓶颈，让等待的时间更短；
> * 开拓新的通道，增加并行处理能力。





## 3、优化数据库结构

一个好的数据设计方案对于数据库的性能常常会起到事半功倍的效果。合理的数据库结构不仅可以使数据库占用更小的磁盘空间，而且能够使查询速度更快。数据库结构的设计需要考虑数据冗余、查询和更新的速度，字段的数据类型是否合理等多方面内容。

### 3.1、拆分表：冷热数据分离

拆分表的思路是，把1个包含很多字段的表拆分成2个或多个相对较小的表。这样做的原因是，这些表中某些字段的操作频率很高（`热数据`），经常要进行查询或更新操作，而另外一些字段的使用频率却很低（`冷数据`），将冷热数据分离，就是把一张表分成热数据表和冷数据表，可以减少表的宽度，防止每次读取就要读取很大的记录，把不常用的记录剔除出去，这样就有足够的内存存放有效的热数据。

将冷热数据分离，这样一来，一个表中的字段就变少了，在聚簇索引中，一个记录所占用的内存就也就变少了，一个页中能够存储的记录数也就会变多，这样一来磁盘的IO次数就变少，也能够更有效地利用到缓存来存储热数据，效率会变高。

所以，**冷热数据分离的目的**是：`（1）减少磁盘IO，保证热数据的内存缓存命中率。（2）更有效的利用缓存，避免读入无用的冷数据`。

该方式适用于表中字段较多，有部分字段需要经常查询使用，而有部分字段不经常查询。如果字段都需要经常使用，可能会造成联合查询的次数增多造成查询效率的降低。



**举例：**

`会员表members`存储会员登录认证信息，该表中有很多字段，如id、姓名、密码、地址、电话、个人描述字段。其中地址、电话、个人描述等字段并不常用，可以将这些不常用的字段分解出另一个表。将这个表取名叫members_detail，表中有member_id、address、telephone、description等字段。这样就把会员表分成了两个表，分别为`mebers表`和`mebers_detail表`。

创建这两个表的SQL语句如下：

```sql
CREATE TABLE members(
	id INT NOT NULL AUTO_INCREMENT,
	username VARCHAR(50) DEFAULT NULL,
	password VARCHAR(50) DEFAULT NULL,
	last_login_time datetime DEFAULT NULL,
	last_login_ip VARCHAR(100) DEFAULT NULL,
	PRIMARY KEY(id)
);

CREATE TABLE members_detail(
	member_id INT NOT NULL DEFAULT 0,
	address varchar(255) DEFAULT NULL,
	telephone VARCHAR(255) DEFAULT NULL,
	description text
);
```

将表members分成了两张表，一张表members存放热数据，一张表members_detail存放冷数据。这样，我们经常使用的热数据表，聚簇索引中存放的字段就少了很多，我们在使用索引时，内存缓冲的有效率就高，一页中存放的记录数也高，读取效率自然就高。

如果需要查询会员的基本信息或详细信息，那么可以用会员的id来查询。如果需要将会员的基本信息和详细信息同时显现，那么可以将members表和members_detail表进行联合查询，查询语句如下：

```sql
SELECT * FROM members LEFT JOIN memebrs_detail ON members.id = members_detail.member_id;
```







### 3.2、增加中间表

对于需要经常联合查询的表，可以建立中间表以提高查询效率。通过建立中间表，**`把需要经常联合查询的数据插入中间表中，然后将原来的联合查询改为对中间表的查询，以此提高查询效率。`**

**注意：**这种方式指适用于不需要频繁更新的表，因为当有一张表中的数据发生改变了，中间表中的数据也需要同步地进行修改。 

首先，分析经常联合查询表中的字段；然后，使用这些字段建立一个中间表，并将原来联合查询的表的数据插入中间表中；最后，使用中间表来进行查询。

**举例：**学生信息表和班级表的SQL语句如下：

```sql
CREATE TABLE class (
	id INT NOT NULL AUTO_INCREMENT,
    className VARCHAR(30) DEFAULT NULL,
    address VARCHAR(40) DEFAULT NULL,
	monitor INT NULL,
    PRIMARY KEY(id)
)ENGINE = INNODB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4;

CREATE TABLE student(
	id INT NOT NULL AUTO_INCREMENT,
    stuno INT NOT NULL,
    name VARCHAR(20) DEFAULT NULL,
	age INT DEFAULT NULL,
    classId INT DEFAULT NULL,
    PRIMARY KEY(id)
)ENGINE = INNODB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4;
```

现在有一个模块需要经常查询带有学生名称（name）、学生所在班级（className）、学生班级班长（monitor）的学生信息。根据这种情况可以创建一个temp_student表。temp_student表中存储学生名称(stu_name)、学生所在班级名称(className)和学生班级班长（monitor）信息。创建表的语句如下：

```sql
CREATE TABLE temp_student(
    id INT NOT NULL AUTO_INCREMENT,
    stu_name INT NOT NULL,
    className VARCHAR(20) DEFAULT NULL,
    monitor INT(3) DEFAULT NULL,
    PRIMARY KEY(id)
)ENGINE=INNODB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4;
```

接下来，从学生信息表和班级表中查询相关信息存储到临时表中：

```sql
INSERT INTO temp_student(stu_name, className, monitor)
	SELECT s.name,c.className,c.monitor
	FROM student as s INNER JOIN class as c
	ON s.classId = c.id;
```

以后，可以直接从temp_student表中查询学生名称、班级名称和班级班长，而不用每次都进行联合查询。这样可以提高数据库的查询速度。



**问题**：如何保证数据的一致性？

* 方式一：清空数据->重新添加数据

* 方式二：可以使用视图的方式，来存放多张表中联合的字段，同时也能够避免因增加中间表，而造成的数据不一致问题。（但是视图实际上是对联合查询SQL的一个封装，效率上并没有增加，只不过视图能够让我们更加直观地查看联合查询的结果，所以不能使用视图的方式来代替中间表）





### 3.3、增加冗余字段

即**`反范式化`**。



### 3.4、优化数据类型

改进表的设计时，可以考虑优化字段的数据类型。当数据量越来越多的似乎，不能只从系统稳定性的角度思考问题，还要考虑系统整体的稳定性和效率。此时，**`优先考虑符合存储需要的最小的数据类型。`**

列的`字段越大`，建立索引时所需要的`空间也就越大`，这样一页中所能存储的`索引节点的数量也就越少`，在遍历时所需要的`IO次数也就越多`，`索引的性能也就越差`。

具体来说：

**情况1：对正数类型数据进行优化**

遇到正数类型的字段可以用**`INT型`**。这样做的理由是，INT型数据有足够大的取值范围，不用担心数据超出取值范围的问题。刚开始做项目的时候，首先要保证系统的稳定性，这样设计字段类型是可以的。但在数据量很大的时候，数据类型的定义，在很大程度上会影响到系统整体的执行效率。

对于非负型的数据（如自增ID、整型IP）来说，要优先使用无符合整形**`UNSIGNED`**来存储。因为无符号相对于有符号，同样的字节数，存储的数值范围更大。如tinyint有符号为-128~127，无符号为0~255，多出一倍的存储空间。

**情况2：既可以使用文本类型也可以使用整数类型的字段，要选择使用整数类型**

跟文本类型相比，大整数往往`占用更少的存储空间`，因此，在存取和比对的时候，可以占用更少的内存空间。所以，在二者皆可用的情况下，尽量使用整数类型，这样可以提高查询的效率。如：将IP地址转换成整型数据。

**情况3：避免使用TEXT、BLOB数据类型**

MySQL`内存临时表`不支持TEXT、BLOB这样的大数据类型，如果查询中包含这样的数据，在排序等操作时，就不能使用内存临时表，必须使用`磁盘临时表`进行。并且对于这种数据，MySQL还是要进行`二次查询`，会使SQL性能变得很差，但是不是说一定不能使用这样的数据类型。

如果一定要使用，建议把BLOB或是TEXT列`分离到单独的扩展表`中，查询时一定不要使用select *，而只需要取出必要的列，不需要把TEXT列的数据时不要对该列进行查询。

**情况4：避免使用ENUM类型**

修改ENUM值需要使用ALTER语句。

ENUM类型的ORDER BY操作效率低，需要额外操作。使用TINYINT类型代替ENUM类型。

**情况5：使用TIMESTAMP存储时间**

TIMESTAMP存储的时间范围1970-01-01 00:00:01 至 2038-01-19 03:14:07。TIMESTAMP使用4个字节，DATETIME使用8个字节。并且TIMESTAMP具有自动赋值以及自动更新的特性，对于create_time和update_time来说，再好不过。

**情况6：使用DECIMAL代替FLOAT和DOUBLE存储精确浮点数**

1）非精确浮点数：float、double

2）精确浮点数：decimal

DECIMAL类型为精准浮点数，在计算时不会丢失精度，尤其是财务相关的金融类数据。占用空间由定义的宽度决定，每4个字节可以存储9位数字，并且小数点要占用一个字节。可用于存储比bigint更大的整型数据。

**`总之，遇到数据量大的项目时，一定要在充分了解业务需求的前提下，合理优化数据类型，这样才能充分发挥资源的效率，使系统达到最优。`**



### 3.5、优化插入记录的速度

插入记录时，若是批量插入，影响插入速度的主要是索引、唯一性校验、一次插入记录条数等。根据这些情况可以分别进行优化。这里我们分为MyISAM引擎和InnoDB存储引擎来讲。

1. **`MyISAM引擎的表`**

**(1)禁用索引**

对于非空表，插入记录时，MySQL会根据表的索引对插入的记录建立索引。如果插入大量数据，建立索引就会降低插入记录的速度。为了解决这种情况，可以在插入记录之前禁用索引，数据插入完毕后再开启索引。禁用索引的语句如下：

```sql
ALTER TABLE table_name DISABLE KEYS;
```

重新开启索引的语句如下：

```sql
ALTER TABLE table_name ENABLE KEYS;
```

若对于空表批量导入数据，则不需要进行此操作，因为MyISAM引擎的表是在导入数据后才建立索引的。

**(2)禁用唯一性检查**

插入数据时，MySQL会对插入的记录进行唯一性校验。这种唯一性校验会降低插入的速度。为了避免这种情况对插入速度的影响，可以在插入数据之前禁用唯一性检查，等到数据插入完毕后再开启。禁用唯一性检查的语句如下：

```sql
SET UNIQUE_CHECKS=0;
```

开启唯一性检查的语句如下：

```sql
SET UNIQUE_CHECKS=1;
```

**(3)使用批量插入**

插入多条记录时，可以使用一条INSERT语句插入一条记录，也可以使用一条INSERT语句插入多条记录。插入一条记录的INSERT语句情形如下：

```sql
INSERT INTO student values(1,'zhangsan',18,1);
INSERT INTO student values(2,'lisi',17,1);
INSERT INTO student values(3,'wangwu',17,1);
INSERT INTO student values(4,'zhaoliu',19,1);
```

使用一条INSERT语句插入多条记录的情形如下：

```sql
INSERT INTO student valus
(1,'zhangsan',18,1),
(2,'lisi',17,1),
(3,'wangwu',17,1),
(4,'zhaoliu',19,1);
```

第2种情形的插入速度要比第一种情形快。

**(4)使用LOAD DATA INFILE批量导入**

当需要批量导入数据时，如果能用LOAD DATA INFILE语句，就尽量使用。因为LOAD DATA INFILE语句导入数据的速度比INSERT语句快。

2. **`InnoDB引擎的表：`**

**(1)禁用唯一性检查**

插入数据之前执行`set unique_checks=0`来禁止对唯一索引的检查，数据导入完成之后再运行`set unique_checks=1`。这个和MyISAM引擎的使用方法一样。

**(2)禁用外键检查**

插入数据之前执行禁止对外键的检查，数据插入完成之后再恢复对外键的检查。禁用外键检查的语句如下：

```sql
SET foreign_key_checks=0;
```

恢复对外键的检查语句如下：

```sql
SET foreign_key_checks=1;
```

**(3)禁止自动提交**

插入数据之前禁止事务的自动提交，数据导入完成之后，执行恢复自动提交操作。禁止自动提交的语句如下：

```sql
SET autocommit=0;
```

恢复自动提交的语句如下：

```sql
SET autocommit=1;
```



### 3.6、使用非空约束

**`在设计字段的时候，如果业务允许，建议尽量使用非空约束。`**这样做的好处是：

1. 使用IS NOT NULL判断无法使用索引，如果字段设置了NOT NULL约束，就不需要再进行判断。
2. 在进行比较和计算时，省去要对NULL值的字段判断是否为空的开销，提高存储效率。
3. 非空字段也容易创建索引。因为索引NULL列需要额外的空间来保存，所以要占用更多的空间。使用非空约束，就可以节省存储空间（每个字段1个bit）。

### 3.7、分析表、检查表与优化表

MySQL提供了分析表、检查表和优化表的语句。`分析表`主要是分析关键字的分布，`检查表`主要是检查表是否存在错误，`优化表`主要是消除删除或者更新造成的空间浪费。

#### 1、分析表

MySQL中提供了`ANALYZE TABLE`语句分析表，ANALYZE TABLE语句的基本语法如下：

```sql
ANALYZE TABLE table_name[, table_name...];
```

默认的，MySQL服务会将ANALYZE TABLE语句写到binlog中，以便在主从架构中，从服务能够同步数据。可以添加参数LOCAL或者NO_WRITE_TO_BINLOG取消将语句写到binlog中。

使用ANALYZE TABLE分析表的过程中，数据库系统会自动对表加一个`只读锁`。在分析期间，只能读取表中的记录，不能更新和插入记录。ANALYZE TABLE语句能够分析InnoDB和MyISAM类型的表，但是不能作用于视图。

ANALYZE TABLE分析后的统计结果会反映到**`cardinality`**的值，该值统计了表中某一键所在的列不重复的值的个数。**`该值越接近于表中的总行数，则在表查询连接或者索引查询时，就越优先被优化器选择使用。`**也就是索引列的cardinality的值与表中数据的总行数差距越大，即便查询的时候使用了该索引作为查询条件，存储引擎实际查询时使用的概率就越小。下面通过例子来验证下，cardinality可以通过SHOW INDEX FROM 表名查看。

**下面来举个例子：**

创建一张users表：

```sql
CREATE TABLE users(
	id INT NOT NULL AUTO_INCREMNET,
	name VARCHAR(255) DEFAULT NULL,
	age INT DEFAULT NULL,
	sex varchar(1) DEFAULT NULL,
	PRIMARY KEY(id),
	KEY idx_name(name)
) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4;
```

其中，给name创建了一个二级索引

然后，我们使用存储函数，往表中添加1000条数据，这1000条数据中，id单调递增，但是name值都是相同的tom。

```sql
DELIMITER //
CREATE PROCEDURE insert_users(IN max_num INT)
BEGIN
DECLARE i INT DEFAULT 0;
SET autocommit = 0;
REPEAT
	SET i = i + 1;
	INSERT INTO users(name,age,sex)
	VALUES ('tom', rand_num(1, 20), '男');

UNTIL i = max_num END REPEAT;
COMMIT;
END //
DELIMITER ;

call insert_users(1000);
```

![image-20240417160840201](.\images\image-20240417160840201.png)

此时，去查看表中的索引信息：

```sql
SHOW INDEX FROM users;
```

![image-20240417161020648](.\images\image-20240417161020648.png)

有两个索引，分别是聚簇索引和name字段的普通索引。

查询结果中的Cardinality字段表示的含义是表中该索引对应的字段有多少个不同的数据。**这个值可以用来表示字段的区分度**。比如这里name字段索引的Cardinality是1，聚簇索引的Cardinality是1000，表示name字段的区分度非常小，区分度小，即数据都是一样的，索引的作用也就小，MySQL优化器在选择时会尽量避免使用区分度小的索引。

当我们给users表中的一个数据进行了修改，例如：

```sql
UPDATE users SET name = 'jerry' WHERE id = 2;
```

此时再去查看索引的信息：

![image-20240417161737472](.\images\image-20240417161737472.png)

发现name字段索引的Cardinality的值依然是1.

只有当我们去调用分析表的操作后，才会去更新索引中的Cardinality的值，即：

```sql
ANALYZE TABLE users;
```

此时再去查看索引：

![image-20240417161901411](.\images\image-20240417161901411.png)

即，由此可知：

> **`ANALYZE TABLE分析表语句的作用是去刷新索引信息中Cardinality的值。Cardinality值代表着字段的区分度，值越大，区分度越大，索引的效果越好，MySQL优化器越优先考虑`。**



#### 2、检查表

MySQL中可以使用`CHECK TABLE`语句来检查表。CHECK TABLE语句能够检查InnoDB和MyISAM类型的表是否存在错误。CHECK TABLE语句在执行过程中也会给表加上`只读锁`。

对于MyISAM类型的表，CHECK TABLE语句还会更新关键字统计数据。而且，CHECK TABLE也可以检查视图是否有错误，比如在视图定义中被引用的表已经不存在。该语句的基本语法如下：

```sql
CHECK TABLE table_name[, table_name]...[option]...
option = {QUICK | FAST | MEDIUM | EXTENDED | CHANGED}
```

执行案例：

![image-20240417172227867](.\images\image-20240417172227867.png)

该语句对于检查的表可能会产生多行信息。最后一行有一个状态的Msg_text值，Msg_text通常为OK。如果不是OK，需要对其进行修复；是OK说明表已经是最新的了。

#### 3、优化表

**`方式1：OPTIMIZE TABLE`**

MySQL中使用OPTIMIZE TABLE语句来优化表。但是，**`OPTIMIZER TABLE只能优化表中的VARCHAR、BLOB或者TEXT类型的字段`**。一个表使用了这些字段的数据类型，若已经删除了表的一大部分数据，或者已经对含有可变长度行的表（含有VARCHAR、BLOB或TEXT列的表）进行了跟多更新，则应使用OPTIMIZE TABLE来重新利用未使用的空间，并整理数据文件的碎片。

OPTIMIZE TABLE语句对InnoDB和MyISAM类型的表都有效。该语句在执行过程中也会给表加上`只读锁`。

OPTIMIZE TABLE语句的基本语法如下：

```sql
OPTIMIZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE table_name [, table_name]...
```

LOCAL | NO_WRITE_TO_BINLOG关键字的意义和分析表相同，都是离不写入二进制日志。

![image-20240417173834012](.\images\image-20240417173834012.png)

> 说明：
>
> 在多数的设置中，根本不需要运行OPTIMIZE TABLE，即使对可变长度进行了大量的更新，也不需要经常运行，每周一次或每月一次即可，并且只需要针对特定的表运行。

举例：

```
1. 新建一张表，使用存储过程往里面放入100MB数据，或者更多
2. 查看服务器上数据文件的大小，文件目录是/var/lib/mysql/所在的水库
3. 删除二分之一的数据，然后在查看当前数据文件的大小，会发现此时的大小不变
4. 使用OPTIMIZE TABLE表名;命令优化表
5. 再查看当前数据文件的大小，会发现此时大小已经变化，做了空间的回收
```

优化前：

![image-20240417174220499](.\images\image-20240417174220499.png)

优化后：

![image-20240417174245053](.\images\image-20240417174245053.png)

**`方式2：使用mysqlcheck命令`**

mysqlcheck的作用实际上和OPTIMIZE TABLE语句的效果是一样的：

```shell
mysqlcheck -o DatabaseName TableName -u root -p*******
```

mysqlcheck是Linux中的命令，-o代表着Optimize

举例：优化所有的表

```shell
mysqlcheck -o DatabaseName -u root -p*******
#或
mysqlcheck -o --all-databases -u root -p********
```

![image-20240417190828277](.\images\image-20240417190828277.png)



### 3.8、小结

上述这些方法都是有利有弊的。比如：

* 修改数据类型，节省存储空间的同时，还要考虑到数据不能超过取值范围；
* 增加冗余字段的时候，不要忘了确保数据的一致性；
* 把大表拆分，也就意味着查询会增加新的连接，从而增加额外的开销和运维成本。

## 4、大表优化

当MySQL单表记录数过大时，数据库的CRUD性能明显下降，一些常见的措施如下：

### 4.1、限定查询的范围

**`禁止不带任何限制数据范围条件的查询语句`**。比如：我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内。

### 4.2、读/写分离

详细内容请查看《主从复制》

经典的数据库拆分方案，主库负责写，从库负责读。

* 一主一从模式：

![image-20240417191306441](.\images\image-20240417191306441.png)

* 双主双从模式：

![image-20240417191428356](.\images\image-20240417191428356.png)

### 4.3、垂直拆分

即：将表拆分，将列拆分。将表放在不同的数据库中，对很多列的表拆分成多个表（冷热分离）

当数量级达到`千万级`以上时，有时候我们需要把一个数据库切成多份，放到不同的数据库服务器上，减少对单一数据库服务器的访问压力。

![image-20240417195947380](.\images\image-20240417195947380.png)

* 如果数据库中的数据表过多，可以采用`垂直分库`的方式，将关联的数据表部署到同一个数据库上。
* 如果数据表中的列过多，可以采用`垂直分表`的方式，将一张数据表拆分成多张数据表，把经常一起使用的列放到同一张表中。（类似于冷热数据分离）

![image-20240417200405315](.\images\image-20240417200405315.png)

**`垂直拆分的优点`**：可以使得列数据变小，在查询时减少读取的Block数，减少I/O次数。此外，垂直分区可以简化表的结构，易于维护。

**`垂直拆分的缺点`**：主键会出现冗余，需要管理冗余列，并会引起JOIN操作。此外，垂直拆分会让事务变得更加复杂。

### 4.4、水平拆分

* 尽量控制单表数据量的大小，建议控制在1000万以内。1000万并不是MySQL数据库的限制，过大会造成修改表结构、备份、恢复都有很大的问题。此时可以用`历史数据归档`（应用于日志数据），`水平分表`（应用于业务数据）等手段控制数据量的大小。
* 这里我们主要考虑业务数据的水平分表策略。将大的数据表按照`某个属性维度拆成不同的小表`，每张小表保持相同的表结构。比如你可以按照年份来划分，把不同年份的数据放在不同的数据表中。2017年、2018年和2019年的数据就可以分别放到三张数据表中。
* 水平分表仅是解决了单一表数据过大的问题，但由于表的数据还是在同一台机器上，其实对于提升MySQL并发能力没有什么意义，所以`水平拆分最好分库`，从而达到分布式的目的。

![image-20240417201016023](.\images\image-20240417201016023.png)

`水平拆分能够支持非常大的数据量存储，应用端改造也少，但分片事务难以解决，扩节点JOIN性能较差，逻辑复杂。`

《Java工程师修炼之道》的作者推荐**`尽量不要对数据进行分片，因为拆分会带来逻辑、部署、运维的各种复杂度`**，一般的数据表在优化得当的情况下支撑千万以下的数据量是没有太大问题的。如果实在要分片，尽量选择客户端分片架构，这样可以减少一次和中间件的网络I/O。

下面补充一下数据库分片的两种常见方案：

* **`客户端代理：分片逻辑在应用端，封装在jar包，通过修改或者封装JDBC层来实现。`**
* **`中间件代理：在应用和数据中间加了一个代理层。分片逻辑统一维护在中间件服务中。`**



## 5、其他调优策略（了解，均是MySQL8.0版本下）

### 5.1、服务器语句超时处理

在MySQL8.0中可以设置`服务器语句超时的限制`，单位可以达到`毫秒`级别。当中断的执行语句超过设置的毫秒数后，服务器将终止查询影响不大的事务或连接，然后将错误报给客户端。

设置服务器语句超时的限制，可以通过设置系统变量**`MAX_EXECUTION_TIME`**来实现。默认情况下，MAX_EXECUTION_TIME的值为0，代表没有时间限制。

例如：

```sql
SET GLOBAL MAX_EXECUTION_TIME = 2000;

SET SESSION MAX_EXECUTION_TIME = 2000; #指定该会话中SELECT语句的超时时间
```



### 5.2、创建全局通用表空间

MySQL8.0使用**`CREATE TABLESPACE`**语句来创建一个`全局通用表空间`（也叫作常规表空间）。

类似于系统表空间，常规表空间是共享表空间，可以存储多个表的数据。

常规表空间比独占表空间（每个表自己的表空间）具有潜在的内存优势。服务器在表空间的生存期内将表空间元数据保留在内存中。与独占表空间中相同数量的表相比，常规表空间中的多个表元数据消耗的内存更少。

可以在创建表的时候，指定属于哪个表空间，也可以对已有表进行表空间修改等。

下面创建名为atguigu1的共享表空间，SQL语句如下：

```sql
CREATE TABLESPACE 常规表空间名 ADD datafile '常规表空间文件名.ibd' file_block_size=16k;
```

创建表时指定表空间，SQL语句如下：

```sql
CREATE TABLE test(id INT, name VARCHAR(10)) engine=innodb DEFAULT charset=utf8mb4 tablespace 常规表空间名;
```

如何删除创建的表空间？因为是共享表空间，所以不能直接通过drop table tbname删除，这样操作并不能回收空间。当确定共享表空间的数据都没用，并且依赖该表空间的表均已经删除时，可以通过**`DROP TABLESPACE`**删除共享表空间来释放空间，如果依赖该共享表空间的表存在，就会删除失败。

应该首先删除依赖该表空间的数据表，SQL语句如下：

```sql
DROP TABLE test;
```

最后即可删除表空间，SQL语句如下：

```sql
DROP TABLESPACE 表空间名;
```



### 5.3、隐藏索引对调优的帮助（之前学习过）

不可见索引的特性对于性能调试非常有用。在MySQL8.0中，索引可以被"隐藏"和"显示"。**`当一个索引被隐藏时，它不会被查询优化器所使用`**。也就是说，管理员可以隐藏一个索引，观察它对数据库的影响。如果数据库的性能有所下降，说明这个索引是有用的，于是将其恢复显示即可；如果数据库性能看不出变化，就说明这个索引是多余的，可以删除。

需要注意的是当索引被隐藏时，它的内容仍然和正常索引一样是实时更新的。如果一个索引需要长期被隐藏，那么可以将其删除，因为索引的存在会影响插入、更新和删除性能。

数据表中的主键索引不能被设置成隐藏的。





